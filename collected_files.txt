--- 文件地址: viat/Attack_exp_fast_K.py ---
from __future__ import print_function
import os
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torch.optim as optim
from torchvision import datasets, transforms

from trades import trades_loss

from PIL import Image  
import numpy as np
from models.networks import NGP
from models.rendering import render
from metrics import psnr

from tqdm import tqdm
from datasets import dataset_dict
from datasets.ray_utils import get_rays
from utils import load_ckpt
from train import depth2img
import imageio
import joblib
import timm

from datasets.opts import get_opts

# ��������������������� dist_pool ��������������������������������������� ������dist_pool.npy���������warm-star���������
from NES_GMM_forAT import NES_GMM_search
from NES_viewfool_forAT import NES_viewfool_search


args = get_opts()
@torch.no_grad()
def render_image(all_args, labels, objects, is_over=False, split='train'):
    """
    调用渲染函数 从viewpoints渲染一批图像
    Args:
        all_args: viewpoints array(batchsize, 6)
        labels: 每列viewpoint属于的类别号 array(batchszie, 1)
        batch_size: 每列viewpoint属于的类别中的物体序号 array(batchszie, 1)

    Returns: a batch of adversarial viewpoint rendering images

    ./ckpt/nerf/ 存放着所有物体的nerf权重
    -----------
    /913/00.pt
    /913/01.pt
    ... ... ...
    /913/09.pt
    -------------
    """

    dataset = dataset_dict['nerf_for_attack'](
        root_dir='/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog',
        split='AT', downsample=0.5, all_args=all_args, is_over=is_over
    )
    model = NGP(scale=0.5).cuda()
    
    # save_path = f'results/{args.dataset_name}/{args.scene_name}'
    # os.makedirs(save_path, exist_ok=True)
    imgs = np.zeros((len(dataset), 400, 400, 3))
    
    for img_idx in range(len(dataset)):
        
        ckpt_path = f'{args.ckpt_attack_path}/{split}/' + str('%02d' % int(labels[img_idx])) + '/' + str('%02d' % objects[img_idx]) + '.ckpt'
        load_ckpt(model, ckpt_path)

        rays_o, rays_d = get_rays(dataset.directions.cuda(), dataset[img_idx]['pose'].cuda())
        results = render(model, rays_o, rays_d,
                        **{'test_time': True,
                            'T_threshold': 1e-2
                            })
        torch.cuda.synchronize()
        #TS += time.time()-t
        pred = results['rgb'].reshape(dataset.img_wh[1], dataset.img_wh[0], 3).cpu().numpy()
        pred = (pred*255).astype(np.uint8)

        imgs[img_idx, :, :, :] = pred
        # if is_over:
        #     imageio.imwrite(os.path.join(save_path, f'{img_idx:03d}.png'), pred)

    return imgs


def AddBackground(render_imgs, clean_images, batch_size, split, flag='AT'):
    
    render_transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize(args.crop_size),
            transforms.ToTensor(),
        ])

    render_imgs_ = torch.zeros([len(render_imgs), 3, args.crop_size, args.crop_size])
    for i in range(len(render_imgs)):
        a = np.uint8(render_imgs[i,:,:,:])
        render_imgs_[i,:,:,:] = render_transform(a)
        #--------------------------------------------------------------------#
        # save = render_imgs_[i,:,:,:].numpy()
        # save = np.transpose(save, (1,2,0))
        # save = (save*255).astype(np.uint8)
        # # print(save)
        # # print(save.shape)
        # imageio.imwrite(os.path.join('./results', f'{i:03d}.png'), save)
        #--------------------------------------------------------------------#
        
    if split == 'train' and not args.no_background and flag == 'AT':
        for i in range(batch_size):
            background = torch.squeeze(clean_images[np.random.randint(low=0, high=batch_size, size=1),:,:,:])
            render = render_imgs_[i, :, :, :]
            # print('background',background.size())
            # print('render', render_imgs_[i, :, :, :].size())
            
            for h in range(args.crop_size):
                for w in range(args.crop_size):
                    if render[0, h, w]>0.95:
                        render_imgs_[i, :, h, w] = background[:, h, w]
        #--------------------------------------------------------------------#
    # save = render_imgs_[i,:,:,:].numpy()
    # save = np.transpose(save, (1,2,0))
    # save = (save*255).astype(np.uint8)
    # # print(save)
    # # print(save.shape)
    # imageio.imwrite(os.path.join('./results', f'{i:03d}.png'), save)
        #--------------------------------------------------------------------#
                    
    # Normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    # for i in range(len(render_imgs)):
    #     render_imgs_[i,:,:,:] = Normalize(render_imgs_[i,:,:,:])

    return render_imgs_


def GMSampler(dist_pool_mu, dist_pool_sigma, batch_size, clean_imgs=None, split='train', flag='AT'):
    args = get_opts()
    """
    从对应类别的混合高斯分布池中采样视角参数，并生成对应的渲染对抗样本
    Args:
        label: a batch of true label
        dist_pool: The uploaded GM distribution pool
        batch_size: num of adversarial viewpoint renderings

    Returns: a batch of adversarial viewpoint rendering images

    """
    """
    dist_pool以四维数组形式存储 m为标签（数字表示） 后三维为对应的 n*k*6矩阵(n为每个物体设置采集的分布数,k为一个分布的分量数)
    
    dist_pool_mu: array(m,n,k,6)
    dist_pool_sigma: array(m,n,k,6)
    dist_pool_omiga: array(m,n,k,6) // omiga = 1.0/K
    """
    M = dist_pool_mu.shape[0]
    # N = dist_pool_mu.shape[1]
    k = dist_pool_mu.shape[2]

    if split == 'train':
        ckpt_path = f'{args.ckpt_attack_path}/train/'
    else:
        ckpt_path = f'{args.ckpt_attack_path}/test/'

    label_list = os.listdir(ckpt_path)
    label_list.sort()

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])

    a = [30, 180, 70, 1.0, 0.5, 0.5]
    b = [0, 0, 0, 4.0, 0, 0]
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)
        # if args.share_dist:
        #     mu = dist_pool_mu[label_idx[i], 0, :, :].squeeze()
        #     sigma = dist_pool_sigma[label_idx[i], 0, :, :].squeeze()
        # else:
        if args.share_dist:  # 分布共享策略，将以0.5的概率抽到物体本身分布，其余0.5概率随机选择剩下的分布共享 
            num_self = np.random.random(size=1)
            if num_self < 1-args.share_dist_rate:
                n_choice = n_idx
            else:
                n_choice = np.random.randint(low=0, high=N, size=1)
        else:
            n_choice = n_idx

        mu = dist_pool_mu[label_idx[i], n_choice, :, :].squeeze()
        sigma = dist_pool_sigma[label_idx[i], n_choice, :, :].squeeze()

        F = np.random.choice(a=np.arange(k), size=6, replace=True, p=np.ones(k)/k)
        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            L = int(F[j])
            if args.num_k == 1:
                sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[j], scale=sigma[j], size=1))+b[j]
            else:
                sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[L, j], scale=sigma[L, j], size=1))+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs, split=split) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split, flag=flag)

    return  render_imgs, labels



def ViewFoolSampler(dist_pool_mu, dist_pool_sigma, batch_size, clean_imgs=None, split='train', flag='AT', only_center=True):
    args = get_opts()
    """
    执行ViewFool攻击后，从单高斯分布中采样，并生成对应的渲染对抗样本
    Args:
        label: a batch of true label
        dist_pool: The uploaded GM distribution pool
        batch_size: num of adversarial viewpoint renderings

    Returns: a batch of adversarial viewpoint rendering images

    """
    """
    viewfool 的dist_pool以三维数组形式存储 m为标签（数字表示） 后二维为对应的 n*6矩阵(n为每个物体设置采集的分布数,k为一个分布的分量数)
    
    dist_pool_mu: array(m,n,6)
    dist_pool_sigma: array(m,n,6)
    """
    M = dist_pool_mu.shape[0]
    # N = dist_pool_mu.shape[1]

    if split == 'train':
        ckpt_path = f'{args.ckpt_attack_path}/train/'
    else:
        ckpt_path = f'{args.ckpt_attack_path}/test/'

    label_list = os.listdir(ckpt_path)
    label_list.sort()

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])

    a = [30, 180, 70, 1.0, 0.5, 0.5]
    b = [0, 0, 0, 4.0, 0, 0]
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)
        mu = dist_pool_mu[label_idx[i], n_idx, :].squeeze()
        sigma = dist_pool_sigma[label_idx[i], n_idx, :].squeeze()
        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            if only_center:
                sample[j] = a[j]*np.tanh(mu[j])+b[j]
            else:
                sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[j], scale=sigma[j], size=1))+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs, split=split) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split, flag=flag)

    return  render_imgs, labels


def RandomSampler(batch_size, clean_imgs=None, split='train', mood='eval', random_type='full'):
    args = get_opts()
    ckpt_path = f'{args.ckpt_attack_path}/{split}/'
    label_list = os.listdir(ckpt_path)
    label_list.sort()
    M = len(label_list)

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])
       

    if random_type=='side': 
        a = [0, 360, -10, 2.0, 1.0, 1.0]
        b = [0, -180, 70, 3.0, -0.5, -0.5]
    elif random_type=='up':
        a = [0, 360, -30, 2.0, 1.0, 1.0]
        b = [0, -180, 15, 3.0, -0.5, -0.5]
    elif random_type=='2D-trans':
        a = [0, 0, -30, 2.0, 1.0, 1.0]
        b = [0, 0, 15, 3.0, -0.5, -0.5]
    elif random_type=='full':
        a = [60, 360, 140, 2.0, 1.0, 1.0]
        b = [-30, -180, -70, 3.0, -0.5, -0.5]

    # a = [0, 360, -10, 2.0, 1.0, 1.0]
    # b = [0, -180, 70, 3.0, -0.5, -0.5]
    
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)

        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            sample[j] = a[j]*np.random.random(1)+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split)

    return  render_imgs, labels


# ------------------------------------------------------------------------------------------------------------- #


# settings
model_dir = args.model_dir
if not os.path.exists(model_dir):
    os.makedirs(model_dir)
use_cuda = not args.no_cuda and torch.cuda.is_available()
torch.manual_seed(args.seed)
device = torch.device("cuda" if use_cuda else "cpu")
gpus = [0, 1]
# gpus = [0, 1, 2, 3]

kwargs = {'num_workers': 10*len(gpus), 'pin_memory': True} if use_cuda else {}

# blck_box_model

def get_black_model(model_name):

    if model_name == 'resnet50':
        model = torchvision.models.resnet50(pretrained=False)
        checkpoint = '/hy-tmp/VIAT/model-imagenet-100-ckpts/model-res50-epoch120.pt'
        #----------------------------------------------
        num_ftr = model.fc.in_features
        model.fc = nn.Linear(num_ftr,100)
        #----------------------------------------------

    if model_name == 'inc-v3':
        model = torchvision.models.inception_v3(pretrained=False)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-inc-v3-inc-v3_pre_train-epoch120.pt'
        #----------------------------------------------
        num_ftr = model.fc.in_features
        model.fc = nn.Linear(num_ftr,100)
        #----------------------------------------------
    
    if model_name == 'dense':
        model = torchvision.models.densenet121(pretrained=False)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-dense-dense_pre_train-epoch120.pt'
        #----------------------------------------------
        num_ftr = model.classifier.in_features
        model.classifier = nn.Linear(num_ftr, 100)
        #----------------------------------------------

    if model_name == 'inc-res':
        model = timm.create_model('inception_resnet_v2', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-inc-res-inc-res_pre_train-epoch120.pt'

    if model_name == 'en':
        model = timm.create_model('efficientnet_b0', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-en-en_pre_train-epoch120.pt'

    if model_name == 'vit-b':
        model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-vit-b-vit-b_pre_train-epoch10.pt'

    if model_name == 'deit-b':
        model = timm.create_model('deit_base_patch16_224', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-deit-b-deit-b_pre_train-epoch10.pt'

    if model_name == 'swin-b':
        model = timm.create_model('swin_base_patch4_window7_224', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-swin-b-swin-b_pre_train-epoch10.pt'


    model.load_state_dict(torch.load(checkpoint))
    model = model.to(device)
    model = torch.nn.DataParallel(model, device_ids=gpus, output_device=gpus[0])
    model.eval()

    return model
    



def eval_GMFool(model, device):
    model.eval()

    NES_GMM_search(model, dist_pool_mu=None, dist_pool_sigma=None, mood='eval_test')
    dist_pool_mu_test = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}_eval_test.npy')
    dist_pool_sigma_test = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}_eval_test.npy')

    train_loss = 0
    correct = 0
    data_num = 0

    with torch.no_grad():
        for i in range(10):
            data, target = GMSampler(dist_pool_mu_test, dist_pool_sigma_test, args.batch_size, split='test')
            data, target = data.to(device), target.to(device)
            data_num += len(data)
                
            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
        train_loss /= data_num

    print('GMFool to {}: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(
        args.treat_model, train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num
    
    return train_loss

def eval_viewfool(model, device, only_center):
    model.eval()

    NES_viewfool_search(model, mood='test')
    dist_pool_mu_test = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}_viewfool_test.npy')
    dist_pool_sigma_test = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}_viewfool_test.npy')

    train_loss = 0
    correct = 0
    data_num = 0
        
    with torch.no_grad():
        for i in range(10):
            data, target = ViewFoolSampler(dist_pool_mu_test, dist_pool_sigma_test, args.batch_size, split='test', only_center=only_center)
            data, target = data.to(device), target.to(device)
            data_num += len(data)
                
            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
        train_loss /= data_num

    print('ViewFool to {}: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(
        args.treat_model, train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num
    
    return train_loss


def eval_random(model, device, random_type='full'):
    model.eval()

    train_loss = 0
    correct = 0
    data_num = 0

    with torch.no_grad():
        for i in range(10):
            data, target = RandomSampler(args.batch_size, split='train', random_type=random_type)
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('Random {} to {}: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(random_type,
        args.treat_model, train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num
    
    return train_loss


#----------------------------------------------------------------------------------------------------------#

def main():

    # init white_box_model

    if args.treat_model == 'resnet50':
        model = torchvision.models.resnet50(pretrained=False)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-res50-epoch120.pt'
        #----------------------------------------------
        num_ftr = model.fc.in_features
        model.fc = nn.Linear(num_ftr,100)
        #----------------------------------------------

    if args.treat_model == 'inc-v3':
        model = torchvision.models.inception_v3(pretrained=False)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-inc-v3-inc-v3_pre_train-epoch120.pt'
        #----------------------------------------------
        num_ftr = model.fc.in_features
        model.fc = nn.Linear(num_ftr,100)
        #----------------------------------------------
    
    if args.treat_model == 'vit-b':
        model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-vit-b-vit-b_pre_train-epoch10.pt'

    if args.treat_model == 'dense':
        model = torchvision.models.densenet121(pretrained=False)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-dense-dense_pre_train-epoch120.pt'
        #----------------------------------------------
        num_ftr = model.classifier.in_features
        model.classifier = nn.Linear(num_ftr, 100)
        #----------------------------------------------

    if args.treat_model == 'inc-res':
        model = timm.create_model('inception_resnet_v2', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-inc-res-inc-res_pre_train-epoch120.pt'

    if args.treat_model == 'en':
        model = timm.create_model('efficientnet_b0', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-en-en_pre_train-epoch120.pt'

    if args.treat_model == 'deit-b':
        model = timm.create_model('deit_base_patch16_224', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-deit-b-deit-b_pre_train-epoch10.pt'

    if args.treat_model == 'swin-b':
        model = timm.create_model('swin_base_patch4_window7_224', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-swin-b-swin-b_pre_train-epoch10.pt'

    
    model.load_state_dict(torch.load(checkpoint))
    model = model.to(device)
    model = torch.nn.DataParallel(model, device_ids=gpus, output_device=gpus[0])

    #GMVFool:
    print('================================================================')
    # eval_GMFool(model, device) # GMVFool
    eval_viewfool(model, device, only_center=True)
    print('================================================================')



if __name__ == '__main__':
    main()

--- 文件地址: viat/NES.py ---
import numpy as np
from evaluate import comput_fitness
from rendering_image import render_image
# from classifier.predict import test_baseline
from tqdm import tqdm
from datasets.opts import get_opts
import joblib
import torch

import os
import sys
current_directory = os.path.dirname(os.path.abspath(__file__))
root_path = os.path.abspath(os.path.dirname(current_directory) + os.path.sep + ".")
sys.path.append(root_path)
import classifier.predict #父级文件内的文件名字，去掉.py
from classifier.predict import test_baseline #从文件中导入类


def compute_ranks(x):
  """
  Returns ranks in [0, len(x))
  Note: This is different from scipy.stats.rankdata, which returns ranks in [1, len(x)].
  (https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/es.py)
  """
  assert x.ndim == 1
  ranks = np.empty(len(x), dtype=int)
  ranks[x.argsort()] = np.arange(len(x))
  return ranks

def compute_centered_ranks(x):
  """
  https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/es.py
  """
  y = compute_ranks(x.ravel()).reshape(x.shape).astype(np.float32)
  y /= (x.size - 1)
  y -= .5
  return y

def compute_normalize(x):
  mean = np.mean(x)
  var = np.var(x)
  y = x-mean/var
  return y

def compute_weight_decay(weight_decay, model_param_list):
  model_param_grid = np.array(model_param_list)
  return - weight_decay * np.mean(model_param_grid * model_param_grid, axis=1)

# adopted from:
# https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/optimizers.py

class Optimizer(object):
  def __init__(self, pi, epsilon=1e-08):
    self.pi = pi
    self.dim = pi.num_params
    self.epsilon = epsilon
    self.t = 0

  def update(self, globalg):
    self.t += 1
    step = self._compute_step(globalg)
    theta = self.pi.mu
    ratio = np.linalg.norm(step) / (np.linalg.norm(theta) + self.epsilon)
    self.pi.mu = theta + step
    return ratio

  def _compute_step(self, globalg):
    raise NotImplementedError


class BasicSGD(Optimizer):
  def __init__(self, pi, stepsize):
    Optimizer.__init__(self, pi)
    self.stepsize = stepsize

  def _compute_step(self, globalg):
    step = -self.stepsize * globalg
    return step

class SGD(Optimizer):
  def __init__(self, pi, stepsize, momentum=0.9):
    Optimizer.__init__(self, pi)
    self.v = np.zeros(self.dim, dtype=np.float32)
    self.stepsize, self.momentum = stepsize, momentum

  def _compute_step(self, globalg):
    self.v = self.momentum * self.v + (1. - self.momentum) * globalg
    step = -self.stepsize * self.v
    return step


class Adam(Optimizer):
  def __init__(self, pi, stepsize, beta1=0.99, beta2=0.999):
    Optimizer.__init__(self, pi)
    self.stepsize = stepsize
    self.beta1 = beta1
    self.beta2 = beta2
    self.m = np.zeros(self.dim, dtype=np.float32)
    self.v = np.zeros(self.dim, dtype=np.float32)

  def _compute_step(self, globalg):
    a = self.stepsize * np.sqrt(1 - self.beta2 ** self.t) / (1 - self.beta1 ** self.t)
    self.m = self.beta1 * self.m + (1 - self.beta1) * globalg
    self.v = self.beta2 * self.v + (1 - self.beta2) * (globalg * globalg)
    step = -a * self.m / (np.sqrt(self.v) + self.epsilon)
    return step


class PEPG:
  '''Extension of PEPG with bells and whistles.'''

  def __init__(self, num_params,  # number of model parameters
               sigma_init=0.10,  # initial standard deviation
               sigma_alpha=0.20,  # learning rate for standard deviation
               sigma_decay=0.999,  # anneal standard deviation
               sigma_limit=0.01,  # stop annealing if less than this
               sigma_max_change=0.2,  # clips adaptive sigma to 20%
               sigma_min=0.05,  # 允许的最小sigma
               sigma_update=True,
               learning_rate=0.01,  # learning rate for standard deviation
               learning_rate_decay=0.9999,  # annealing the learning rate
               learning_rate_limit=0.01,  # stop annealing learning rate
               elite_ratio=0,  # if > 0, then ignore learning_rate
               popsize=256,  # population size
               average_baseline=True,  # set baseline to average of batch
               weight_decay=0.01,  # weight decay coefficient
               rank_fitness=True,  # use rank rather than fitness numbers
               forget_best=True,
               mu_lambda=0.0001,
               sigma_lambda=0.0001):  # don't keep the historical best solution

    self.num_params = num_params
    self.sigma_init = sigma_init
    self.sigma_alpha = sigma_alpha
    self.sigma_decay = sigma_decay
    self.sigma_limit = sigma_limit
    self.sigma_max_change = sigma_max_change
    self.learning_rate = learning_rate
    self.learning_rate_decay = learning_rate_decay
    self.learning_rate_limit = learning_rate_limit
    self.popsize = popsize
    self.average_baseline = average_baseline
    self.sigma_update = sigma_update
    self.sigma_min = sigma_min
    self.mu_lamba = mu_lambda
    self.sigma_lamba = sigma_lambda

    if self.average_baseline:
      assert (self.popsize % 2 == 0), "Population size must be even"
      self.batch_size = int(self.popsize / 2)
    else:
      assert (self.popsize & 1), "Population size must be odd"
      self.batch_size = int((self.popsize - 1) / 2)

    # option to use greedy es method to select next mu, rather than using drift param
    self.elite_ratio = elite_ratio
    self.elite_popsize = int(self.popsize * self.elite_ratio)
    self.use_elite = False
    if self.elite_popsize > 0:
      self.use_elite = True

    self.forget_best = forget_best
    self.batch_reward = np.zeros(self.batch_size * 2)
    self.mu = np.zeros(self.num_params)
    self.sigma = np.ones(self.num_params) * self.sigma_init
    self.curr_best_mu = np.zeros(self.num_params)
    self.best_mu = np.zeros(self.num_params)
    self.best_reward = 0
    self.first_interation = True
    self.weight_decay = weight_decay
    self.rank_fitness = rank_fitness
    if self.rank_fitness:
      self.forget_best = True  # always forget the best one if we rank
    # choose optimizer
    self.optimizer = SGD(self, learning_rate)

  def rms_stdev(self):
    sigma = self.sigma
    return np.mean(np.sqrt(sigma * sigma))

  def ask(self):
    '''returns a list of parameters'''
    # antithetic sampling
    self.epsilon = np.random.randn(self.batch_size, self.num_params) * self.sigma.reshape(1, self.num_params)
    self.epsilon_full = np.concatenate([self.epsilon, - self.epsilon])
    if self.average_baseline:
      epsilon = self.epsilon_full
    else:
      # first population is mu, then positive epsilon, then negative epsilon
      epsilon = np.concatenate([np.zeros((1, self.num_params)), self.epsilon_full])
      self.r = epsilon/self.sigma.reshape(1, self.num_params)
    solutions = self.mu.reshape(1, self.num_params) + epsilon
    self.solutions = solutions
    return solutions

  def comput_entropy(self):
    # 计算每个批次的高斯分布的熵
    r = torch.Tensor(self.r)  # N(0,1)中的采样点
    sigma = torch.Tensor(self.sigma)
    sigma.requires_grad = True
    mu = torch.Tensor(self.mu)
    mu.requires_grad = True
    a = torch.Tensor([60, 180, 60, 1, 0.7, 0.7])    # 各个参数的前系数


    inside = 1-torch.pow(torch.tanh(mu+sigma*r), 2)+1e-8
    neg_logp = torch.log(sigma+1e-8) + 1/2*torch.pow(r, 2) + torch.log(inside)
    entropy = torch.sum(neg_logp, 0)/self.popsize
    print('entropy:\n', entropy)
    Entropy = torch.sum(entropy)

    # 得到的Entropy是当前种群所有参数熵的总和

    # 梯度反向传播
    Entropy.backward()
    # 对于sigma，求这一批次中，每个参数的梯度之和作为这个参数的搜索方向 （11,6）->(1,6)
    # 对于mu，先求出（11,1）的熵，再将每个mu（1,6）对（11,1）的每列求导 得到 （11,6）的梯度
    mu_entropy_grad = mu.grad.clone()
    sigma_entropy_grad = sigma.grad.clone()
    # 梯度清零
    mu.grad.data.zero_()
    sigma.grad.data.zero_()
    print("Entropy：\n", Entropy)
    self.entropy = Entropy

    return mu_entropy_grad.cpu().detach().numpy(), sigma_entropy_grad.cpu().detach().numpy()





  def tell(self, reward_table_result, mu_entropy_grad, sigma_entropy_grad):
    # input must be a numpy float array
    assert (len(reward_table_result) == self.popsize), "Inconsistent reward_table size reported."

    reward_table = np.array(reward_table_result)

    if self.rank_fitness:
      reward_table = compute_centered_ranks(reward_table)
      # reward_table = compute_normalize(reward_table)

    if self.weight_decay > 0:
      l2_decay = compute_weight_decay(self.weight_decay, self.solutions)
      reward_table += l2_decay

    reward_offset = 1
    if self.average_baseline:
      b = np.mean(reward_table)
      reward_offset = 0
    else:
      b = reward_table[0]  # baseline

    reward = reward_table[reward_offset:]
    if self.use_elite:
      idx = np.argsort(reward)[::-1][0:self.elite_popsize]
    else:
      idx = np.argsort(reward)[::-1]

    best_reward = reward[idx[0]]
    if (best_reward > b or self.average_baseline):
      best_mu = self.mu + self.epsilon_full[idx[0]]
      best_reward = reward[idx[0]]
    else:
      best_mu = self.mu
      best_reward = b

    self.curr_best_reward = best_reward
    self.curr_best_mu = best_mu

    if self.first_interation:
      self.sigma = np.ones(self.num_params) * self.sigma_init
      self.first_interation = False
      self.best_reward = self.curr_best_reward
      self.best_mu = best_mu
    else:
      if self.forget_best or (self.curr_best_reward > self.best_reward):
        self.best_mu = best_mu
        self.best_reward = self.curr_best_reward

    # short hand
    epsilon = self.epsilon
    sigma = self.sigma

    # update the mean

    # move mean to the average of the best idx means
    if self.use_elite:
      self.mu += self.epsilon_full[idx].mean(axis=0)
    else:
      rT = (reward[:self.batch_size] - reward[self.batch_size:])
      change_mu = np.dot(rT, epsilon) + self.mu_lamba*mu_entropy_grad
      #print('rt:\n', rT)
      #print('epsilon', epsilon)
      print('mu-loss1:', np.dot(rT, epsilon))
      print('mu-loss2:', self.mu_lamba*mu_entropy_grad)

      self.optimizer.stepsize = self.learning_rate
      update_ratio = self.optimizer.update(-change_mu)  # adam, rmsprop, momentum, etc.
      # self.mu += (change_mu * self.learning_rate) # normal SGD method

    # adaptive sigma
    # normalization
    
    #if (self.sigma[a] > self.sigma_min for a in range(self.num_params)):
    if (self.sigma_alpha > 0 and self.sigma_update):
      stdev_reward = 1.0
      if not self.rank_fitness:
        stdev_reward = reward.std()
      S = ((epsilon * epsilon - (sigma * sigma).reshape(1, self.num_params)) / sigma.reshape(1, self.num_params))
      reward_avg = (reward[:self.batch_size] + reward[self.batch_size:]) / 2.0
      rS = reward_avg - b

      delta_sigma = (np.dot(rS, S)) / (2 * self.batch_size * stdev_reward)

      # adjust sigma according to the adaptive sigma calculation
      # for stability, don't let sigma move more than 10% of orig value
      change_sigma = self.sigma_alpha * (delta_sigma + self.sigma_lamba*sigma_entropy_grad)

      print('sigma-loss1:', delta_sigma)
      print('sigma-loss2:', self.sigma_lamba*sigma_entropy_grad)

      change_sigma = np.minimum(change_sigma, self.sigma_max_change * self.sigma)
      change_sigma = np.maximum(change_sigma, - self.sigma_max_change * self.sigma)
      self.sigma += change_sigma
      self.sigma = np.clip(self.sigma, 0.0, 0.15)

      if (self.sigma_decay < 1):
        self.sigma[self.sigma > self.sigma_limit] *= self.sigma_decay

    if (self.learning_rate_decay < 1 and self.learning_rate > self.learning_rate_limit):
      self.learning_rate *= self.learning_rate_decay

  def current_param(self):
    return self.curr_best_mu

  def set_mu(self, mu):
    self.mu = np.array(mu)

  def best_param(self):
    return self.best_mu

  def result(self):  # return best params so far, along with historically best reward, curr reward, sigma
    return (self.best_mu, self.best_reward, self.curr_best_reward, self.sigma)





def NES_search():
  args = get_opts()
  search_num = args.search_num

  # 搜索三维空间，th phi r
  if search_num == 3:

    MAX_ITERATION = args.iteration
    POPSIZE = args.popsize
    NUM_PARAMS = 3
    solver = PEPG(num_params=NUM_PARAMS,                         # number of model parameters
              sigma_init=0.15,                  # initial standard deviation
              learning_rate=0.1,               # learning rate for standard deviation
              learning_rate_decay=0.999,       # don't anneal the learning rate
              popsize=POPSIZE,             # population size
              average_baseline=False,          # set baseline to average of batch
              weight_decay=0.00,             # weight decay coefficient
              rank_fitness=False,           # use rank rather than fitness numbers
              forget_best=False)

    history = []
    history_best_solution = []
    for j in range(MAX_ITERATION):
      solutions = solver.ask()
      # th (-180,180)
      solutions[:, 0] = 180 * np.tanh(solutions[:, 0])
      # phi (180, 0)
      solutions[:, 1] = 45 * np.tanh(solutions[:, 2]) - 90
      # r (4, 6)
      solutions[:, 2] = np.tanh(solutions[:, 2]) + 4

      fitness_list = np.zeros(solver.popsize)
      for i in tqdm(range(solver.popsize)):
        fitness_list[i] = comput_fitness(solutions[i])
      solver.tell(fitness_list)
      result = solver.result()  # first element is the best solution, second element is the best fitness

      history.append(result[1])
      max_idx = np.argmax(fitness_list)
      history_best_solution.append(solutions[max_idx])
      if (j + 1) % 1 == 0:
        print("fitness at iteration", (j + 1), result[1])
      # print('fitness_list', fitness_list)

    max_idx_ = 0
    '问题：下次迭代的不一定是最好的，如果最好值没变化，要记录之前的'
    for i in range(len(history)-1):
      if history[i+1] > history[i]:
        max_idx_ = i+1
      else:
        continue

    best_solutions = history_best_solution[max_idx_]

    result[0][0] = 180 * np.tanh(result[0][0])
    result[0][1] = 45 * np.tanh(result[0][1]) - 90
    result[0][2] = np.tanh(result[0][2]) + 4

    print('local optimum discovered by solver(best mu):\n th: {:.16f},th: {:.16f},th: {:.16f}'.format(result[0][0], result[0][1], result[0][2]))
    print('local optimum discovered by solver(best solution):\n th: {:.16f},th: {:.16f},th: {:.16f}'.format(best_solutions[0], best_solutions[1], best_solutions[2]))
    print("fitness score at this local optimum: ", result[1])


    "验证"
    x = render_image(th=best_solutions[0], phi=best_solutions[1], r=best_solutions[2])
    test_baseline(path="C:/Users/Silvester/PycharmProjects/NeRFAttack/NeRF/results/blender_for_attack/'hotdog'/",
                  label='hotdog, hot dog, red hot')

  if search_num == 6:

    MAX_ITERATION = args.iteration
    POPSIZE = args.popsize
    NUM_PARAMS = 6
    N_JOBS = 3
    # 搜索六维空间，th phi gamma r x y
    solver = PEPG(num_params=NUM_PARAMS,  # number of model parameters
                  sigma_init=0.1,  # initial standard deviation
                  sigma_update=True,  # 不大幅更新sigma
                  learning_rate=0.1,  # learning rate for standard deviation
                  learning_rate_decay=0.99,
                  learning_rate_limit=0,  # don't anneal the learning rate
                  popsize=POPSIZE,  # population size
                  average_baseline=False,  # set baseline to average of batch
                  weight_decay=0.00,  # weight decay coefficient
                  rank_fitness=True,  # use rank rather than fitness numbers
                  forget_best=False,
                  mu_lambda=args.mu_lamba,
                  sigma_lambda=args.sigma_lamba
                  )

    logging = {'mu': [], 'sigma': [], 'fitness': [], 'entropy':[]}
    history = []
    fitness_origin = []
    history_best_solution = []
    for j in tqdm(range(MAX_ITERATION)):
      solutions = solver.ask()
      mu_entropy_grad, sigma_entropy_grad = solver.comput_entropy()

      # gamma (-30,30)
      solutions[:, 0] = 30 * np.tanh(solutions[:, 0])
      # th (-180,180)
      solutions[:, 1] = 180 * np.tanh(solutions[:, 1])
      # phi (-70, 70)
      solutions[:, 2] = 70 * np.tanh(solutions[:, 2])
      # r (3, 5)
      solutions[:, 3] = np.tanh(solutions[:, 3]) + 4
      # x (-0.5, 0.5)
      solutions[:, 4] = 0.5 * np.tanh(solutions[:, 4])
      # x (-0.5, 0.5)
      solutions[:, 5] = 0.5 * np.tanh(solutions[:, 5])

      fitness_list = np.zeros(solver.popsize)


      #  多进程工作
      # with joblib.Parallel(n_jobs=N_JOBS) as parallel:
      #   #for i in tqdm(range(solver.popsize)):
      #     #fitness_list[i] = comput_fitness(solutions[i])

      #   fitness_list = parallel(joblib.delayed(comput_fitness)(solutions[i], solver.sigma) for i in tqdm(range(solver.popsize)))

      fitness_list = comput_fitness(solutions)

      solver.tell(fitness_list, mu_entropy_grad, sigma_entropy_grad)
      result = solver.result()  # first element is the best solution, second element is the best fitness

      history.append(result[1])
      fitness_origin.append(np.max(fitness_list))
      average_fitness = np.mean(fitness_list)


      max_idx = np.argmax(fitness_list)
      history_best_solution.append(solutions[max_idx])
      if (j + 1) % 1 == 0:
        print("fitness at iteration\n", (j + 1), max(fitness_origin))
        print("average fitness at iteration\n", (j + 1), average_fitness)
        print("sigma at iteration\n", (j + 1), result[3])
        print("mu at iteration\n", (j + 1), result[0])

        # 写入日志数据
        logging['fitness'].append(result[1])
        logging['sigma'].append(result[3])
        logging['mu'].append(result[0])
        logging['entropy'].append(solver.entropy)
      # print('fitness_list', fitness_list)

      #if average_fitness > -0.25:
        #break
        

    max_idx_ = 0
    '问题：下次迭代的不一定是最好的，如果最好值没变化，要记录之前的'
    for i in range(len(history) - 1):
      if history[i + 1] > history[i]:
        max_idx_ = i + 1
      else:
        continue

    best_solutions = history_best_solution[max_idx_]

    # 输出sigma和mu的在tanh后的采样值
    random = np.zeros([args.num_sample+1, 6])
    gamma = np.random.normal(loc=result[0][0], scale=result[3][0], size=args.num_sample)
    th = np.random.normal(loc=result[0][1], scale=result[3][1], size=args.num_sample)
    phi = np.random.normal(loc=result[0][2], scale=result[3][2], size=args.num_sample)
    r = np.random.normal(loc=result[0][3], scale=result[3][3], size=args.num_sample)
    a = np.random.normal(loc=result[0][4], scale=result[3][4], size=args.num_sample)
    b = np.random.normal(loc=result[0][5], scale=result[3][5], size=args.num_sample)
    # 000为中心值对应的图像
    gamma = np.append(gamma, result[0][0])
    th = np.append(th, result[0][1])
    phi = np.append(phi, result[0][2])
    r = np.append(r, result[0][3])
    a = np.append(a, result[0][4])
    b = np.append(b, result[0][5])
    

    random[:, 0] = 30 * np.tanh(gamma)
    random[:, 1] = 180 * np.tanh(th)
    random[:, 2] = 70 * np.tanh(phi)
    random[:, 3] = np.tanh(r) + 4.0
    random[:, 4] = 0.5 * np.tanh(a)
    random[:, 5] = 0.5 * np.tanh(b)
    mu = random.mean(axis=0)
    var = (random - mu).T @ (random - mu) / random.shape[0]
    var = np.sqrt(np.diagonal(var))  # this is slightly suboptimal, but instructive
    print('final sigma after tanh（角度方差）', var)

    mu = np.zeros([6])
    mu[0] = 30 * np.tanh(result[0][0])
    mu[1] = 180 * np.tanh(result[0][1])
    mu[2] = 70 * np.tanh(result[0][2])
    mu[3] = np.tanh(result[0][3]) + 4.0
    mu[4] = 0.5 * np.tanh(result[0][4])
    mu[5] = 0.5 * np.tanh(result[0][5])

    print('final mu after tanh（角度中心值）', mu)

    np.save('logging_test4.npy', logging)
    
    "渲染100张该分布下的图像"
    print('begin render 100 images in current adv-distribution')
    print('--------------------------------------------------')
    render_image(random, is_over=True)

    "验证准确率"
    print('begin test the accuracy')
    print('--------------------------------------------------')
    path =path = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/run_GMM/results/nerf_for_attack/' + args.scene_name + '/'
    test_baseline(path=path, label=args.label_name, model='resnet')

    print('entropy')
    print('--------------------------------------------------')
    print(solver.entropy)


    print('no.100 the mean img')
    print('--------------------------------------------------')
    path = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/run_GMM/results/nerf_for_attack/' + args.scene_name + '/'
    test_baseline(path=path, label=args.label_name, model='resnet', is_mean=True)


    #x = render_image(best_solutions)
    #test_baseline(path="C:/Users/Silvester/PycharmProjects/NeRFAttack/NeRF/results/blender_for_attack/'hotdog'/",label='hotdog, hot dog, red hot')




  # 角度搜索
  if search_num == 123:

    MAX_ITERATION = args.iteration
    POPSIZE = args.popsize
    NUM_PARAMS = 3
    N_JOBS = 3
    max_stop_fitness = 6.0
    # 搜索六维空间，th phi gamma r x y
    solver = PEPG(num_params=NUM_PARAMS,  # number of model parameters
                  sigma_init=0.1,  # initial standard deviation
                  sigma_update=True,  # 不大幅更新sigma
                  learning_rate=0.1,  # learning rate for standard deviation
                  learning_rate_decay=0.99,
                  learning_rate_limit=0,  # don't anneal the learning rate
                  popsize=POPSIZE,  # population size
                  average_baseline=False,  # set baseline to average of batch
                  weight_decay=0.00,  # weight decay coefficient
                  rank_fitness=True,  # use rank rather than fitness numbers
                  forget_best=False,
                  mu_lambda=args.mu_lamba,
                  sigma_lambda=args.sigma_lamba
                  )

    logging = {'mu': [], 'sigma': [], 'fitness': [], 'entropy':[]}
    history = []
    fitness_origin = []
    history_best_solution = []
    for j in range(MAX_ITERATION):
      solutions = solver.ask()
      mu_entropy_grad, sigma_entropy_grad = solver.comput_entropy()
      solutions_ = np.zeros([POPSIZE, 6])

      # gamma (-60,60)
      solutions_[:, 0] = 30 * np.tanh(solutions[:, 0])
      # th (-180,180)
      solutions_[:, 1] = 180 * np.tanh(solutions[:, 1])
      # phi (-60, 60)
      solutions_[:, 2] = 70 * np.tanh(solutions[:, 2])

      # 固定位置参数为（4.0， 0， 0）

      # r (4, 6)
      solutions_[:, 3] = 4.0
      # x (-1, 1)
      solutions_[:, 4] = 0.0
      # x (-1, 1)
      solutions_[:, 5] = 0.0

      fitness_list = np.zeros(solver.popsize)


      #  多进程工作
      with joblib.Parallel(n_jobs=N_JOBS) as parallel:
        #for i in tqdm(range(solver.popsize)):
          #fitness_list[i] = comput_fitness(solutions[i])

        fitness_list = parallel(joblib.delayed(comput_fitness)(solutions_[i], solver.sigma) for i in tqdm(range(solver.popsize)))

      

      solver.tell(fitness_list, mu_entropy_grad, sigma_entropy_grad)
      result = solver.result()  # first element is the best solution, second element is the best fitness

      fitness_origin.append(np.max(fitness_list))
      history.append(result[1])
      average_fitness = np.mean(fitness_list)
      max_idx = np.argmax(fitness_list)
      history_best_solution.append(solutions[max_idx])
      if (j + 1) % 1 == 0:
        print("fitness at iteration\n", (j + 1), max(fitness_origin))
        print("average fitness at iteration\n", (j + 1), average_fitness)
        print("sigma at iteration\n", (j + 1), result[3])
        print("mu at iteration\n", (j + 1), result[0])

        # 写入日志数据
        logging['fitness'].append(result[1])
        logging['sigma'].append(result[3])
        logging['mu'].append(result[0])
        logging['entropy'].append(solver.entropy)
      # print('fitness_list', fitness_list)

      # 若达到搜索要求，则停止迭代
      #if average_fitness > max_stop_fitness:
        #break

    max_idx_ = 0
    '问题：下次迭代的不一定是最好的，如果最好值没变化，要记录之前的'
    for i in range(len(history) - 1):
      if history[i + 1] > history[i]:
        max_idx_ = i + 1
      else:
        continue

    best_solutions = history_best_solution[max_idx_]

    # 输出sigma和mu的在tanh后的采样值
    random = np.zeros([args.num_sample+1, 6])
    gamma = np.random.normal(loc=result[0][0], scale=result[3][0], size=args.num_sample)
    th = np.random.normal(loc=result[0][1], scale=result[3][1], size=args.num_sample)
    phi = np.random.normal(loc=result[0][2], scale=result[3][2], size=args.num_sample)

    gamma = np.append(gamma, result[0][0])
    th = np.append(th, result[0][1])
    phi = np.append(phi, result[0][2])


    random[:, 0] = 30 * np.tanh(gamma)
    random[:, 1] = 180 * np.tanh(th)
    random[:, 2] = 70 * np.tanh(phi)
    random[:, 3] = 4.0
    random[:, 4] = 0.0
    random[:, 5] = 0.0
    mu = random.mean(axis=0)
    var = (random - mu).T @ (random - mu) / random.shape[0]
    var = np.sqrt(np.diagonal(var))  # this is slightly suboptimal, but instructive
    print('final sigma after tanh（角度方差）', var)

    mu = np.zeros([6])
    mu[0] = 30 * np.tanh(result[0][0])
    mu[1] = 180 * np.tanh(result[0][1])
    mu[2] = 70 * np.tanh(result[0][2])
    mu[3] = 4.0
    mu[4] = 0.0
    mu[5] = 0.0

    print('final mu after tanh（角度中心值）', mu)

    "渲染100张该分布下的图像"
    print('begin render 100 images in current adv-distribution')
    print('--------------------------------------------------')
    render_image(random, is_over=True)

    "验证准确率"
    print('begin test the accuracy')
    print('--------------------------------------------------')
    path = '/HOME/scz1972/run/rsw_/NeRFAttack/run_NES_A/results/blender_for_attack/' + args.scene_name + '/'
    test_baseline(path=path, label=args.label_name, model='vit')

    print('no.100 the mean img')
    print('--------------------------------------------------')
    path = '/HOME/scz1972/run/rsw_/NeRFAttack/results/blender_for_attack/' + args.scene_name + '/'
    test_baseline(path=path, label=args.label_name, model='vit', is_mean=True)

    #x = render_image(best_solutions)
    #test_baseline(path="C:/Users/Silvester/PycharmProjects/NeRFAttack/NeRF/results/blender_for_attack/'hotdog'/",label='hotdog, hot dog, red hot')




# 位置搜索
  if search_num == 456:

    MAX_ITERATION = args.iteration
    POPSIZE = args.popsize
    NUM_PARAMS = 3
    N_JOBS = 3
    max_stop_fitness = 6.0
    # 搜索六维空间，th phi gamma r x y
    solver = PEPG(num_params=NUM_PARAMS,  # number of model parameters
                  sigma_init=0.1,  # initial standard deviation
                  sigma_update=True,  # 不大幅更新sigma
                  learning_rate=0.1,  # learning rate for standard deviation
                  learning_rate_decay=0.99,
                  learning_rate_limit=0,  # don't anneal the learning rate
                  popsize=POPSIZE,  # population size
                  average_baseline=False,  # set baseline to average of batch
                  weight_decay=0.00,  # weight decay coefficient
                  rank_fitness=True,  # use rank rather than fitness numbers
                  forget_best=False,
                  mu_lambda=args.mu_lamba,
                  sigma_lambda=args.sigma_lamba
                  )

    logging = {'mu': [], 'sigma': [], 'fitness': [], 'entropy':[]}
    history = []
    fitness_origin = []
    history_best_solution = []
    for j in range(MAX_ITERATION):
      solutions = solver.ask()
      mu_entropy_grad, sigma_entropy_grad = solver.comput_entropy()
      solutions_ = np.zeros([POPSIZE, 6])

      # gamma (-60,60)
      solutions_[:, 0] = 0.0
      # th (-180,180)
      solutions_[:, 1] = 0.0
      # phi (-60, 60)
      solutions_[:, 2] = 45.0

      # 固定位置参数为（4.0， 0， 0）

      # r (4, 6)
      solutions_[:, 3] = np.tanh(solutions[:, 0]) + 4
      # x (-1, 1)
      solutions_[:, 4] = 0.5 * np.tanh(solutions[:, 1])
      # x (-1, 1)
      solutions_[:, 5] = 0.5 * np.tanh(solutions[:, 2])

      fitness_list = np.zeros(solver.popsize)


      #  多进程工作
      with joblib.Parallel(n_jobs=N_JOBS) as parallel:
        #for i in tqdm(range(solver.popsize)):
          #fitness_list[i] = comput_fitness(solutions[i])

        fitness_list = parallel(joblib.delayed(comput_fitness)(solutions_[i], solver.sigma) for i in tqdm(range(solver.popsize)))

      solver.tell(fitness_list, mu_entropy_grad, sigma_entropy_grad)
      result = solver.result()  # first element is the best solution, second element is the best fitness

      fitness_origin.append(np.max(fitness_list))
      history.append(result[1])
      average_fitness = np.mean(fitness_list)
      max_idx = np.argmax(fitness_list)
      history_best_solution.append(solutions[max_idx])
      if (j + 1) % 1 == 0:
        print("fitness at iteration\n", (j + 1), max(fitness_origin))
        print("average fitness at iteration\n", (j + 1), average_fitness)
        print("sigma at iteration\n", (j + 1), result[3])
        print("mu at iteration\n", (j + 1), result[0])

        # 写入日志数据
        logging['fitness'].append(result[1])
        logging['sigma'].append(result[3])
        logging['mu'].append(result[0])
        logging['entropy'].append(solver.entropy)
      # print('fitness_list', fitness_list)

      # 若达到搜索要求，则停止迭代
      #if average_fitness > max_stop_fitness:
        #break

    max_idx_ = 0
    '问题：下次迭代的不一定是最好的，如果最好值没变化，要记录之前的'
    for i in range(len(history) - 1):
      if history[i + 1] > history[i]:
        max_idx_ = i + 1
      else:
        continue

    best_solutions = history_best_solution[max_idx_]

    # 输出sigma和mu的在tanh后的采样值
    random = np.zeros([args.num_sample+1, 6])
    r = np.random.normal(loc=result[0][0], scale=result[3][0], size=args.num_sample)
    a = np.random.normal(loc=result[0][1], scale=result[3][1], size=args.num_sample)
    b = np.random.normal(loc=result[0][2], scale=result[3][2], size=args.num_sample)

    r = np.append(r, result[0][0])
    a = np.append(a, result[0][1])
    b = np.append(b, result[0][2])


    random[:, 0] = 0.0
    random[:, 1] = 0.0
    random[:, 2] = 45.0
    random[:, 3] = np.tanh(r) + 4.0
    random[:, 4] = 0.5 * np.tanh(a)
    random[:, 5] = 0.5 * np.tanh(b)

    
    mu = random.mean(axis=0)
    var = (random - mu).T @ (random - mu) / random.shape[0]
    var = np.sqrt(np.diagonal(var))  # this is slightly suboptimal, but instructive
    print('final sigma after tanh（角度方差）', var)

    mu = np.zeros([6])
    mu[0] = 0.0
    mu[1] = 0.0
    mu[2] = 45.0
    mu[3] = np.tanh(result[0][0]) + 4.0
    mu[4] = 0.5 * np.tanh(result[0][1])
    mu[5] = 0.5 * np.tanh(result[0][2])

    print('final mu after tanh（角度中心值）', mu)

    "渲染100张该分布下的图像"
    print('begin render 100 images in current adv-distribution')
    print('--------------------------------------------------')
    render_image(random, is_over=True)

    "验证准确率"
    print('begin test the accuracy')
    print('--------------------------------------------------')
    path = '/HOME/scz1972/run/rsw_/NeRFAttack/run_NES_P/results/blender_for_attack/' + args.scene_name + '/'
    test_baseline(path=path, label=args.label_name, model='vit')

    print('no.100 the mean img')
    print('--------------------------------------------------')
    path = '/HOME/scz1972/run/rsw_/NeRFAttack/results/blender_for_attack/' + args.scene_name + '/'
    test_baseline(path=path, label=args.label_name, model='vit', is_mean=True)

    #x = render_image(best_solutions)
    #test_baseline(path="C:/Users/Silvester/PycharmProjects/NeRFAttack/NeRF/results/blender_for_attack/'hotdog'/",label='hotdog, hot dog, red hot')


  # 角度搜索
  if search_num == 1231:

    MAX_ITERATION = args.iteration
    POPSIZE = args.popsize
    NUM_PARAMS = 6
    N_JOBS = 3
    # 搜索六维空间，th phi gamma r x y
    solver = PEPG(num_params=NUM_PARAMS,  # number of model parameters
                  sigma_init=0.1,  # initial standard deviation
                  sigma_update=True,  # 不大幅更新sigma
                  learning_rate=0.1,  # learning rate for standard deviation
                  learning_rate_decay=0.99,
                  learning_rate_limit=0,  # don't anneal the learning rate
                  popsize=POPSIZE,  # population size
                  average_baseline=False,  # set baseline to average of batch
                  weight_decay=0.00,  # weight decay coefficient
                  rank_fitness=True,  # use rank rather than fitness numbers
                  forget_best=False,
                  mu_lambda=args.mu_lamba,
                  sigma_lambda=args.sigma_lamba
                  )

    logging = {'mu': [], 'sigma': [], 'fitness': [], 'entropy':[]}
    history = []
    fitness_origin = []
    history_best_solution = []
    for j in range(MAX_ITERATION):
      solutions = solver.ask()
      mu_entropy_grad, sigma_entropy_grad = solver.comput_entropy()

      # gamma (-30,30)
      solutions[:, 0] = args.gamma_size * np.tanh(solutions[:, 0])
      # th (-180,180)
      solutions[:, 1] = args.th_size * np.tanh(solutions[:, 1])
      # phi (-70, 70)
      solutions[:, 2] = args.phi_size * np.tanh(solutions[:, 2])
      # r (3, 5)
      solutions[:, 3] = args.r_size * np.tanh(solutions[:, 3]) + 4
      # x (-0.5, 0.5)
      solutions[:, 4] = args.x_size * np.tanh(solutions[:, 4])
      # x (-0.5, 0.5)
      solutions[:, 5] = args.y_size * np.tanh(solutions[:, 5])

      fitness_list = np.zeros(solver.popsize)


      #  多进程工作
      with joblib.Parallel(n_jobs=N_JOBS) as parallel:
        #for i in tqdm(range(solver.popsize)):
          #fitness_list[i] = comput_fitness(solutions[i])

        fitness_list = parallel(joblib.delayed(comput_fitness)(solutions[i], solver.sigma) for i in tqdm(range(solver.popsize)))

      solver.tell(fitness_list, mu_entropy_grad, sigma_entropy_grad)
      result = solver.result()  # first element is the best solution, second element is the best fitness

      history.append(result[1])
      fitness_origin.append(np.max(fitness_list))
      average_fitness = np.mean(fitness_list)


      max_idx = np.argmax(fitness_list)
      history_best_solution.append(solutions[max_idx])
      if (j + 1) % 1 == 0:
        print("fitness at iteration\n", (j + 1), max(fitness_origin))
        print("average fitness at iteration\n", (j + 1), average_fitness)
        print("sigma at iteration\n", (j + 1), result[3])
        print("mu at iteration\n", (j + 1), result[0])

        # 写入日志数据
        logging['fitness'].append(result[1])
        logging['sigma'].append(result[3])
        logging['mu'].append(result[0])
        logging['entropy'].append(solver.entropy)
      # print('fitness_list', fitness_list)

      #if average_fitness > -0.25:
        #break
        

    max_idx_ = 0
    '问题：下次迭代的不一定是最好的，如果最好值没变化，要记录之前的'
    for i in range(len(history) - 1):
      if history[i + 1] > history[i]:
        max_idx_ = i + 1
      else:
        continue

    best_solutions = history_best_solution[max_idx_]

    # 输出sigma和mu的在tanh后的采样值
    random = np.zeros([args.num_sample+1, 6])
    gamma = np.random.normal(loc=result[0][0], scale=result[3][0], size=args.num_sample)
    th = np.random.normal(loc=result[0][1], scale=result[3][1], size=args.num_sample)
    phi = np.random.normal(loc=result[0][2], scale=result[3][2], size=args.num_sample)
    r = np.random.normal(loc=result[0][3], scale=result[3][3], size=args.num_sample)
    a = np.random.normal(loc=result[0][4], scale=result[3][4], size=args.num_sample)
    b = np.random.normal(loc=result[0][5], scale=result[3][5], size=args.num_sample)
    # 000为中心值对应的图像
    gamma = np.append(gamma, result[0][0])
    th = np.append(th, result[0][1])
    phi = np.append(phi, result[0][2])
    r = np.append(r, result[0][3])
    a = np.append(a, result[0][4])
    b = np.append(b, result[0][5])
    

    random[:, 0] = args.gamma_size * np.tanh(gamma)
    random[:, 1] = args.th_size * np.tanh(th)
    random[:, 2] = args.phi_size * np.tanh(phi)
    random[:, 3] = args.r_size * np.tanh(r) + 4.0
    random[:, 4] = args.x_size * np.tanh(a)
    random[:, 5] = args.y_size * np.tanh(b)
    mu = random.mean(axis=0)
    var = (random - mu).T @ (random - mu) / random.shape[0]
    var = np.sqrt(np.diagonal(var))  # this is slightly suboptimal, but instructive
    print('final sigma after tanh（角度方差）', var)

    mu = np.zeros([6])
    mu[0] = args.gamma_size * np.tanh(result[0][0])
    mu[1] = args.th_size * np.tanh(result[0][1])
    mu[2] = args.phi_size * np.tanh(result[0][2])
    mu[3] = args.r_size * np.tanh(result[0][3]) + 4.0
    mu[4] = args.x_size * np.tanh(result[0][4])
    mu[5] = args.y_size * np.tanh(result[0][5])

    print('final mu after tanh（角度中心值）', mu)

    np.save('logging_test4.npy', logging)
    
    "渲染100张该分布下的图像"
    print('begin render 100 images in current adv-distribution')
    print('--------------------------------------------------')
    render_image(random, is_over=True)

    "验证准确率"
    print('begin test the accuracy')
    print('--------------------------------------------------')
    path = '/HOME/scz1972/run/rsw_/NeRFAttack/run_NES_rebuttal_A/results/blender_for_attack/' + args.scene_name + '/'
    test_baseline(path=path, label=args.label_name, model='resnet')

    print('no.100 the mean img')
    print('--------------------------------------------------')
    path = '/HOME/scz1972/run/rsw_/NeRFAttack/run_NES_rebuttal_A/results/blender_for_attack/' + args.scene_name + '/'
    test_baseline(path=path, label=args.label_name, model='resnet', is_mean=True)


    #x = render_image(best_solutions)
    #test_baseline(path="C:/Users/Silvester/PycharmProjects/NeRFAttack/NeRF/results/blender_for_attack/'hotdog'/",label='hotdog, hot dog, red hot')



--- 文件地址: viat/NES_GMM.py ---
import numpy as np
from evaluate import comput_fitness
from rendering_image import render_image
from classifier.predict import test_baseline
from tqdm import tqdm
from datasets.opts import get_opts
import joblib
import torch
import time
np.set_printoptions(precision=4,  linewidth=100, suppress=True)
np.random.seed(0)


def compute_ranks(x):
  """
  Returns ranks in [0, len(x))
  Note: This is different from scipy.stats.rankdata, which returns ranks in [1, len(x)].
  (https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/es.py)
  """
  assert x.ndim == 1
  ranks = np.empty(len(x), dtype=int)
  ranks[x.argsort()] = np.arange(len(x))
  return ranks

def compute_centered_ranks(x):
  """
  https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/es.py
  """
  y = compute_ranks(x.ravel()).reshape(x.shape).astype(np.float32)
  y /= (x.size - 1)
  y -= .5
  return y

def compute_normalize(x):
  mean = np.mean(x)
  var = np.var(x)
  y = x-mean/var
  return y



def compute_weight_decay(weight_decay, model_param_list):
  model_param_grid = np.array(model_param_list)
  return - weight_decay * np.mean(model_param_grid * model_param_grid, axis=1)

# adopted from:
# https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/optimizers.py

class Optimizer(object):
  def __init__(self, pi, epsilon=1e-08):
    self.pi = pi
    self.dim = pi.num_params
    self.epsilon = epsilon
    self.t = 0

  def update(self, globalg):
    self.t += 1
    step = self._compute_step(globalg)
    theta = self.pi.mu
    ratio = np.linalg.norm(step) / (np.linalg.norm(theta) + self.epsilon)
    self.pi.mu = theta + step
    return ratio

  def _compute_step(self, globalg):
    raise NotImplementedError


class BasicSGD(Optimizer):
  def __init__(self, pi, stepsize):
    Optimizer.__init__(self, pi)
    self.stepsize = stepsize

  def _compute_step(self, globalg):
    step = -self.stepsize * globalg
    return step

class SGD(Optimizer):
  def __init__(self, pi, stepsize, momentum=0.9):
    Optimizer.__init__(self, pi)
    self.v = np.zeros(self.dim, dtype=np.float32)
    self.stepsize, self.momentum = stepsize, momentum

  def _compute_step(self, globalg):
    self.v = self.momentum * self.v + (1. - self.momentum) * globalg
    step = -self.stepsize * self.v
    return step


class Adam(Optimizer):
  def __init__(self, pi, stepsize, beta1=0.99, beta2=0.999):
    Optimizer.__init__(self, pi)
    self.stepsize = stepsize
    self.beta1 = beta1
    self.beta2 = beta2
    self.m = np.zeros(self.dim, dtype=np.float32)
    self.v = np.zeros(self.dim, dtype=np.float32)

  def _compute_step(self, globalg):
    a = self.stepsize * np.sqrt(1 - self.beta2 ** self.t) / (1 - self.beta1 ** self.t)
    self.m = self.beta1 * self.m + (1 - self.beta1) * globalg
    self.v = self.beta2 * self.v + (1 - self.beta2) * (globalg * globalg)
    step = -a * self.m / (np.sqrt(self.v) + self.epsilon)
    return step


class PEPG:
  '''Extension of PEPG with bells and whistles.'''

  def __init__(self, num_params,  # number of model parameters
               num_k=5,  # 混合高斯的分量数
               sigma_init=0.10,  # initial standard deviation
               sigma_alpha=0.20,  # learning rate for standard deviation
               sigma_decay=0.999,  # anneal standard deviation
               sigma_limit=0.01,  # stop annealing if less than this
               sigma_max_change=0.2,  # clips adaptive sigma to 20%
               sigma_min=0.05,  # 允许的最小sigma
               sigma_update=True,
               omiga_max_change=0.2,
               omiga_decay=0.999,
               omiga_alpha=0.020,
               learning_rate=0.01,  # learning rate for standard deviation
               learning_rate_decay=0.9999,  # annealing the learning rate
               learning_rate_limit=0.01,  # stop annealing learning rate
               elite_ratio=0,  # if > 0, then ignore learning_rate
               popsize=256,  # population size
               average_baseline=True,  # set baseline to average of batch
               weight_decay=0.01,  # weight decay coefficient
               rank_fitness=True,  # use rank rather than fitness numbers
               forget_best=True,
               mu_lambda=0.0001,
               sigma_lambda=0.0001,
               omiga_lamba=0.0001, # don't keep the historical best solution
               update_omiga=False,
               random_begin=True):

    self.num_params = num_params
    self.num_k = num_k
    self.sigma_init = sigma_init
    self.sigma_alpha = sigma_alpha
    self.sigma_decay = sigma_decay
    self.sigma_limit = sigma_limit
    self.sigma_max_change = sigma_max_change

    self.omiga_decay = omiga_decay
    self.omiga_alpha = omiga_alpha
    self.omiga_max_change = omiga_max_change

    self.learning_rate = learning_rate
    self.learning_rate_decay = learning_rate_decay
    self.learning_rate_limit = learning_rate_limit
    self.popsize = popsize
    self.average_baseline = average_baseline
    self.sigma_update = sigma_update
    self.sigma_min = sigma_min
    self.mu_lamba = mu_lambda
    self.sigma_lamba = sigma_lambda
    self.omiga_lamba = omiga_lamba


    if self.average_baseline:
      assert (self.popsize % 2 == 0), "Population size must be even"
      self.batch_size = int(self.popsize / 2)
    else:
      assert (self.popsize & 1), "Population size must be odd"
      self.batch_size = int((self.popsize - 1) / 2)

    # option to use greedy es method to select next mu, rather than using drift param
    self.elite_ratio = elite_ratio
    self.elite_popsize = int(self.popsize * self.elite_ratio)
    self.use_elite = False
    if self.elite_popsize > 0:
      self.use_elite = True

    self.forget_best = forget_best
    self.batch_reward = np.zeros(self.batch_size * 2)

# -----------------------------------------------------------------------------------
    if not random_begin:
      self.mu = np.zeros([self.num_k, self.num_params])
    else:
      self.mu = 2.0*np.random.random_sample([self.num_k, self.num_params])-1.0

    self.sigma = np.ones([self.num_k, self.num_params]) * self.sigma_init
    self.omiga = 1/self.num_k * np.ones([self.num_k, self.num_params])

    self.curr_best_mu = np.zeros([self.num_k, self.num_params])
    self.best_mu = np.zeros([self.num_k, self.num_params])
# -----------------------------------------------------------------------------------

    self.best_reward = 0
    self.first_interation = True
    self.weight_decay = weight_decay
    self.rank_fitness = rank_fitness
    if self.rank_fitness:
      self.forget_best = True  # always forget the best one if we rank
    # choose optimizer
    self.optimizer = SGD(self, learning_rate)

    self.update_omiga = update_omiga

  def rms_stdev(self):
    sigma = self.sigma
    return np.mean(np.sqrt(sigma * sigma))

  def ask(self):
    '''returns a list of parameters'''
    # antithetic sampling
    # self.epsilon = np.random.randn(self.batch_size, self.num_params) * self.sigma.reshape(1, self.num_params)
    # self.epsilon_full = np.concatenate([self.epsilon, - self.epsilon])
    # if self.average_baseline:
    #   epsilon = self.epsilon_full
    # else:
    #   # first population is mu, then positive epsilon, then negative epsilon
    #   epsilon = np.concatenate([np.zeros((1, self.num_params)), self.epsilon_full])
    #   self.r = epsilon/self.sigma.reshape(1, self.num_params)
    # solutions = self.mu.reshape(1, self.num_params) + epsilon
    # self.solutions = solutions
    # return solutions

    self.r = np.random.randn(self.batch_size, self.num_params)  # N*6 的 r
    self.r_full = np.concatenate([self.r, - self.r])
    if self.average_baseline:
        r = self.r_full
    else:
     # first population is every mu, then positive epsilon, then negative epsilon
        r = np.concatenate([np.zeros((self.num_k, self.num_params)), self.r_full])
        self.r_full = r

    self.F = np.zeros([self.batch_size, self.num_params])
    for i in range(self.num_params):
        F = np.random.choice(a=np.arange(self.num_k), size=self.batch_size, replace=True, p=self.omiga[:, i])
        self.F[:, i] = F
    self.F_full = np.concatenate([self.F, self.F])

    if self.average_baseline:
        F = self.F_full
    else:
     # first population is every mu, then positive epsilon, then negative epsilon
        l = np.linspace(0, self.num_k-1, num=self.num_k).repeat(self.num_params, axis=0).reshape((self.num_k, -1))
        F = np.concatenate([l, self.F_full])
        self.F_full = F

    # 依照各个分量得到solution
    self.solutions = np.zeros([self.batch_size*2+self.num_k, self.num_params])
    self.epsilon_full = np.zeros([self.batch_size*2+self.num_k, self.num_params])
    for i in range(self.num_params):
        for j in range(self.batch_size*2+self.num_k):
            k = int(self.F_full[j, i])
            self.epsilon_full[j, i] = r[j, i] * self.sigma[k, i]
            self.solutions[j, i] = self.mu[k, i] + self.epsilon_full[j, i]
    solutions = self.solutions
    self.epsilon = self.epsilon_full[self.num_k:self.num_k+self.batch_size, :]
    return solutions

  def comput_entropy(self):
    # 计算每个批次的高斯分布的熵
    r = torch.Tensor(self.r_full)  # N(0,1)中的采样点
    sigma = torch.Tensor(self.sigma)
    sigma.requires_grad = True
    mu = torch.Tensor(self.mu)
    mu.requires_grad = True
    omiga = torch.Tensor(self.omiga)
    omiga.requires_grad = True
    a = torch.Tensor([60, 180, 60, 1, 0.7, 0.7])    # 各个参数的前系数
    F_full = torch.Tensor(self.F_full)  # 隐变量

    # 计算当前批次的每个搜索维度下 各个高斯分量分布的熵 NUM_K*NUM_params
    Entropy = torch.zeros([self.num_k, self.num_params])
    for i in range(self.num_params):
        for j in range(self.batch_size*2+self.num_k):
            k = int(F_full[j, i])
            inside = 1-torch.pow(torch.tanh(mu[k, i] + sigma[k, i] * r[j, i]), 2) + 1e-8
            neg_logp = -torch.log(omiga[k, i]+1e-8) + torch.log(sigma[k, i]+1e-8) + 1/2*torch.pow(r[j, i], 2) + torch.log(inside)
            Entropy[k, i] += neg_logp

    print('每个搜索维度下各个高斯分量分布的熵 entropy:\n', Entropy)

    Entropy = Entropy / torch.Tensor([self.popsize]).repeat(self.num_k, self.num_params)

    # inside = 1-torch.pow(torch.tanh(mu+sigma*r), 2) +1e-8
    # neg_logp = torch.log(sigma+1e-8) + 1/2*torch.pow(r, 2) + torch.log(inside)
    # Entropy = torch.mean(neg_logp, 0)
    # print('entropy:\n', Entropy)
    Entropy = torch.sum(Entropy)

    # 得到的Entropy是当前种群所有参数熵的总和

    # 梯度反向传播
    Entropy.backward()

    mu_entropy_grad = mu.grad.clone()
    sigma_entropy_grad = sigma.grad.clone()
    omiga_entropy_grad = omiga.grad.clone()
    # 梯度清零
    mu.grad.data.zero_()
    sigma.grad.data.zero_()
    omiga.grad.data.zero_()
    print("总的 Entropy：\n", Entropy)
    self.entropy = Entropy

    return mu_entropy_grad.cpu().detach().numpy(), sigma_entropy_grad.cpu().detach().numpy(), omiga_entropy_grad.cpu().detach().numpy()


  def tell(self, reward_table_result, mu_entropy_grad, sigma_entropy_grad, omiga_entropy_grad):
    # input must be a numpy float array
    assert (len(reward_table_result) == self.batch_size*2+self.num_k), "Inconsistent reward_table size reported."

    reward_table = np.array(reward_table_result)

    if self.rank_fitness:
      reward_table = compute_centered_ranks(reward_table)
      # reward_table = compute_normalize(reward_table)

    if self.weight_decay > 0:
      l2_decay = compute_weight_decay(self.weight_decay, self.solutions)
      reward_table += l2_decay

    reward_offset = self.num_k
    if self.average_baseline:
      b = np.mean(reward_table)
      reward_offset = 0
    else:
      b = reward_table[0:reward_offset]  # baseline

    reward = reward_table[reward_offset:]
    F = self.F_full[reward_offset:]


    best_mu = np.zeros([self.num_k, self.num_params])
    best_rewards = np.zeros([self.num_k, self.num_params])

    for j in range(self.num_params):

      for k in range(self.num_k):
        current_reward = np.array([])
        current_epsilon = np.array([])
        for i in range(len(F)):
          if int(F[i, j]) == k:
            current_reward = np.append(current_reward, reward[i])
            current_epsilon = np.append(current_epsilon, self.epsilon_full[self.num_k+i, j])
        # current_epsilon = current_epsilon.reshape((-1, self.num_params))

        if len(current_reward) != 0:
          if self.use_elite:
            idx = np.argsort(current_reward)[::-1][0:self.elite_popsize]
          else:
            idx = np.argsort(current_reward)[::-1]
          best_reward = current_reward[idx[0]]

          if (best_reward > b[k] or self.average_baseline):
            best_mu[k, j] = self.mu[k, j] + current_epsilon[idx[0]]
            best_rewards[k, j] = reward[idx[0]]
          else:
            best_mu[k, j] = self.mu[k, j]
            best_rewards[k, j] = b[k]
        else:
          best_mu[k, j] = self.mu[k, j]
          best_rewards[k, j] = b[k]

    self.curr_best_reward = best_rewards
    self.curr_best_mu = best_mu

    if self.first_interation:
      self.sigma = np.ones([self.num_k, self.num_params]) * self.sigma_init
      self.first_interation = False
      self.best_reward = self.curr_best_reward
      self.best_mu = best_mu
    else:
      if self.forget_best or (self.curr_best_reward > self.best_reward):
        self.best_mu = best_mu
        self.best_reward = self.curr_best_reward

    # short hand
    epsilon = self.epsilon
    sigma = self.sigma

    # update the mean

    # move mean to the average of the best idx means
    if self.use_elite:
      self.mu += self.epsilon_full[idx].mean(axis=0)
    else:
      change_mu = np.zeros([self.num_k, self.num_params])
      for j in range(self.num_params):

        for k in range(self.num_k):
          current_reward = np.array([])
          current_epsilon = np.array([])
          for i in range(len(F)):
            if int(F[i, j]) == k:
              current_reward = np.append(current_reward, reward[i])
              current_epsilon = np.append(current_epsilon, self.epsilon_full[self.num_k+i, j])
          if len(current_reward) != 0:
              rT = (current_reward[:int(len(current_reward)/2)] - current_reward[int(len(current_reward)/2):])
              change_mu[k, j] = np.dot(rT, current_epsilon[:int(len(current_epsilon)/2)])/self.omiga[k, j]
          else:
              change_mu[k, j] = 0

      change_mu_all = change_mu + self.mu_lamba*mu_entropy_grad
      print('mu-loss1:\n', change_mu)
      print('mu-loss2:\n', self.mu_lamba*mu_entropy_grad)

      self.optimizer.stepsize = self.learning_rate
      update_ratio = self.optimizer.update(-change_mu_all)  # adam, rmsprop, momentum, etc.
      # self.mu += (change_mu * self.learning_rate) # normal SGD method

    # adaptive sigma
    # normalization
    if self.sigma.all() > self.sigma_min:
    #if (self.sigma[a] > self.sigma_min for a in range(self.num_params)):
      if (self.sigma_alpha > 0 and self.sigma_update):
        stdev_reward = 1.0
        if not self.rank_fitness:
          stdev_reward = reward.std()

        delta_sigma = np.zeros([self.num_k, self.num_params])
        for j in range(self.num_params):
          for k in range(self.num_k):
            current_reward = np.array([])
            current_epsilon = np.array([])
            for i in range(len(F)):
              if int(F[i, j]) == k:
                current_reward = np.append(current_reward, reward[i])
                current_epsilon = np.append(current_epsilon, self.epsilon_full[self.num_k + i, j])

            if len(current_reward) != 0:
              S = ((current_epsilon[:int(len(current_epsilon)/2)] * current_epsilon[:int(len(current_epsilon)/2)] - sigma[k, j] * sigma[k, j]) / sigma[k, j]*self.omiga[k, j])
              reward_avg = (current_reward[:int(len(current_reward)/2)] + current_reward[int(len(current_reward)/2):]) / 2.0
              rS = reward_avg - b[k]

              delta_sigma[k, j] = (np.dot(rS, S)) / (2 * len(current_reward)/2 * stdev_reward)
            else:
              delta_sigma[k, j] = 0
          # adjust sigma according to the adaptive sigma calculation
        # for stability, don't let sigma move more than 10% of orig value
        change_sigma = self.sigma_alpha * (delta_sigma + self.sigma_lamba*sigma_entropy_grad)

        print('sigma-loss1:\n', self.sigma_alpha * delta_sigma)
        print('sigma-loss2:\n', self.sigma_lamba*sigma_entropy_grad)

        change_sigma = np.minimum(change_sigma, self.sigma_max_change * self.sigma)
        change_sigma = np.maximum(change_sigma, - self.sigma_max_change * self.sigma)
        self.sigma += change_sigma
        self.sigma = np.clip(self.sigma, 0.0, 0.15)

        if (self.sigma_decay < 1):
          self.sigma[self.sigma > self.sigma_limit] *= self.sigma_decay

    if (self.learning_rate_decay < 1 and self.learning_rate > self.learning_rate_limit):
      self.learning_rate *= self.learning_rate_decay

    # adaptive omiga
    if self.update_omiga:
      change_omiga = np.zeros([self.num_k, self.num_params])
      for j in range(self.num_params):
        for k in range(self.num_k):
          current_reward = np.array([])
          for i in range(len(F)):
            if int(F[i, j]) == k:
              current_reward = np.append(current_reward, reward[i])
          if len(current_reward) != 0:
            rT = (current_reward[:int(len(current_reward) / 2)] - current_reward[int(len(current_reward) / 2):])
            change_omiga[k, j] = sum(rT) / self.omiga[k, j]*len(rT)
          else:
            change_omiga[k, j] = 0

      change_omiga_all = self.omiga_alpha*(change_omiga + self.omiga_lamba * omiga_entropy_grad)
      print('omiga-loss1:\n', change_omiga)
      print('omiga-loss2:\n', self.omiga_lamba*omiga_entropy_grad)

      change_omiga_all = np.minimum(change_omiga_all, self.omiga_max_change * self.omiga)
      change_omiga_all = np.maximum(change_omiga_all, - self.omiga_max_change * self.omiga)
      self.omiga += change_omiga_all
      self.omiga = np.clip(self.omiga, 10e-8, 1.0-10e-8)
      # 按列归一化
      for i in range(self.num_params):
        # self.omiga[:, i] = (self.omiga[:, i] - min(self.omiga[:, i])) / (max(self.omiga[:, i])-min(self.omiga[:, i]))
        self.omiga[:, i] = self.omiga[:, i]/sum(self.omiga[:, i])


  def current_param(self):
    return self.curr_best_mu

  def set_mu(self, mu):
    self.mu = np.array(mu)

  def best_param(self):
    return self.best_mu

  def result(self):  # return best params so far, along with historically best reward, curr reward, sigma
    return (self.best_mu, self.best_reward, self.curr_best_reward, self.sigma, self.omiga)



def NES_GMM_search():
  args = get_opts()
  search_num = args.search_num

  # 搜索三维空间，th phi r
  if search_num == 3:

    MAX_ITERATION = args.iteration
    POPSIZE = args.popsize
    NUM_PARAMS = 3
    solver = PEPG(num_params=NUM_PARAMS,                         # number of model parameters
              sigma_init=0.15,                  # initial standard deviation
              learning_rate=0.1,               # learning rate for standard deviation
              learning_rate_decay=0.999,       # don't anneal the learning rate
              popsize=POPSIZE,             # population size
              average_baseline=False,          # set baseline to average of batch
              weight_decay=0.00,             # weight decay coefficient
              rank_fitness=False,           # use rank rather than fitness numbers
              forget_best=False)

    history = []
    history_best_solution = []
    for j in range(MAX_ITERATION):
      solutions = solver.ask()
      # th (-180,180)
      solutions[:, 0] = 180 * np.tanh(solutions[:, 0])
      # phi (180, 0)
      solutions[:, 1] = 45 * np.tanh(solutions[:, 2]) - 90
      # r (4, 6)
      solutions[:, 2] = np.tanh(solutions[:, 2]) + 4

      fitness_list = np.zeros(solver.popsize)
      for i in tqdm(range(solver.popsize)):
        fitness_list[i] = comput_fitness(solutions[i])
      solver.tell(fitness_list)
      result = solver.result()  # first element is the best solution, second element is the best fitness

      history.append(result[1])
      max_idx = np.argmax(fitness_list)
      history_best_solution.append(solutions[max_idx])
      if (j + 1) % 1 == 0:
        print("fitness at iteration", (j + 1), result[1])
      # print('fitness_list', fitness_list)

    max_idx_ = 0
    '问题：下次迭代的不一定是最好的，如果最好值没变化，要记录之前的'
    for i in range(len(history)-1):
      if history[i+1] > history[i]:
        max_idx_ = i+1
      else:
        continue

    best_solutions = history_best_solution[max_idx_]

    result[0][0] = 180 * np.tanh(result[0][0])
    result[0][1] = 45 * np.tanh(result[0][1]) - 90
    result[0][2] = np.tanh(result[0][2]) + 4

    print('local optimum discovered by solver(best mu):\n th: {:.16f},th: {:.16f},th: {:.16f}'.format(result[0][0], result[0][1], result[0][2]))
    print('local optimum discovered by solver(best solution):\n th: {:.16f},th: {:.16f},th: {:.16f}'.format(best_solutions[0], best_solutions[1], best_solutions[2]))
    print("fitness score at this local optimum: ", result[1])


    "验证"
    x = render_image(th=best_solutions[0], phi=best_solutions[1], r=best_solutions[2])
    test_baseline(path="C:/Users/Silvester/PycharmProjects/NeRFAttack/NeRF/results/blender_for_attack/'hotdog'/",
                  label='hotdog, hot dog, red hot')

  if search_num == 6:

    MAX_ITERATION = args.iteration
    POPSIZE = args.popsize
    NUM_PARAMS = 6
    NUM_K = args.num_k
    N_JOBS = 10
    max_stop_fitness = 6.0
    # 搜索六维空间，th phi gamma r x y
    solver = PEPG(num_params=NUM_PARAMS,  # number of model parameters
                  num_k = NUM_K,
                  sigma_init=0.1,  # initial standard deviation
                  sigma_update=True,  # 不大幅更新sigma
                  learning_rate=0.1,  # learning rate for standard deviation
                  learning_rate_decay=0.99, # don't anneal the learning rate
                  learning_rate_limit=0,
                  popsize=POPSIZE,  # population size
                  average_baseline=False,  # set baseline to average of batch
                  weight_decay=0.00,  # weight decay coefficient
                  rank_fitness=True,  # use rank rather than fitness numbers
                  forget_best=False,
                  mu_lambda=args.mu_lamba,
                  sigma_lambda=args.sigma_lamba,
                  omiga_lamba=args.omiga_lamba,
                  random_begin=args.random_begin,
                  omiga_alpha=0.02
                  )

    logging = {'mu': [], 'sigma': [], 'fitness': [], 'entropy':[]}
    history = []
    fitness_origin = []
    history_best_solution = []
    for j in tqdm(range(MAX_ITERATION)):
      solutions = solver.ask()
      mu_entropy_grad, sigma_entropy_grad, omiga_entropy_grad = solver.comput_entropy()

      # gamma (-60,60)
      solutions[:, 0] = 30 * np.tanh(solutions[:, 0])
      # th (-180,180)
      solutions[:, 1] = 180 * np.tanh(solutions[:, 1])
      # phi (-60, 60)
      solutions[:, 2] = 70 * np.tanh(solutions[:, 2])
      # r (4, 6)
      solutions[:, 3] = np.tanh(solutions[:, 3]) + 4
      # x (-1, 1)
      solutions[:, 4] = 0.5 * np.tanh(solutions[:, 4])
      # x (-1, 1)
      solutions[:, 5] = 0.5 * np.tanh(solutions[:, 5])

      fitness_list = np.zeros(solver.popsize)

      #  多进程工作
      # with joblib.Parallel(n_jobs=N_JOBS) as parallel:
      #   #for i in tqdm(range(solver.popsize)):
      #     #fitness_list[i] = comput_fitness(solutions[i])

      #   fitness_list = parallel(joblib.delayed(comput_fitness)(solutions[i], solver.sigma) for i in tqdm(range(solver.batch_size*2+solver.num_k)))

      fitness_list = comput_fitness(solutions)
      
      solver.tell(fitness_list, mu_entropy_grad, sigma_entropy_grad, omiga_entropy_grad)
      result = solver.result()  # first element is the best solution, second element is the best fitness

      fitness_origin.append(np.max(fitness_list))
      history.append(result[1])
      average_fitness = np.mean(fitness_list)
      max_idx = np.argmax(fitness_list)
      history_best_solution.append(solutions[max_idx])
      if (j + 1) % 1 == 0:
        print("fitness at iteration\n", (j + 1), max(fitness_origin))
        print("average fitness at iteration\n", (j + 1), average_fitness)
        print("sigma at iteration\n", (j + 1), result[3])
        print("mu at iteration\n", (j + 1), result[0])
        print("omiga at iteration\n", (j + 1), result[4])

        # 写入日志数据
        logging['fitness'].append(result[1])
        logging['sigma'].append(result[3])
        logging['mu'].append(result[0])
        logging['entropy'].append(solver.entropy)
      # print('fitness_list', fitness_list)

      # 若达到搜索要求，则停止迭代
      #if average_fitness > max_stop_fitness:
        #break

    # max_idx_ = 0
    # '问题：下次迭代的不一定是最好的，如果最好值没变化，要记录之前的'
    # for i in range(len(history) - 1):
    #   if history[i + 1] > history[i]:
    #     max_idx_ = i + 1
    #   else:
    #     continue

    # best_solutions = history_best_solution[max_idx_]

    # 输出sigma和mu的在tanh后的混合高斯采样值
    # 根据omiga矩阵对每个维度采样分量标号
    random = np.zeros([args.num_sample + solver.num_k, 6])
    mu = result[0]
    sigma = result[3]

    F_all = np.zeros([args.num_sample, solver.num_params])
    for i in range(solver.num_params):
      F = np.random.choice(a=np.arange(solver.num_k), size=args.num_sample, replace=True, p=solver.omiga[:, i])
      F_all[:, i] = F

    def get_GMM_sample(F, mu, sigma):
      sample_all = np.zeros(args.num_sample)
      for i in range(len(F)):
        k = int(F[i])
        sample = np.random.normal(loc=mu[k], scale=sigma[k], size=1)
        sample_all[i] = sample
      sample_all = np.concatenate([sample_all, mu])
      return sample_all

    a = [30, 180, 70, 1.0, 0.5, 0.5]
    b = [0, 0, 0, 4.0, 0, 0]
    for i in range(solver.num_params):
      random[:, i] = a[i]*np.tanh(get_GMM_sample(F_all[:, i], mu[:, i], sigma[:, i]))+b[i]

    # 计算各高斯分量的方差 均值
    # mu_ = np.zeros([solver.num_k, solver.num_params])
    # var = np.zeros([solver.num_k, solver.num_params])
    # for j in range(solver.num_params):
    #   for i in range(solver.num_k):
    #     sample = np.array([])
    #     for l in range(len(F)):
    #       if int(F[l]) == i:
    #         sample = np.append(sample, random[l, j])
    #     if len(sample) != 0:
    #       mu_[i, j] = np.mean(sample)
    #       var_ = (sample - mu_[i, j]).T @ (sample - mu_[i, j]) / sample.shape[0]
    #       var[i, j] = np.sqrt(var_)
    #     else:
    #       mu_[i, j] = 0
    #       var[i, j] = None
    
    for i in range(solver.num_k):
      max_value = a * np.tanh(mu[i, :]+sigma[i, :]) + b
      min_value = a * np.tanh(mu[i, :]-sigma[i, :]) + b
      value_range = max_value-min_value
      sigma[i,:] = value_range

    print('final sigma after tanh（角度方差）\n', sigma)

    for i in range(solver.num_k):
      mu[i, :] = a * np.tanh(mu[i, :]) + b

    print('final mu after tanh（角度中心值）\n', mu)
    print('final omiga after tanh（高斯分量权重）\n', result[4])

    "渲染100张该分布下的图像"
    print('begin render 100 images in current adv-distribution')
    print('--------------------------------------------------')
    render_image(random, is_over=True)

    "验证准确率"
    print('begin test the accuracy')
    print('--------------------------------------------------')
    path = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/run_GMM/results/nerf_for_attack/' + args.scene_name + '/'
    acc = test_baseline(path=path, label=args.label, model='resnet')
    print("acc:", acc)

    # print('no.100 the mean img')
    # print('--------------------------------------------------')
    # path = '/HOME/scz1972/run/rsw_/NeRFAttack/run_NES_rebuttal_A/results/blender_for_attack/' + args.scene_name + '/'
    # test_baseline(path=path, label=args.label_name, model='resnet', is_mean=True)


--- 文件地址: viat/NES_GMM_forAT.py ---
import numpy as np
import os
from evaluate_forAT import comput_fitness
from rendering_image import render_image
from classifier.predict import test_baseline
from tqdm import tqdm
from datasets.opts import get_opts
import joblib
import torch
import time
np.set_printoptions(precision=4,  linewidth=100, suppress=True)
# np.random.seed(0)


def compute_ranks(x):
  """
  Returns ranks in [0, len(x))
  Note: This is different from scipy.stats.rankdata, which returns ranks in [1, len(x)].
  (https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/es.py)
  """
  assert x.ndim == 1
  ranks = np.empty(len(x), dtype=int)
  ranks[x.argsort()] = np.arange(len(x))
  return ranks

def compute_centered_ranks(x):
  """
  https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/es.py
  """
  y = compute_ranks(x.ravel()).reshape(x.shape).astype(np.float32)
  y /= (x.size - 1)
  y -= .5
  return y

def compute_normalize(x):
  mean = np.mean(x)
  var = np.var(x)
  y = x-mean/var
  return y



def compute_weight_decay(weight_decay, model_param_list):
  model_param_grid = np.array(model_param_list)
  return - weight_decay * np.mean(model_param_grid * model_param_grid, axis=1)

# adopted from:
# https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/optimizers.py

class Optimizer(object):
  def __init__(self, pi, epsilon=1e-08):
    self.pi = pi
    self.dim = pi.num_params
    self.epsilon = epsilon
    self.t = 0

  def update(self, globalg):
    self.t += 1
    step = self._compute_step(globalg)
    theta = self.pi.mu
    ratio = np.linalg.norm(step) / (np.linalg.norm(theta) + self.epsilon)
    self.pi.mu = theta + step
    return ratio

  def _compute_step(self, globalg):
    raise NotImplementedError


class BasicSGD(Optimizer):
  def __init__(self, pi, stepsize):
    Optimizer.__init__(self, pi)
    self.stepsize = stepsize

  def _compute_step(self, globalg):
    step = -self.stepsize * globalg
    return step

class SGD(Optimizer):
  def __init__(self, pi, stepsize, momentum=0.9):
    Optimizer.__init__(self, pi)
    self.v = np.zeros(self.dim, dtype=np.float32)
    self.stepsize, self.momentum = stepsize, momentum

  def _compute_step(self, globalg):
    self.v = self.momentum * self.v + (1. - self.momentum) * globalg
    step = -self.stepsize * self.v
    return step


class Adam(Optimizer):
  def __init__(self, pi, stepsize, beta1=0.99, beta2=0.999):
    Optimizer.__init__(self, pi)
    self.stepsize = stepsize
    self.beta1 = beta1
    self.beta2 = beta2
    self.m = np.zeros(self.dim, dtype=np.float32)
    self.v = np.zeros(self.dim, dtype=np.float32)

  def _compute_step(self, globalg):
    a = self.stepsize * np.sqrt(1 - self.beta2 ** self.t) / (1 - self.beta1 ** self.t)
    self.m = self.beta1 * self.m + (1 - self.beta1) * globalg
    self.v = self.beta2 * self.v + (1 - self.beta2) * (globalg * globalg)
    step = -a * self.m / (np.sqrt(self.v) + self.epsilon)
    return step


class PEPG:
  '''Extension of PEPG with bells and whistles.'''

  def __init__(self, num_params,  # number of model parameters
               num_k=5,  # 混合高斯的分量数
               sigma_init=0.10,  # initial standard deviation
               sigma_alpha=0.20,  # learning rate for standard deviation
               sigma_decay=0.999,  # anneal standard deviation
               sigma_limit=0.01,  # stop annealing if less than this
               sigma_max_change=0.2,  # clips adaptive sigma to 20%
               sigma_min=0.05,  # 允许的最小sigma
               sigma_update=True,
               omiga_max_change=0.2,
               omiga_decay=0.999,
               omiga_alpha=0.020,
               learning_rate=0.01,  # learning rate for standard deviation
               learning_rate_decay=0.9999,  # annealing the learning rate
               learning_rate_limit=0.01,  # stop annealing learning rate
               elite_ratio=0,  # if > 0, then ignore learning_rate
               popsize=256,  # population size
               average_baseline=True,  # set baseline to average of batch
               weight_decay=0.01,  # weight decay coefficient
               rank_fitness=True,  # use rank rather than fitness numbers
               forget_best=True,
               mu_lambda=0.0001,
               sigma_lambda=0.0001,
               omiga_lamba=0.0001, # don't keep the historical best solution
               update_omiga=False,
               random_begin=True,
               mood='init',
               mu_start=None,
               sigma_start=None
               ):

    self.num_params = num_params
    self.num_k = num_k
    self.sigma_init = sigma_init
    self.sigma_alpha = sigma_alpha
    self.sigma_decay = sigma_decay
    self.sigma_limit = sigma_limit
    self.sigma_max_change = sigma_max_change

    self.omiga_decay = omiga_decay
    self.omiga_alpha = omiga_alpha
    self.omiga_max_change = omiga_max_change

    self.learning_rate = learning_rate
    self.learning_rate_decay = learning_rate_decay
    self.learning_rate_limit = learning_rate_limit
    self.popsize = popsize
    self.average_baseline = average_baseline
    self.sigma_update = sigma_update
    self.sigma_min = sigma_min
    self.mu_lamba = mu_lambda
    self.sigma_lamba = sigma_lambda
    self.omiga_lamba = omiga_lamba


    if self.average_baseline:
      assert (self.popsize % 2 == 0), "Population size must be even"
      self.batch_size = int(self.popsize / 2)
    else:
      assert (self.popsize & 1), "Population size must be odd"
      self.batch_size = int((self.popsize - 1) / 2)

    # option to use greedy es method to select next mu, rather than using drift param
    self.elite_ratio = elite_ratio
    self.elite_popsize = int(self.popsize * self.elite_ratio)
    self.use_elite = False
    if self.elite_popsize > 0:
      self.use_elite = True

    self.forget_best = forget_best
    self.batch_reward = np.zeros(self.batch_size * 2)

# -----------------------------------------------------------------------------------
    if mood == 'init' or mood == 'eval_test':
      if not random_begin:
        self.mu = np.zeros([self.num_k, self.num_params])
      else:
        self.mu = 2.0*np.random.random_sample([self.num_k, self.num_params])-1.0

      self.sigma = np.ones([self.num_k, self.num_params]) * self.sigma_init
    else:
      self.mu = mu_start
      self.sigma = sigma_start


    self.omiga = 1/self.num_k * np.ones([self.num_k, self.num_params])

    self.curr_best_mu = np.zeros([self.num_k, self.num_params])
    self.best_mu = np.zeros([self.num_k, self.num_params])
# -----------------------------------------------------------------------------------

    self.best_reward = 0
    self.first_interation = True
    self.weight_decay = weight_decay
    self.rank_fitness = rank_fitness
    if self.rank_fitness:
      self.forget_best = True  # always forget the best one if we rank
    # choose optimizer
    self.optimizer = SGD(self, learning_rate)

    self.update_omiga = update_omiga

  def rms_stdev(self):
    sigma = self.sigma
    return np.mean(np.sqrt(sigma * sigma))

  def ask(self):
    '''returns a list of parameters'''
    # antithetic sampling
    # self.epsilon = np.random.randn(self.batch_size, self.num_params) * self.sigma.reshape(1, self.num_params)
    # self.epsilon_full = np.concatenate([self.epsilon, - self.epsilon])
    # if self.average_baseline:
    #   epsilon = self.epsilon_full
    # else:
    #   # first population is mu, then positive epsilon, then negative epsilon
    #   epsilon = np.concatenate([np.zeros((1, self.num_params)), self.epsilon_full])
    #   self.r = epsilon/self.sigma.reshape(1, self.num_params)
    # solutions = self.mu.reshape(1, self.num_params) + epsilon
    # self.solutions = solutions
    # return solutions

    self.r = np.random.randn(self.batch_size, self.num_params)  # N*6 的 r
    self.r_full = np.concatenate([self.r, - self.r])
    if self.average_baseline:
        r = self.r_full
    else:
     # first population is every mu, then positive epsilon, then negative epsilon
        r = np.concatenate([np.zeros((self.num_k, self.num_params)), self.r_full])
        self.r_full = r

    self.F = np.zeros([self.batch_size, self.num_params])
    for i in range(self.num_params):
        F = np.random.choice(a=np.arange(self.num_k), size=self.batch_size, replace=True, p=self.omiga[:, i])
        self.F[:, i] = F
    self.F_full = np.concatenate([self.F, self.F])

    if self.average_baseline:
        F = self.F_full
    else:
     # first population is every mu, then positive epsilon, then negative epsilon
        l = np.linspace(0, self.num_k-1, num=self.num_k).repeat(self.num_params, axis=0).reshape((self.num_k, -1))
        F = np.concatenate([l, self.F_full])
        self.F_full = F

    # 依照各个分量得到solution
    self.solutions = np.zeros([self.batch_size*2+self.num_k, self.num_params])
    self.epsilon_full = np.zeros([self.batch_size*2+self.num_k, self.num_params])
    for i in range(self.num_params):
        for j in range(self.batch_size*2+self.num_k):
            k = int(self.F_full[j, i])
            self.epsilon_full[j, i] = r[j, i] * self.sigma[k, i]
            self.solutions[j, i] = self.mu[k, i] + self.epsilon_full[j, i]
    solutions = self.solutions
    self.epsilon = self.epsilon_full[self.num_k:self.num_k+self.batch_size, :]
    return solutions

  def comput_entropy(self):
    # 计算每个批次的高斯分布的熵
    r = torch.Tensor(self.r_full)  # N(0,1)中的采样点
    sigma = torch.Tensor(self.sigma)
    sigma.requires_grad = True
    mu = torch.Tensor(self.mu)
    mu.requires_grad = True
    omiga = torch.Tensor(self.omiga)
    omiga.requires_grad = True
    a = torch.Tensor([60, 180, 60, 1, 0.7, 0.7])    # 各个参数的前系数
    F_full = torch.Tensor(self.F_full)  # 隐变量

    # 计算当前批次的每个搜索维度下 各个高斯分量分布的熵 NUM_K*NUM_params
    Entropy = torch.zeros([self.num_k, self.num_params])
    for i in range(self.num_params):
        for j in range(self.batch_size*2+self.num_k):
            k = int(F_full[j, i])
            inside = 1-torch.pow(torch.tanh(mu[k, i] + sigma[k, i] * r[j, i]), 2) + 1e-8
            neg_logp = -torch.log(omiga[k, i]+1e-8) + torch.log(sigma[k, i]+1e-8) + 1/2*torch.pow(r[j, i], 2) + torch.log(inside)
            Entropy[k, i] += neg_logp

    # print('每个搜索维度下各个高斯分量分布的熵 entropy:\n', Entropy)

    Entropy = Entropy / torch.Tensor([self.popsize]).repeat(self.num_k, self.num_params)

    # inside = 1-torch.pow(torch.tanh(mu+sigma*r), 2) +1e-8
    # neg_logp = torch.log(sigma+1e-8) + 1/2*torch.pow(r, 2) + torch.log(inside)
    # Entropy = torch.mean(neg_logp, 0)
    # print('entropy:\n', Entropy)
    Entropy = torch.sum(Entropy)

    # 得到的Entropy是当前种群所有参数熵的总和

    # 梯度反向传播
    Entropy.backward()

    mu_entropy_grad = mu.grad.clone()
    sigma_entropy_grad = sigma.grad.clone()
    omiga_entropy_grad = omiga.grad.clone()
    # 梯度清零
    mu.grad.data.zero_()
    sigma.grad.data.zero_()
    omiga.grad.data.zero_()
    # print("总的 Entropy：\n", Entropy)
    self.entropy = Entropy

    return mu_entropy_grad.cpu().detach().numpy(), sigma_entropy_grad.cpu().detach().numpy(), omiga_entropy_grad.cpu().detach().numpy()


  def tell(self, reward_table_result, mu_entropy_grad, sigma_entropy_grad, omiga_entropy_grad):
    # input must be a numpy float array
    assert (len(reward_table_result) == self.batch_size*2+self.num_k), "Inconsistent reward_table size reported."

    reward_table = np.array(reward_table_result)

    if self.rank_fitness:
      reward_table = compute_centered_ranks(reward_table)
      # reward_table = compute_normalize(reward_table)

    if self.weight_decay > 0:
      l2_decay = compute_weight_decay(self.weight_decay, self.solutions)
      reward_table += l2_decay

    reward_offset = self.num_k
    if self.average_baseline:
      b = np.mean(reward_table)
      reward_offset = 0
    else:
      b = reward_table[0:reward_offset]  # baseline

    reward = reward_table[reward_offset:]
    F = self.F_full[reward_offset:]


    best_mu = np.zeros([self.num_k, self.num_params])
    best_rewards = np.zeros([self.num_k, self.num_params])

    for j in range(self.num_params):

      for k in range(self.num_k):
        current_reward = np.array([])
        current_epsilon = np.array([])
        for i in range(len(F)):
          if int(F[i, j]) == k:
            current_reward = np.append(current_reward, reward[i])
            current_epsilon = np.append(current_epsilon, self.epsilon_full[self.num_k+i, j])
        # current_epsilon = current_epsilon.reshape((-1, self.num_params))

        if len(current_reward) != 0:
          if self.use_elite:
            idx = np.argsort(current_reward)[::-1][0:self.elite_popsize]
          else:
            idx = np.argsort(current_reward)[::-1]
          best_reward = current_reward[idx[0]]

          if (best_reward > b[k] or self.average_baseline):
            best_mu[k, j] = self.mu[k, j] + current_epsilon[idx[0]]
            best_rewards[k, j] = reward[idx[0]]
          else:
            best_mu[k, j] = self.mu[k, j]
            best_rewards[k, j] = b[k]
        else:
          best_mu[k, j] = self.mu[k, j]
          best_rewards[k, j] = b[k]

    self.curr_best_reward = best_rewards
    self.curr_best_mu = best_mu

    if self.first_interation:
      self.sigma = np.ones([self.num_k, self.num_params]) * self.sigma_init
      self.first_interation = False
      self.best_reward = self.curr_best_reward
      self.best_mu = best_mu
    else:
      if self.forget_best or (self.curr_best_reward > self.best_reward):
        self.best_mu = best_mu
        self.best_reward = self.curr_best_reward

    # short hand
    epsilon = self.epsilon
    sigma = self.sigma

    # update the mean

    # move mean to the average of the best idx means
    if self.use_elite:
      self.mu += self.epsilon_full[idx].mean(axis=0)
    else:
      change_mu = np.zeros([self.num_k, self.num_params])
      for j in range(self.num_params):

        for k in range(self.num_k):
          current_reward = np.array([])
          current_epsilon = np.array([])
          for i in range(len(F)):
            if int(F[i, j]) == k:
              current_reward = np.append(current_reward, reward[i])
              current_epsilon = np.append(current_epsilon, self.epsilon_full[self.num_k+i, j])
          if len(current_reward) != 0:
              rT = (current_reward[:int(len(current_reward)/2)] - current_reward[int(len(current_reward)/2):])
              change_mu[k, j] = np.dot(rT, current_epsilon[:int(len(current_epsilon)/2)])/self.omiga[k, j]
          else:
              change_mu[k, j] = 0

      change_mu_all = change_mu + self.mu_lamba*mu_entropy_grad
      # print('mu-loss1:\n', change_mu)
      # print('mu-loss2:\n', self.mu_lamba*mu_entropy_grad)

      self.optimizer.stepsize = self.learning_rate
      update_ratio = self.optimizer.update(-change_mu_all)  # adam, rmsprop, momentum, etc.
      # self.mu += (change_mu * self.learning_rate) # normal SGD method

    # adaptive sigma
    # normalization
    if self.sigma.all() > self.sigma_min:
    #if (self.sigma[a] > self.sigma_min for a in range(self.num_params)):
      if (self.sigma_alpha > 0 and self.sigma_update):
        stdev_reward = 1.0
        if not self.rank_fitness:
          stdev_reward = reward.std()

        delta_sigma = np.zeros([self.num_k, self.num_params])
        for j in range(self.num_params):
          for k in range(self.num_k):
            current_reward = np.array([])
            current_epsilon = np.array([])
            for i in range(len(F)):
              if int(F[i, j]) == k:
                current_reward = np.append(current_reward, reward[i])
                current_epsilon = np.append(current_epsilon, self.epsilon_full[self.num_k + i, j])

            if len(current_reward) != 0:
              S = ((current_epsilon[:int(len(current_epsilon)/2)] * current_epsilon[:int(len(current_epsilon)/2)] - sigma[k, j] * sigma[k, j]) / sigma[k, j]*self.omiga[k, j])
              reward_avg = (current_reward[:int(len(current_reward)/2)] + current_reward[int(len(current_reward)/2):]) / 2.0
              rS = reward_avg - b[k]

              delta_sigma[k, j] = (np.dot(rS, S)) / (2 * len(current_reward)/2 * stdev_reward)
            else:
              delta_sigma[k, j] = 0
          # adjust sigma according to the adaptive sigma calculation
        # for stability, don't let sigma move more than 10% of orig value
        change_sigma = self.sigma_alpha * (delta_sigma + self.sigma_lamba*sigma_entropy_grad)

        # print('sigma-loss1:\n', self.sigma_alpha * delta_sigma)
        # print('sigma-loss2:\n', self.sigma_lamba*sigma_entropy_grad)

        change_sigma = np.minimum(change_sigma, self.sigma_max_change * self.sigma)
        change_sigma = np.maximum(change_sigma, - self.sigma_max_change * self.sigma)
        self.sigma += change_sigma
        self.sigma = np.clip(self.sigma, 0.0, 0.15)

        if (self.sigma_decay < 1):
          self.sigma[self.sigma > self.sigma_limit] *= self.sigma_decay

    if (self.learning_rate_decay < 1 and self.learning_rate > self.learning_rate_limit):
      self.learning_rate *= self.learning_rate_decay

    # adaptive omiga
    if self.update_omiga:
      change_omiga = np.zeros([self.num_k, self.num_params])
      for j in range(self.num_params):
        for k in range(self.num_k):
          current_reward = np.array([])
          for i in range(len(F)):
            if int(F[i, j]) == k:
              current_reward = np.append(current_reward, reward[i])
          if len(current_reward) != 0:
            rT = (current_reward[:int(len(current_reward) / 2)] - current_reward[int(len(current_reward) / 2):])
            change_omiga[k, j] = sum(rT) / self.omiga[k, j]*len(rT)
          else:
            change_omiga[k, j] = 0

      change_omiga_all = self.omiga_alpha*(change_omiga + self.omiga_lamba * omiga_entropy_grad)
      # print('omiga-loss1:\n', change_omiga)
      # print('omiga-loss2:\n', self.omiga_lamba*omiga_entropy_grad)

      change_omiga_all = np.minimum(change_omiga_all, self.omiga_max_change * self.omiga)
      change_omiga_all = np.maximum(change_omiga_all, - self.omiga_max_change * self.omiga)
      self.omiga += change_omiga_all
      self.omiga = np.clip(self.omiga, 10e-8, 1.0-10e-8)
      # 按列归一化
      for i in range(self.num_params):
        # self.omiga[:, i] = (self.omiga[:, i] - min(self.omiga[:, i])) / (max(self.omiga[:, i])-min(self.omiga[:, i]))
        self.omiga[:, i] = self.omiga[:, i]/sum(self.omiga[:, i])


  def current_param(self):
    return self.curr_best_mu

  def set_mu(self, mu):
    self.mu = np.array(mu)

  def best_param(self):
    return self.best_mu

  def result(self):  # return best params so far, along with historically best reward, curr reward, sigma
    return (self.best_mu, self.best_reward, self.curr_best_reward, self.sigma, self.omiga)



def NES_GMM_search_step(model, label, ckpt_path, mood, mu_start=None, sigma_start=None):
  args = get_opts()
  search_num = args.search_num
  
  if search_num == 6:

    if mood == 'init' or mood == 'eval_test':
      MAX_ITERATION = args.iteration
    else:
      MAX_ITERATION = args.iteration_warmstart
    POPSIZE = args.popsize
    NUM_PARAMS = 6
    NUM_K = args.num_k
    N_JOBS = 10
    max_stop_fitness = 6.0
    # 搜索六维空间，th phi gamma r x y
    solver = PEPG(num_params=NUM_PARAMS,  # number of model parameters
                  num_k = NUM_K,
                  sigma_init=0.1,  # initial standard deviation
                  sigma_update=True,  # 不大幅更新sigma
                  learning_rate=0.1,  # learning rate for standard deviation
                  learning_rate_decay=0.99, # don't anneal the learning rate
                  learning_rate_limit=0,
                  popsize=POPSIZE,  # population size
                  average_baseline=False,  # set baseline to average of batch
                  weight_decay=0.00,  # weight decay coefficient
                  rank_fitness=True,  # use rank rather than fitness numbers
                  forget_best=False,
                  mu_lambda=args.mu_lamba,
                  sigma_lambda=args.sigma_lamba,
                  omiga_lamba=args.omiga_lamba,
                  random_begin=args.random_begin,
                  omiga_alpha=0.02,
                  mood = mood,
                  mu_start=mu_start,
                  sigma_start=sigma_start
                  )
    history = []
    fitness_origin = []
    for j in range(MAX_ITERATION):
      solutions = solver.ask()
      mu_entropy_grad, sigma_entropy_grad, omiga_entropy_grad = solver.comput_entropy()

      # gamma (-60,60)
      solutions[:, 0] = 30 * np.tanh(solutions[:, 0])
      # th (-180,180)
      solutions[:, 1] = 180 * np.tanh(solutions[:, 1])
      # phi (-60, 60)
      solutions[:, 2] = 70 * np.tanh(solutions[:, 2])
      # r (4, 6)
      solutions[:, 3] = np.tanh(solutions[:, 3]) + 4
      # x (-1, 1)
      solutions[:, 4] = 0.5 * np.tanh(solutions[:, 4])
      # x (-1, 1)
      solutions[:, 5] = 0.5 * np.tanh(solutions[:, 5])

      fitness_list = np.zeros(solver.popsize)

      #  多进程工作
      # with joblib.Parallel(n_jobs=N_JOBS) as parallel:
      #   #for i in tqdm(range(solver.popsize)):
      #     #fitness_list[i] = comput_fitness(solutions[i])

      #   fitness_list = parallel(joblib.delayed(comput_fitness)(solutions[i], solver.sigma) for i in tqdm(range(solver.batch_size*2+solver.num_k)))

      fitness_list = comput_fitness(model, label, ckpt_path, solutions, is_viewfool=False)
      
      solver.tell(fitness_list, mu_entropy_grad, sigma_entropy_grad, omiga_entropy_grad)
      result = solver.result()  # first element is the best solution, second element is the best fitness

      fitness_origin.append(np.max(fitness_list))
      history.append(result[1])
      average_fitness = np.mean(fitness_list)

      # if (j + 1) % 10 == 0:
        # print("================================================================")
        # print("fitness at iteration\n", (j + 1), max(fitness_origin))
        # print("average fitness at iteration\n", (j + 1), average_fitness)
      
 
    mu = result[0]
    sigma = result[3]
    Entropy = solver.entropy

    return mu, sigma, Entropy



class GMFool:

  def __init__(self, dist_pool_mu=None, dist_pool_sigma=None, mood='init'):

    args = get_opts()
    if mood == 'init' or mood == 'warm_start':
      all_class = os.listdir(f'{args.ckpt_attack_path}/train/')
    else: # eval_test
      all_class = os.listdir(f'{args.ckpt_attack_path}/test/')
    all_class.sort()
    class_num = len(all_class)
    self.class_num = class_num
    self.all_class = all_class
    # object_num = len(os.listdir(f'{args.ckpt_attack_path}/' + all_class[0] + '/'))
    object_num = 10

    self.dist_pool_mu = dist_pool_mu
    self.dist_pool_sigma = dist_pool_sigma


  def step(self, class_id, all_class, model, mood):
      args = get_opts()
      object_num = 10
      mu_result = np.zeros([object_num, args.num_k, 6])
      sigma_result = np.zeros([object_num, args.num_k, 6])
      Entropy_class = 0

      if mood == 'init' or mood == 'warm_start':
        path = f'{args.ckpt_attack_path}/train/'
      else:
        path = f'{args.ckpt_attack_path}/test/'

      all_object = os.listdir(path + all_class[class_id] + '/')
      all_object.sort()

      if args.fast_AVDT:  #轮流优化策略，每次随机优化一个物体的参数
        if mood == 'init' or mood == 'eval_test':
          for object_id in range(len(all_object)):
            ckpt_path = path + all_class[class_id] + '/' + all_object[object_id]
            label = int(all_class[class_id])
            mu, sigma, Entropy = NES_GMM_search_step(model, label, ckpt_path, mood)
            Entropy_class += Entropy

            mu_result[object_id, :, :] = mu
            sigma_result[object_id, :, :] = sigma
          rand = None

        elif mood == 'warm_start':
          rand = int(np.random.random_integers(0, len(all_object)-1, size=1))
          ckpt_path = path + all_class[class_id] + '/' + all_object[rand]
          label = int(all_class[class_id])

          mu_start = self.dist_pool_mu[class_id, rand, :, :]
          sigma_start = self.dist_pool_sigma[class_id, rand, :, :]
          mu, sigma, Entropy = NES_GMM_search_step(model, label, ckpt_path, mood, mu_start, sigma_start)
          Entropy_class += Entropy

          mu_result[rand, :, :] = mu
          sigma_result[rand, :, :] = sigma

      else:
        for object_id in range(len(all_object)):
          ckpt_path = path + all_class[class_id] + '/' + all_object[object_id]
          label = int(all_class[class_id])

          if mood == 'init' or mood == 'eval_test':
            mu, sigma, Entropy = NES_GMM_search_step(model, label, ckpt_path, mood)
            Entropy_class += Entropy

          elif mood == 'warm_start':
            mu_start = self.dist_pool_mu[class_id, object_id, :, :]
            sigma_start = self.dist_pool_sigma[class_id, object_id, :, :]
            mu, sigma, Entropy = NES_GMM_search_step(model, label, ckpt_path, mood, mu_start, sigma_start)
            Entropy_class += Entropy

          mu_result[object_id, :, :] = mu
          sigma_result[object_id, :, :] = sigma

        rand = None

      return mu_result, sigma_result, rand, Entropy_class
    

def NES_GMM_search(model, dist_pool_mu, dist_pool_sigma, mood='init'):

  args = get_opts()
  method = 'para'
  
  GMFool_solver = GMFool(dist_pool_mu=dist_pool_mu, dist_pool_sigma=dist_pool_sigma, mood=mood)
  
  if mood == 'init' or mood == 'eval_test':
    dist_pool_mu_return = np.zeros([GMFool_solver.class_num, 10, args.num_k, 6])
    dist_pool_sigma_return = np.zeros([GMFool_solver.class_num, 10, args.num_k, 6])
  elif mood == 'warm_start':
    dist_pool_mu_return = dist_pool_mu
    dist_pool_sigma_return = dist_pool_sigma

  #-----------------------------------并行-------------------------------------------------------------
  if method == 'para':
    with joblib.Parallel(n_jobs=5) as parallel:
      res = parallel(joblib.delayed(GMFool_solver.step)(class_id, GMFool_solver.all_class, model, mood) for class_id in tqdm(range(GMFool_solver.class_num)))

    mu_result = [item[0] for item in res]
    sigma_result = [item[1] for item in res]
    rand = [item[2] for item in res]
    Entropy_class = [item[3] for item in res]

    average_entropy = sum(Entropy_class)/len(Entropy_class)

    if mood == 'init' or mood == 'eval_test':
      for i in range(len(mu_result)):
        dist_pool_mu_return[i, :, :, :] = mu_result[i]
        dist_pool_sigma_return[i, :, :, :] = sigma_result[i]

    elif mood == 'warm_start' and not args.fast_AVDT:
      for i in range(len(mu_result)):
        dist_pool_mu_return[i, :, :, :] = mu_result[i]
        dist_pool_sigma_return[i, :, :, :] = sigma_result[i]

    elif mood == 'warm_start' and args.fast_AVDT:
      for i in range(len(mu_result)):
        mu = mu_result[i]
        sigma = sigma_result[i]
        dist_pool_mu_return[i, rand[i], :, :] = mu[rand[i], :, :]
        dist_pool_sigma_return[i, rand[i], :, :] = sigma[rand[i], :, :]

  #-----------------------------------串行-------------------------------------------------------------
  else:
    for class_id in tqdm(range(GMFool_solver.class_num)):
      mu_result, sigma_result, rand, Entropy_class = GMFool_solver.step(class_id, GMFool_solver.all_class, model, mood)
      if mood == 'init' or mood == 'eval_test':
        dist_pool_mu_return[class_id, :, :, :] = mu_result
        dist_pool_sigma_return[class_id, :, :, :] = sigma_result

      elif mood == 'warm_start' and not args.fast_AVDT:
        dist_pool_mu_return[class_id, :, :, :] = mu_result
        dist_pool_sigma_return[class_id, :, :, :] = sigma_result

      elif mood == 'warm_start' and args.fast_AVDT:
        dist_pool_mu_return[class_id, rand, :, :] = mu_result
        dist_pool_sigma_return[class_id, rand, :, :] = sigma_result
#-----------------------------------------------------------------------------------------------------------
  
  # print("mu_result:", dist_pool_mu_return)
  # print("sigma_result:", dist_pool_sigma_return)

  print("average_entropy:", average_entropy)

  if mood == 'init' or mood == 'warm_start':
    np.save(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy', dist_pool_mu_return)
    np.save(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy', dist_pool_sigma_return)
  else:
    np.save(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}_{mood}.npy', dist_pool_mu_return)
    np.save(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}_{mood}.npy', dist_pool_sigma_return)


--- 文件地址: viat/NES_viewfool_forAT.py ---
import numpy as np
import os
from evaluate_forAT import comput_fitness
from rendering_image import render_image
from classifier.predict import test_baseline
from tqdm import tqdm
from datasets.opts import get_opts
import joblib
import torch
import time
np.set_printoptions(precision=4,  linewidth=100, suppress=True)
# np.random.seed(0)

def compute_ranks(x):
  """
  Returns ranks in [0, len(x))
  Note: This is different from scipy.stats.rankdata, which returns ranks in [1, len(x)].
  (https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/es.py)
  """
  assert x.ndim == 1
  ranks = np.empty(len(x), dtype=int)
  ranks[x.argsort()] = np.arange(len(x))
  return ranks

def compute_centered_ranks(x):
  """
  https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/es.py
  """
  y = compute_ranks(x.ravel()).reshape(x.shape).astype(np.float32)
  y /= (x.size - 1)
  y -= .5
  return y

def compute_normalize(x):
  mean = np.mean(x)
  var = np.var(x)
  y = x-mean/var
  return y

def compute_weight_decay(weight_decay, model_param_list):
  model_param_grid = np.array(model_param_list)
  return - weight_decay * np.mean(model_param_grid * model_param_grid, axis=1)

# adopted from:
# https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/optimizers.py

class Optimizer(object):
  def __init__(self, pi, epsilon=1e-08):
    self.pi = pi
    self.dim = pi.num_params
    self.epsilon = epsilon
    self.t = 0

  def update(self, globalg):
    self.t += 1
    step = self._compute_step(globalg)
    theta = self.pi.mu
    ratio = np.linalg.norm(step) / (np.linalg.norm(theta) + self.epsilon)
    self.pi.mu = theta + step
    return ratio

  def _compute_step(self, globalg):
    raise NotImplementedError


class BasicSGD(Optimizer):
  def __init__(self, pi, stepsize):
    Optimizer.__init__(self, pi)
    self.stepsize = stepsize

  def _compute_step(self, globalg):
    step = -self.stepsize * globalg
    return step

class SGD(Optimizer):
  def __init__(self, pi, stepsize, momentum=0.9):
    Optimizer.__init__(self, pi)
    self.v = np.zeros(self.dim, dtype=np.float32)
    self.stepsize, self.momentum = stepsize, momentum

  def _compute_step(self, globalg):
    self.v = self.momentum * self.v + (1. - self.momentum) * globalg
    step = -self.stepsize * self.v
    return step


class Adam(Optimizer):
  def __init__(self, pi, stepsize, beta1=0.99, beta2=0.999):
    Optimizer.__init__(self, pi)
    self.stepsize = stepsize
    self.beta1 = beta1
    self.beta2 = beta2
    self.m = np.zeros(self.dim, dtype=np.float32)
    self.v = np.zeros(self.dim, dtype=np.float32)

  def _compute_step(self, globalg):
    a = self.stepsize * np.sqrt(1 - self.beta2 ** self.t) / (1 - self.beta1 ** self.t)
    self.m = self.beta1 * self.m + (1 - self.beta1) * globalg
    self.v = self.beta2 * self.v + (1 - self.beta2) * (globalg * globalg)
    step = -a * self.m / (np.sqrt(self.v) + self.epsilon)
    return step


class PEPG:
  '''Extension of PEPG with bells and whistles.'''

  def __init__(self, num_params,  # number of model parameters
               sigma_init=0.10,  # initial standard deviation
               sigma_alpha=0.20,  # learning rate for standard deviation
               sigma_decay=0.999,  # anneal standard deviation
               sigma_limit=0.01,  # stop annealing if less than this
               sigma_max_change=0.2,  # clips adaptive sigma to 20%
               sigma_min=0.05,  # 允许的最小sigma
               sigma_update=True,
               learning_rate=0.01,  # learning rate for standard deviation
               learning_rate_decay=0.9999,  # annealing the learning rate
               learning_rate_limit=0.01,  # stop annealing learning rate
               elite_ratio=0,  # if > 0, then ignore learning_rate
               popsize=256,  # population size
               average_baseline=True,  # set baseline to average of batch
               weight_decay=0.01,  # weight decay coefficient
               rank_fitness=True,  # use rank rather than fitness numbers
               forget_best=True,
               mu_lambda=0.0001,
               sigma_lambda=0.0001):  # don't keep the historical best solution

    self.num_params = num_params
    self.sigma_init = sigma_init
    self.sigma_alpha = sigma_alpha
    self.sigma_decay = sigma_decay
    self.sigma_limit = sigma_limit
    self.sigma_max_change = sigma_max_change
    self.learning_rate = learning_rate
    self.learning_rate_decay = learning_rate_decay
    self.learning_rate_limit = learning_rate_limit
    self.popsize = popsize
    self.average_baseline = average_baseline
    self.sigma_update = sigma_update
    self.sigma_min = sigma_min
    self.mu_lamba = mu_lambda
    self.sigma_lamba = sigma_lambda

    if self.average_baseline:
      assert (self.popsize % 2 == 0), "Population size must be even"
      self.batch_size = int(self.popsize / 2)
    else:
      assert (self.popsize & 1), "Population size must be odd"
      self.batch_size = int((self.popsize - 1) / 2)

    # option to use greedy es method to select next mu, rather than using drift param
    self.elite_ratio = elite_ratio
    self.elite_popsize = int(self.popsize * self.elite_ratio)
    self.use_elite = False
    if self.elite_popsize > 0:
      self.use_elite = True

    self.forget_best = forget_best
    self.batch_reward = np.zeros(self.batch_size * 2)
    self.mu = np.zeros(self.num_params)
    self.sigma = np.ones(self.num_params) * self.sigma_init
    self.curr_best_mu = np.zeros(self.num_params)
    self.best_mu = np.zeros(self.num_params)
    self.best_reward = 0
    self.first_interation = True
    self.weight_decay = weight_decay
    self.rank_fitness = rank_fitness
    if self.rank_fitness:
      self.forget_best = True  # always forget the best one if we rank
    # choose optimizer
    self.optimizer = SGD(self, learning_rate)

  def rms_stdev(self):
    sigma = self.sigma
    return np.mean(np.sqrt(sigma * sigma))

  def ask(self):
    '''returns a list of parameters'''
    # antithetic sampling
    self.epsilon = np.random.randn(self.batch_size, self.num_params) * self.sigma.reshape(1, self.num_params)
    self.epsilon_full = np.concatenate([self.epsilon, - self.epsilon])
    if self.average_baseline:
      epsilon = self.epsilon_full
    else:
      # first population is mu, then positive epsilon, then negative epsilon
      epsilon = np.concatenate([np.zeros((1, self.num_params)), self.epsilon_full])
      self.r = epsilon/self.sigma.reshape(1, self.num_params)
    solutions = self.mu.reshape(1, self.num_params) + epsilon
    self.solutions = solutions
    return solutions

  def comput_entropy(self):
    # 计算每个批次的高斯分布的熵
    r = torch.Tensor(self.r)  # N(0,1)中的采样点
    sigma = torch.Tensor(self.sigma)
    sigma.requires_grad = True
    mu = torch.Tensor(self.mu)
    mu.requires_grad = True
    a = torch.Tensor([60, 180, 60, 1, 0.7, 0.7])    # 各个参数的前系数


    inside = 1-torch.pow(torch.tanh(mu+sigma*r), 2)+1e-8
    neg_logp = torch.log(sigma+1e-8) + 1/2*torch.pow(r, 2) + torch.log(inside)
    entropy = torch.sum(neg_logp, 0)/self.popsize

    Entropy = torch.sum(entropy)

    # 得到的Entropy是当前种群所有参数熵的总和

    # 梯度反向传播
    Entropy.backward()
    # 对于sigma，求这一批次中，每个参数的梯度之和作为这个参数的搜索方向 （11,6）->(1,6)
    # 对于mu，先求出（11,1）的熵，再将每个mu（1,6）对（11,1）的每列求导 得到 （11,6）的梯度
    mu_entropy_grad = mu.grad.clone()
    sigma_entropy_grad = sigma.grad.clone()
    # 梯度清零
    mu.grad.data.zero_()
    sigma.grad.data.zero_()
    self.entropy = Entropy

    return mu_entropy_grad.cpu().detach().numpy(), sigma_entropy_grad.cpu().detach().numpy()





  def tell(self, reward_table_result, mu_entropy_grad, sigma_entropy_grad):
    # input must be a numpy float array
    assert (len(reward_table_result) == self.popsize), "Inconsistent reward_table size reported."

    reward_table = np.array(reward_table_result)

    if self.rank_fitness:
      reward_table = compute_centered_ranks(reward_table)
      # reward_table = compute_normalize(reward_table)

    if self.weight_decay > 0:
      l2_decay = compute_weight_decay(self.weight_decay, self.solutions)
      reward_table += l2_decay

    reward_offset = 1
    if self.average_baseline:
      b = np.mean(reward_table)
      reward_offset = 0
    else:
      b = reward_table[0]  # baseline

    reward = reward_table[reward_offset:]
    if self.use_elite:
      idx = np.argsort(reward)[::-1][0:self.elite_popsize]
    else:
      idx = np.argsort(reward)[::-1]

    best_reward = reward[idx[0]]
    if (best_reward > b or self.average_baseline):
      best_mu = self.mu + self.epsilon_full[idx[0]]
      best_reward = reward[idx[0]]
    else:
      best_mu = self.mu
      best_reward = b

    self.curr_best_reward = best_reward
    self.curr_best_mu = best_mu

    if self.first_interation:
      self.sigma = np.ones(self.num_params) * self.sigma_init
      self.first_interation = False
      self.best_reward = self.curr_best_reward
      self.best_mu = best_mu
    else:
      if self.forget_best or (self.curr_best_reward > self.best_reward):
        self.best_mu = best_mu
        self.best_reward = self.curr_best_reward

    # short hand
    epsilon = self.epsilon
    sigma = self.sigma

    # update the mean

    # move mean to the average of the best idx means
    if self.use_elite:
      self.mu += self.epsilon_full[idx].mean(axis=0)
    else:
      rT = (reward[:self.batch_size] - reward[self.batch_size:])
      change_mu = np.dot(rT, epsilon) + self.mu_lamba*mu_entropy_grad
      #print('rt:\n', rT)
      #print('epsilon', epsilon)
      # print('mu-loss1:', np.dot(rT, epsilon))
      # print('mu-loss2:', self.mu_lamba*mu_entropy_grad)

      self.optimizer.stepsize = self.learning_rate
      update_ratio = self.optimizer.update(-change_mu)  # adam, rmsprop, momentum, etc.
      # self.mu += (change_mu * self.learning_rate) # normal SGD method

    # adaptive sigma
    # normalization
    
    #if (self.sigma[a] > self.sigma_min for a in range(self.num_params)):
    if (self.sigma_alpha > 0 and self.sigma_update):
      stdev_reward = 1.0
      if not self.rank_fitness:
        stdev_reward = reward.std()
      S = ((epsilon * epsilon - (sigma * sigma).reshape(1, self.num_params)) / sigma.reshape(1, self.num_params))
      reward_avg = (reward[:self.batch_size] + reward[self.batch_size:]) / 2.0
      rS = reward_avg - b

      delta_sigma = (np.dot(rS, S)) / (2 * self.batch_size * stdev_reward)

      # adjust sigma according to the adaptive sigma calculation
      # for stability, don't let sigma move more than 10% of orig value
      change_sigma = self.sigma_alpha * (delta_sigma + self.sigma_lamba*sigma_entropy_grad)

      # print('sigma-loss1:', delta_sigma)
      # print('sigma-loss2:', self.sigma_lamba*sigma_entropy_grad)

      change_sigma = np.minimum(change_sigma, self.sigma_max_change * self.sigma)
      change_sigma = np.maximum(change_sigma, - self.sigma_max_change * self.sigma)
      self.sigma += change_sigma
      self.sigma = np.clip(self.sigma, 0.0, 0.15)

      if (self.sigma_decay < 1):
        self.sigma[self.sigma > self.sigma_limit] *= self.sigma_decay

    if (self.learning_rate_decay < 1 and self.learning_rate > self.learning_rate_limit):
      self.learning_rate *= self.learning_rate_decay

  def current_param(self):
    return self.curr_best_mu

  def set_mu(self, mu):
    self.mu = np.array(mu)

  def best_param(self):
    return self.best_mu

  def result(self):  # return best params so far, along with historically best reward, curr reward, sigma
    return (self.best_mu, self.best_reward, self.curr_best_reward, self.sigma, self.entropy)


def NES_viewfool_search_step(model, label, ckpt_path, mood, mu_start=None, sigma_start=None):
    args = get_opts()
    MAX_ITERATION = args.iteration
    POPSIZE = args.popsize
    NUM_PARAMS = 6
    N_JOBS = 3
    # 搜索六维空间，th phi gamma r x y
    solver = PEPG(num_params=NUM_PARAMS,  # number of model parameters
                  sigma_init=0.1,  # initial standard deviation
                  sigma_update=True,  # 不大幅更新sigma
                  learning_rate=0.1,  # learning rate for standard deviation
                  learning_rate_decay=0.99,
                  learning_rate_limit=0,  # don't anneal the learning rate
                  popsize=POPSIZE,  # population size
                  average_baseline=False,  # set baseline to average of batch
                  weight_decay=0.00,  # weight decay coefficient
                  rank_fitness=True,  # use rank rather than fitness numbers
                  forget_best=False,
                  mu_lambda=0.01,
                  sigma_lambda=0.01
                  )

    logging = {'mu': [], 'sigma': [], 'fitness': [], 'entropy':[]}
    history = []
    fitness_origin = []
    history_best_solution = []
    for j in range(MAX_ITERATION):
      solutions = solver.ask()
      mu_entropy_grad, sigma_entropy_grad = solver.comput_entropy()

      # gamma (-30,30)
      solutions[:, 0] = 30 * np.tanh(solutions[:, 0])
      # th (-180,180)
      solutions[:, 1] = 180 * np.tanh(solutions[:, 1])
      # phi (-70, 70)
      solutions[:, 2] = 70 * np.tanh(solutions[:, 2])
      # r (3, 5)
      solutions[:, 3] = np.tanh(solutions[:, 3]) + 4
      # x (-0.5, 0.5)
      solutions[:, 4] = 0.5 * np.tanh(solutions[:, 4])
      # x (-0.5, 0.5)
      solutions[:, 5] = 0.5 * np.tanh(solutions[:, 5])

      fitness_list = np.zeros(solver.popsize)


      #  多进程工作
      # with joblib.Parallel(n_jobs=N_JOBS) as parallel:
      #   #for i in tqdm(range(solver.popsize)):
      #     #fitness_list[i] = comput_fitness(solutions[i])

      #   fitness_list = parallel(joblib.delayed(comput_fitness)(solutions[i], solver.sigma) for i in tqdm(range(solver.popsize)))

      fitness_list = comput_fitness(model, label, ckpt_path, solutions, is_viewfool=True)

      solver.tell(fitness_list, mu_entropy_grad, sigma_entropy_grad)
      result = solver.result()  # first element is the best solution, second element is the best fitness

    mu = result[0]
    sigma = result[3]
    entropy = result[4]
    return mu, sigma, entropy

class ViewFool:
  def __init__(self, mood):
    args = get_opts()
    if mood == 'train':
      all_class = os.listdir(f'{args.ckpt_attack_path}/train/')
    else: # eval_test
      all_class = os.listdir(f'{args.ckpt_attack_path}/test/')
    all_class.sort()
    class_num = len(all_class)
    self.class_num = class_num
    self.all_class = all_class
    # object_num = len(os.listdir(f'{args.ckpt_attack_path}/' + all_class[0] + '/'))
    object_num = 10

    self.dist_pool_mu_return = np.zeros([class_num, object_num, 6])
    self.dist_pool_sigma_return = np.zeros([class_num, object_num, 6])

  def step_viewfool(self, class_id, all_class, model, mood):
      args = get_opts()
      object_num = 10
      mu_result = np.zeros([object_num, 6])
      sigma_result = np.zeros([object_num, 6])
      Entropy_class = 0

      if mood == 'train':
        path = f'{args.ckpt_attack_path}/train/'
      else:
        path = f'{args.ckpt_attack_path}/test/'

      all_object = os.listdir(path + all_class[class_id] + '/')
      all_object.sort()
      
      for object_id in range(len(all_object)):
        ckpt_path = path + all_class[class_id] + '/' + all_object[object_id]
        label = int(all_class[class_id])
        mu, sigma, entropy = NES_viewfool_search_step(model, label, ckpt_path, mood)

        mu_result[object_id, :] = mu
        sigma_result[object_id, :] = sigma
        Entropy_class += entropy
        
      return mu_result, sigma_result, Entropy_class

def NES_viewfool_search(model, mood='test'):

  args = get_opts()
  method = 'para'
  viewfool_solver = ViewFool(mood=mood)

  dist_pool_mu_return = np.zeros([viewfool_solver.class_num, 10, 6])
  dist_pool_sigma_return = np.zeros([viewfool_solver.class_num, 10, 6])
  
#-----------------------------------并行-------------------------------------------------------------
  if method == 'para':
    with joblib.Parallel(n_jobs=5) as parallel:
      res = parallel(joblib.delayed(viewfool_solver.step_viewfool)(class_id, viewfool_solver.all_class, model, mood) for class_id in tqdm(range(viewfool_solver.class_num)))
      mu_result = [item[0] for item in res]
      sigma_result = [item[1] for item in res]
      Entropy = [item[2] for item in res]

      average_entropy = sum(Entropy)/len(Entropy)
    for i in range(len(mu_result)):
      dist_pool_mu_return[i, :, :] = mu_result[i]
      dist_pool_sigma_return[i, :, :] = sigma_result[i]

#-----------------------------------串行-------------------------------------------------------------
  else:
    for class_id in tqdm(range(viewfool_solver.class_num)):
      mu_result, sigma_result = viewfool_solver.step_viewfool(class_id, viewfool_solver.all_class, model, mood)
      dist_pool_mu_return[i, :, :] = mu_result
      dist_pool_sigma_return[i, :, :] = sigma_result

  print("entropy:", average_entropy)
  np.save(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}_viewfool_{mood}.npy', dist_pool_mu_return)
  np.save(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}_viewfool_{mood}.npy', dist_pool_sigma_return)
--- 文件地址: viat/attack_NES.py ---
from rendering_image import render_image
import numpy as np
from PIL import Image
from NES import NES_search
#from xNES import xNES_search
from NES_GMM import NES_GMM_search

from datasets.opts import get_opts

args = get_opts()

if args.optim_method == 'NES':
    #NES_search()
    NES_GMM_search()
else:
    xNES_search()
--- 文件地址: viat/benchmark.py ---
from __future__ import print_function
import os
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torch.optim as optim
from torchvision import datasets, transforms

from trades import trades_loss

from PIL import Image  
import numpy as np
import torchvision.models as models
from models.networks import NGP
from models.rendering import render
from metrics import psnr

from tqdm import tqdm
from datasets import dataset_dict
from datasets.ray_utils import get_rays
from utils import load_ckpt
from train import depth2img
import imageio
import joblib
import timm

from robustness import model_utils
from robustness.datasets import ImageNet


from datasets.opts import get_opts

# 用于寻找攻击的 dist_pool 需要遍历当前所有存在的物体 保存dist_pool.npy（为了warm-star操作）
from NES_GMM_forAT import NES_GMM_search
from NES_viewfool_forAT import NES_viewfool_search


args = get_opts()
def get_black_model(model_name):
    checkpoint = None
    flag = 0
    # vgg
    if model_name == 'vgg16':
        model = timm.create_model('vgg16', pretrained=True)
    if model_name == 'vgg19':
        model = timm.create_model('vgg19', pretrained=True)

    # resnet:
    if model_name == 'resnet18':
        model = timm.create_model('resnet18', pretrained=True)
    if model_name == 'resnet34':
        model = timm.create_model('resnet34', pretrained=True)
    if model_name == 'resnet50':
        model = timm.create_model('resnet50', pretrained=True)
    if model_name == 'resnet101':
        model = timm.create_model('resnet101', pretrained=True)
    if model_name == 'resnet152':
        model = timm.create_model('resnet152', pretrained=True)
    
    # inc
    if model_name == 'inc_v3':
        model = timm.create_model('inception_v3', pretrained=True)
    if model_name == 'inc_v4':
        model = timm.create_model('inception_v4', pretrained=True)
    if model_name == 'inc_res_v2':
        model = timm.create_model('inception_resnet_v2', pretrained=True)

    # dense
    if model_name == 'densenet121':
        model = timm.create_model('densenet121', pretrained=True)
    if model_name == 'densenet169':
        model = timm.create_model('densenet169', pretrained=True)
    if model_name == 'densenet201':
        model = timm.create_model('densenet201', pretrained=True)

    # effe
    if model_name == 'en_b0':
        model = timm.create_model('efficientnet_b0', pretrained=True)
    if model_name == 'en_b1':
        model = timm.create_model('efficientnet_b1', pretrained=True)
    if model_name == 'en_b2':
        model = timm.create_model('efficientnet_b2', pretrained=True)
    if model_name == 'en_b3':
        model = timm.create_model('efficientnet_b3', pretrained=True)
    if model_name == 'en_b4':
        model = timm.create_model('efficientnet_b4', pretrained=True)

    # mobile
    if model_name == 'mobilenetv2_120d':
        model = timm.create_model('mobilenetv2_120d', pretrained=True)
    if model_name == 'mobilenetv2_140':
        model = timm.create_model('mobilenetv2_140', pretrained=True)
    
    # vit
    if model_name == 'vit_base':
        model = timm.create_model('vit_base_patch16_224', pretrained=True)
    if model_name == 'vit_large':
        model = timm.create_model('vit_large_patch16_224', pretrained=True)

    # deit
    if model_name == 'deit_tiny':
        model = timm.create_model('deit_tiny_patch16_224', pretrained=True)
    if model_name == 'deit_small':
        model = timm.create_model('deit_small_patch16_224', pretrained=True)
    if model_name == 'deit_base':
        model = timm.create_model('deit_base_patch16_224', pretrained=True)

    # swin
    if model_name == 'swin_tiny':
        model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True)
    if model_name == 'swin_small':
        model = timm.create_model('swin_small_patch4_window7_224', pretrained=True)
    if model_name == 'swin_base':
        model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)
    if model_name == 'swin_large':
        model = timm.create_model('swin_large_patch4_window7_224', pretrained=True)

    # mixer
    if model_name == 'mixer_b16':
        model = timm.create_model('mixer_b16_224', pretrained=True)
    if model_name == 'mixer_l16':
        model = timm.create_model('mixer_l16_224', pretrained=True)
    
    # augmix
    if model_name == 'augmix':
        model = timm.create_model('resnet50', pretrained=False)
        checkpoint = '/data/home/scv7303/.cache/torch/hub/checkpoints/augmix.pth.tar'
        flag = 1
    if model_name == 'deepaugment':
        model = timm.create_model('resnet50', pretrained=False)
        checkpoint = '/data/home/scv7303/.cache/torch/hub/checkpoints/deepaugment.pth.tar'
        flag = 1
    if model_name == 'augmix+deepaugment':
        model = timm.create_model('resnet50', pretrained=False)
        checkpoint = '/data/home/scv7303/.cache/torch/hub/checkpoints/deepaugment_and_augmix.pth.tar'
        flag = 1

    # l2robust
    if model_name == 'resnet50_l2_robust_eps=1.0':
        model = timm.create_model('resnet50', pretrained=False)
        checkpoint = '/data/home/scv7303/.cache/torch/hub/checkpoints/resnet50_l2_eps1.ckpt'
        flag = 2
    if model_name == 'resnet50_l2_robust_eps=3.0':
        model = timm.create_model('resnet50', pretrained=False)
        checkpoint = '/data/home/scv7303/.cache/torch/hub/checkpoints/resnet50_l2_eps3.ckpt'
        flag = 2
    if model_name == 'resnet50_l2_robust_eps=5.0':
        model = timm.create_model('resnet50', pretrained=False)
        checkpoint = '/data/home/scv7303/.cache/torch/hub/checkpoints/resnet50_l2_eps5.ckpt'
        flag = 2

    # VIAT
    if model_name == 'resnet50-standard':
        model = timm.create_model('resnet50', pretrained=True, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-res50-epoch120.pt'
        model.load_state_dict(torch.load(checkpoint))

    if model_name == 'resnet50-VIAT-gf':
        model = timm.create_model('resnet50', pretrained=True, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-resnet50-final_res_viatgf_R-epoch60.pt'
        model.load_state_dict(torch.load(checkpoint))

    if model_name == 'resnet50-VIAT-vf':
        model = timm.create_model('resnet50', pretrained=True, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-resnet50-final_res_viatvf_R-epoch60.pt'
        model.load_state_dict(torch.load(checkpoint))

    if model_name == 'resnet50-VIAT-natural':
        model = timm.create_model('resnet50', pretrained=True, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-resnet50-final_res_natural-epoch60.pt'
        model.load_state_dict(torch.load(checkpoint))

    if model_name == 'resnet50-VIAT-random':
        model = timm.create_model('resnet50', pretrained=True, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-resnet50-final_res_random-epoch60.pt'
        model.load_state_dict(torch.load(checkpoint))

    if model_name == 'vit-standard':
        model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-vit-b-vit-b_pre_train-epoch10.pt'
        model.load_state_dict(torch.load(checkpoint))
    
    if model_name == 'vit-VIAT-gf':
        model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-vit-b-final_vit_viatgf_R-epoch60.pt'
        model.load_state_dict(torch.load(checkpoint))
    
    if model_name == 'vit-VIAT-vf':
        model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-vit-b-final_vit_viatvf_R-epoch60.pt'
        model.load_state_dict(torch.load(checkpoint))
    
    if model_name == 'vit-VIAT-natural':
        model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-vit-b-final_vit_natural-epoch60.pt'
        model.load_state_dict(torch.load(checkpoint))
    
    if model_name == 'vit-VIAT-random':
        model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-vit-b-final_vit_random-epoch60.pt'
        model.load_state_dict(torch.load(checkpoint))

    if model_name == 'inc-VIAT-gf':
        # model = timm.create_model('inception_v3', pretrained=True, num_classes=100)
        model = torchvision.models.inception_v3(pretrained=False)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-inc-v3-final_inc_viatgf_R-epoch60.pt'
        #----------------------------------------------
        num_ftr = model.fc.in_features
        model.fc = nn.Linear(num_ftr,100)
        model.load_state_dict(torch.load(checkpoint))

    if model_name == 'inc-res-VIAT-gf':
        model = timm.create_model('inception_resnet_v2', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-inc-res-inc-res_viatgf_R-epoch60.pt'
        model.load_state_dict(torch.load(checkpoint))
    if model_name == 'en-VIAT-gf':
        model = timm.create_model('efficientnet_b0', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-en-en_viatgf_R-epoch60.pt'
        model.load_state_dict(torch.load(checkpoint))
    if model_name == 'dn-VIAT-gf':
        model = timm.create_model('densenet121', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-dn-dn_viatgf_R-epoch60.pt'
        model.load_state_dict(torch.load(checkpoint))
    if model_name == 'deit-VIAT-gf':
        model = timm.create_model('deit_base_patch16_224', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-deit-deit_viatgf_R-epoch60.pt'
        model.load_state_dict(torch.load(checkpoint))
    if model_name == 'swin-VIAT-gf':
        model = timm.create_model('swin_base_patch4_window7_224', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-swin-swin_viatgf_R-epoch40.pt'
        model.load_state_dict(torch.load(checkpoint))
        

    if checkpoint != None and flag==1:
        check = torch.load(checkpoint)
        arch = check['arch']
        model = models.__dict__[arch]()
        model = torch.nn.DataParallel(model, device_ids=gpus, output_device=gpus[0]).cuda()
        model.load_state_dict(check['state_dict'])
        model = model.to(device)
    
    # l2 robust
    elif checkpoint != None and flag==2:
        imagenet_ds = ImageNet('data/pathl')
        model , _ = model_utils.make_and_restore_model(arch="resnet50", dataset=imagenet_ds, 
resume_path=checkpoint, parallel=False, add_custom_forward=True)
        model = model.to(device)
        model = torch.nn.DataParallel(model, device_ids=gpus, output_device=gpus[0])
        # model.eval()
        # model.cuda()
        # transform = transforms.Compose([transforms.Resize((248, 248)),transforms.CenterCrop(224),transforms.ToTensor(), ])

    else:
    # model.load_state_dict(torch.load(checkpoint))
        model = model.to(device)
        model = torch.nn.DataParallel(model, device_ids=gpus, output_device=gpus[0])
    
    model.eval()

    return model


# ------------------------------------------------------------------------------------------------------------- #


# settings
model_dir = args.model_dir
if not os.path.exists(model_dir):
    os.makedirs(model_dir)
use_cuda = not args.no_cuda and torch.cuda.is_available()
torch.manual_seed(args.seed)
device=torch.device("cuda:0" )
gpus = [0, 1]
# gpus = [0, 1, 2, 3]

kwargs = {'num_workers': 10*len(gpus), 'pin_memory': True} if use_cuda else {}

# setup data loader

valdir = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/adv_view_all/adv_view_gmfool_vit'

test_loader = torch.utils.data.DataLoader(
        datasets.ImageFolder(valdir, transforms.Compose([
            transforms.Resize(args.img_size),
            transforms.CenterCrop(args.crop_size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],       
                                      std=[0.229, 0.224, 0.225])
        ])),
        batch_size=args.batch_size, shuffle=False, **kwargs)





def eval_test(model_name, map_label, model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            # print(target)
            # for i in range(len(target)):
            #     map_label_ = map_label[target[i].numpy()]
            #     target[i] = int(map_label_)
            # print(target.shape)
            data, target = data.to(device), target.to(device)
            output = model(data)
            # print(output.shape)
            # new_output = torch.zeros((num,100), dtype=torch.float).to(device)
            # for k in range(num):
            #     for i in range(len(map_label)):
            #         for j in range(len(output)):
            #             if j == map_label[i]:
            #                 new_output[k,i] = output[k, j]
            # print(output)
            # print(output[0,403])
            # print(new_output)
            # print(new_output[0, 1])
            # output = new_output
            if type(output) == tuple:
                output = output[0]
            test_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    test_loss /= len(test_loader.dataset)
    print('result to {}: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(
        model_name, test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))
    test_accuracy = correct / len(test_loader.dataset)
    return test_loss, test_accuracy




def main():
    with open('/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/label_map.txt') as f:
        map_label = [line.strip() for line in f.readlines()]

    # model_list = ['augmix','deepaugment','augmix+deepaugment','resnet50_l2_robust_eps=1.0','resnet50_l2_robust_eps=3.0','resnet50_l2_robust_eps=5.0','vgg16','vgg19','resnet18','resnet34','resnet50','resnet101','resnet152','inc_v3','inc_v4','inc_res_v2','densenet121','densenet169','densenet201','en_b0','en_b1','en_b2','en_b3','en_b4','mobilenetv2_120d','mobilenetv2_140','vit_base','vit_large','deit_tiny','deit_small','deit_base','swin_tiny','swin_small','swin_base','swin_large','mixer_b16','mixer_l16']
    
    # model_list = ['resnet50', 'inc_v3', 'vit_base', 'inc_res_v2', 'densenet121', 'en_b0', 'deit_base', 'swin_base']
    # model_list = ['resnet50-VIAT', 'vit-VIAT']

    model_list = ['deit-VIAT-gf', 'swin-VIAT-gf']
    
    for i in tqdm(range(len(model_list))):
        model = get_black_model(model_list[i])
        # evaluation on natural examples
        print('================================================================')
        eval_test(model_list[i], map_label, model, device, test_loader)
        print('================================================================')


if __name__ == '__main__':
    main()

--- 文件地址: viat/evaluate.py ---
from rendering_image import render_image
import numpy as np
import cv2 as cv
from PIL import Image
from torchvision import models
from torchvision import transforms
import torch
import torch.nn as nn
#import matplotlib.pyplot as plt
from datasets.opts import get_opts
import time
'''
    定义NES每个方案的适应度
'''

def metric(prediction, label, target_label, target_flag):
    loss_func = nn.CrossEntropyLoss()
    if target_flag == False:
        # 对于无目标攻击，loss值越大，代表攻击越成功
        loss = loss_func(prediction, label)
    else:
        # 对于无目标攻击，loss的负值越大，说明loss越小，越接近，代表攻击越成功
        loss = - loss_func(prediction, target_label)
    return loss


def compute_ver(sigma, mu, num_sample=1000):
  # 计算多元高斯分布熵

  random = np.zeros([num_sample, 6])
  gamma = np.random.normal(loc=mu[0], scale=sigma[0], size=num_sample)
  th = np.random.normal(loc=mu[1], scale=sigma[1], size=num_sample)
  phi = np.random.normal(loc=mu[2], scale=sigma[2], size=num_sample)
  r = np.random.normal(loc=mu[3], scale=sigma[3], size=num_sample)
  a = np.random.normal(loc=mu[4], scale=sigma[4], size=num_sample)
  b = np.random.normal(loc=mu[5], scale=sigma[5], size=num_sample)
  random[:, 0] = gamma
  random[:, 1] = th
  random[:, 2] = phi
  random[:, 3] = r
  random[:, 4] = a
  random[:, 5] = b
  mu = random.mean(axis=0)
  var = (random - mu).T @ (random - mu) / random.shape[0]

  loss_var = - np.log(np.linalg.det(var))
  loss_var = 0.03 * loss_var
  return loss_var

@torch.no_grad()
def comput_fitness(solution):
    '''

    Args:
        solution: 当前采样到的参数值 (th, phi, r)
    Returns:
        reward: 适应度值
    '''
    args = get_opts()

    # 利用求得的参数渲染一幅图像
    transform = transforms.Compose([
        transforms.Resize(size=256),
        transforms.CenterCrop(size=224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ])

    with torch.no_grad():
        x = render_image(solution) # ndarray [N,W,H,C]

    x = np.array(x)

    tensors = torch.zeros(x.shape[0], x.shape[3], 224, 224)
    for i in range(len(x)):
        img = x[i, :]
        img = Image.fromarray(img)
        tensor = transform(img)
        tensors[i,:,:,:] = tensor

    # print(tensors.shape)
    # print(f"tensor shape: {tensor.shape}, max: {torch.max(tensor)}, min: {torch.min(tensor)}") # (c,h,w)
    # tensor = torch.unsqueeze(tensor, 0)  # 返回一个新的tensor,对输入的既定位置插入维度1
    # print(f"tensor shape: {tensor.shape}, max: {torch.max(tensor)}, min: {torch.min(tensor)}") # (1,c,h,w)
    tensors = tensors.cuda()

    model = models.resnet50(pretrained=False)
    checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/NeRF/ckpts/resnet50-0676ba61.pth'

    # model = models.inception_v3(pretrained=False)
    # checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/NeRF/ckpts/inception_v3_google-0cc3c7bd.pth'

    #model = models.vit_b_16(pretrained=False)
    #checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/NeRF/ckpts/vit_b_16-c867db91.pth'

    model.load_state_dict(torch.load(checkpoint))
    model.cuda()

    model.eval()
    with torch.no_grad():
        # 得到预测的softmax向量
        prediction = model(tensors)

    true_label = np.zeros((1, 1000))
    true_label[:, args.label] = 1.0
    true_label = torch.from_numpy(true_label)

    target_label = np.zeros((1, 1000))
    """
    584: hair slide
    650: microphone, mike
    """

    target_label[:, args.target_label] = 1.0
    target_label = torch.from_numpy(target_label)

    rewards = []
    for i in range(x.shape[0]):
        reward = metric(prediction[i].unsqueeze(0), label=true_label.cuda(), target_label=target_label, target_flag=args.target_flag)
        reward = reward.cpu().detach().numpy()
        rewards += [reward]
    # loss_var = compute_ver(sigma, solution)
    # print('分类损失：', reward)
    # print('高斯熵损失：', 0.5*loss_var)

    return rewards






--- 文件地址: viat/evaluate_forAT.py ---
from rendering_image_forAT import render_image
import numpy as np
import cv2 as cv
from PIL import Image
from torchvision import models
from torchvision import transforms
import torch
import torch.nn as nn
#import matplotlib.pyplot as plt
from datasets.opts import get_opts
import time
'''
    定义NES每个方案的适应度
'''

def metric(prediction, label, target_label=0, target_flag=False):
    loss_func = nn.CrossEntropyLoss()
    if target_flag == False:
        # 对于无目标攻击，loss值越大，代表攻击越成功
        loss = loss_func(prediction, label)
    else:
        # 对于无目标攻击，loss的负值越大，说明loss越小，越接近，代表攻击越成功
        loss = - loss_func(prediction, target_label)
    return loss


@torch.no_grad()
def comput_fitness(model, label, ckpt_path, solution, is_viewfool):
    '''

    Args:
        solution: 当前采样到的参数值 (th, phi, r)
    Returns:
        reward: 适应度值
    '''
    args = get_opts()

    # 利用求得的参数渲染一幅图像
    transform = transforms.Compose([
        transforms.Resize(size=256),
        transforms.CenterCrop(size=224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ])

    with torch.no_grad():
        x = render_image(solution, ckpt_path, is_viewfool=is_viewfool) # ndarray [N,W,H,C]

    x = np.array(x)

    tensors = torch.zeros(x.shape[0], x.shape[3], 224, 224)
    for i in range(len(x)):
        img = x[i, :]
        img = Image.fromarray(img)
        tensor = transform(img)
        tensors[i,:,:,:] = tensor

    tensors = tensors.cuda()


    model.eval()
    with torch.no_grad():
        # 得到预测的softmax向量
        prediction = model(tensors)

    # true_label = np.zeros((1, 1000))
    # true_label[:, label] = 1.0
    # true_label = torch.from_numpy(true_label)

    label = torch.LongTensor([label])
    # print('current class:', label)

    rewards = []
    for i in range(x.shape[0]):
        reward = metric(prediction[i].unsqueeze(0), label=label.cuda())
        reward = reward.cpu().detach().numpy()
        rewards += [reward]
    # loss_var = compute_ver(sigma, solution)
    # print('分类损失：', reward)
    # print('高斯熵损失：', 0.5*loss_var)

    return rewards






--- 文件地址: viat/losses.py ---
import torch
from torch import nn
import vren


class DistortionLoss(torch.autograd.Function):
    """
    Distortion loss proposed in Mip-NeRF 360 (https://arxiv.org/pdf/2111.12077.pdf)
    Implementation is based on DVGO-v2 (https://arxiv.org/pdf/2206.05085.pdf)

    Inputs:
        ws: (N) sample point weights
        deltas: (N) considered as intervals
        ts: (N) considered as midpoints
        rays_a: (N_rays, 3) ray_idx, start_idx, N_samples
                meaning each entry corresponds to the @ray_idx th ray,
                whose samples are [start_idx:start_idx+N_samples]

    Outputs:
        loss: (N_rays)
    """
    @staticmethod
    def forward(ctx, ws, deltas, ts, rays_a):
        loss, ws_inclusive_scan, wts_inclusive_scan = \
            vren.distortion_loss_fw(ws, deltas, ts, rays_a)
        ctx.save_for_backward(ws_inclusive_scan, wts_inclusive_scan, ws, deltas, ts, rays_a)
        return loss

    @staticmethod
    def backward(ctx, dL_dloss):
        ws_inclusive_scan, wts_inclusive_scan, ws, deltas, ts, rays_a = ctx.saved_tensors
        dL_dws = vren.distortion_loss_bw(dL_dloss, ws_inclusive_scan, wts_inclusive_scan,
                                         ws, deltas, ts, rays_a)
        return dL_dws, None, None, None


class NeRFLoss(nn.Module):
    def __init__(self, lambda_opacity=1e-3, lambda_distortion=1e-3):
        super().__init__()

        self.lambda_opacity = lambda_opacity
        self.lambda_distortion = lambda_distortion

    def forward(self, results, target, **kwargs):
        d = {}
        d['rgb'] = (results['rgb']-target['rgb'])**2

        o = results['opacity']+1e-10
        # encourage opacity to be either 0 or 1 to avoid floater
        d['opacity'] = self.lambda_opacity*(-o*torch.log(o))

        if self.lambda_distortion > 0:
            d['distortion'] = self.lambda_distortion * \
                DistortionLoss.apply(results['ws'], results['deltas'],
                                     results['ts'], results['rays_a'])

        return d

--- 文件地址: viat/metrics.py ---
import torch


def mse(image_pred, image_gt, valid_mask=None, reduction='mean'):
    value = (image_pred-image_gt)**2
    if valid_mask is not None:
        value = value[valid_mask]
    if reduction == 'mean':
        return torch.mean(value)
    return value


@torch.no_grad()
def psnr(image_pred, image_gt, valid_mask=None, reduction='mean'):
    return -10*torch.log10(mse(image_pred, image_gt, valid_mask, reduction))

--- 文件地址: viat/opt.py ---
import argparse

def get_opts():
    parser = argparse.ArgumentParser()

    # dataset parameters
    parser.add_argument('--root_dir', type=str, required=True,
                        help='root directory of dataset')
    parser.add_argument('--dataset_name', type=str, default='nsvf',
                        choices=['nerf', 'nsvf', 'colmap', 'nerfpp', 'rtmv'],
                        help='which dataset to train/test')
    parser.add_argument('--split', type=str, default='train',
                        choices=['train', 'trainval', 'trainvaltest'],
                        help='use which split to train')
    parser.add_argument('--downsample', type=float, default=1.0,
                        help='downsample factor (<=1.0) for the images')

    # model parameters
    parser.add_argument('--scale', type=float, default=0.5,
                        help='scene scale (whole scene must lie in [-scale, scale]^3')
    parser.add_argument('--use_exposure', action='store_true', default=False,
                        help='whether to train in HDR-NeRF setting')

    # loss parameters
    parser.add_argument('--distortion_loss_w', type=float, default=0,
                        help='''weight of distortion loss (see losses.py),
                        0 to disable (default), to enable,
                        a good value is 1e-3 for real scene and 1e-2 for synthetic scene
                        ''')

    # training options
    parser.add_argument('--batch_size', type=int, default=8192,
                        help='number of rays in a batch')
    parser.add_argument('--ray_sampling_strategy', type=str, default='all_images',
                        choices=['all_images', 'same_image'],
                        help='''
                        all_images: uniformly from all pixels of ALL images
                        same_image: uniformly from all pixels of a SAME image
                        ''')
    parser.add_argument('--num_epochs', type=int, default=30,
                        help='number of training epochs')
    parser.add_argument('--num_gpus', type=int, default=1,
                        help='number of gpus')
    parser.add_argument('--lr', type=float, default=1e-2,
                        help='learning rate')
    # experimental training options
    parser.add_argument('--optimize_ext', action='store_true', default=False,
                        help='whether to optimize extrinsics')
    parser.add_argument('--random_bg', action='store_true', default=False,
                        help='''whether to train with random bg color (real scene only)
                        to avoid objects with black color to be predicted as transparent
                        ''')

    # validation options
    parser.add_argument('--eval_lpips', action='store_true', default=False,
                        help='evaluate lpips metric (consumes more VRAM)')
    parser.add_argument('--val_only', action='store_true', default=False,
                        help='run only validation (need to provide ckpt_path)')
    parser.add_argument('--no_save_test', action='store_true', default=False,
                        help='whether to save test image and video')

    # misc
    parser.add_argument('--exp_name', type=str, default='exp',
                        help='experiment name')
    parser.add_argument('--ckpt_path', type=str, default=None,
                        help='pretrained checkpoint to load (including optimizers, etc)')
    parser.add_argument('--weight_path', type=str, default=None,
                        help='pretrained checkpoint to load (excluding optimizers, etc)')

    return parser.parse_args()

--- 文件地址: viat/rendering_image.py ---
import warnings
warnings.filterwarnings('ignore', '.*FullyFusedMLP.*')

import torch
import time
import os
import numpy as np
from models.networks import NGP
from models.rendering import render
from metrics import psnr

from tqdm import tqdm
from datasets import dataset_dict
from datasets.ray_utils import get_rays
from utils import load_ckpt
from train import depth2img
import imageio
from datasets.opts import get_opts
import joblib


# dataset_name = 'nerf'
# scene = 'hotdog'
# dataset = dataset_dict[dataset_name](
#     f'/data/home/run/scv7303/rsw_/NeRFAttack/ngp_pl/dataset_source/{scene}',
#     split='test', downsample=1.0
# )

# exp_name = 'ngp_hotdog_nerf'
# model = NGP(scale=0.5).cuda()
# load_ckpt(model, f'ckpts/{dataset_name}/{exp_name}/epoch=19_slim.ckpt')

# psnrs = []; ts=0; imgs = []; depths = []
# os.makedirs(f'results/{dataset_name}/{scene}_traj', exist_ok=True)


# for img_idx in tqdm(range(len(dataset))):
#     t = time.time()
#     rays_o, rays_d = get_rays(dataset.directions.cuda(), dataset[img_idx]['pose'].cuda())
#     results = render(model, rays_o, rays_d,
#                      **{'test_time': True,
#                         'T_threshold': 1e-2
#                         })
#     torch.cuda.synchronize()
#     ts += time.time()-t

#     pred = results['rgb'].reshape(dataset.img_wh[1], dataset.img_wh[0], 3).cpu().numpy()
#     pred = (pred*255).astype(np.uint8)
#     #depth = results['depth'].reshape(dataset.img_wh[1], dataset.img_wh[0]).cpu().numpy()
#     #depth_ = depth2img(depth)
#     imgs += [pred]
#     #depths += [depth_]
#     imageio.imwrite(f'results/{dataset_name}/{scene}_traj/{img_idx:03d}.png', pred)
#     #imageio.imwrite(f'results/{dataset_name}/{scene}_traj/{img_idx:03d}_d.png', depth_)

#     # if dataset.split != 'test_traj':
#     #     rgb_gt = dataset[img_idx]['rgb'].cuda()
#     #     psnrs += [psnr(results['rgb'], rgb_gt).item()]
# # if psnrs: print(f'mean PSNR: {np.mean(psnrs):.2f}, min: {np.min(psnrs):.2f}, max: {np.max(psnrs):.2f}')
# # print(f'mean time: {np.mean(ts):.4f} s, FPS: {1/np.mean(ts):.2f}')
# # print(f'mean samples per ray: {results["total_samples"]/len(rays_d):.2f}')

# if len(imgs)>30:
#     imageio.mimsave(f'results/{dataset_name}/{scene}_traj/rgb.mp4', imgs, fps=30)
#     # imageio.mimsave(f'results/{dataset_name}/{scene}_traj/depth.mp4', depths, fps=30)

# print('cost_time:', ts)
import time


@torch.no_grad()
def render_image(all_args, is_over=False):
    args = get_opts()

    dataset = dataset_dict[args.dataset_name](
        root_dir=args.root_dir,
        split='test', downsample=0.5, all_args=all_args, is_over=is_over
    )

    model = NGP(scale=0.5).cuda()
    load_ckpt(model, args.ckpt_path)

    save_path = f'results/{args.dataset_name}/{args.scene_name}'
    os.makedirs(save_path, exist_ok=True)

    imgs = []

    for img_idx in range(len(dataset)):
        rays_o, rays_d = get_rays(dataset.directions.cuda(), dataset[img_idx]['pose'].cuda())
        results = render(model, rays_o, rays_d,
                        **{'test_time': True,
                            'T_threshold': 1e-2
                            })
        torch.cuda.synchronize()
        #TS += time.time()-t
        pred = results['rgb'].reshape(dataset.img_wh[1], dataset.img_wh[0], 3).cpu().numpy()
        pred = (pred*255).astype(np.uint8)
        imgs += [pred]
        if is_over:
            imageio.imwrite(os.path.join(save_path, f'{img_idx:03d}.png'), pred)
    
    return imgs



    # with joblib.Parallel(n_jobs=args.n_jobs) as parallel:
    #     imgs = parallel(joblib.delayed(render_one)(idx) for idx in range(len(dataset)))

    # return imgs

--- 文件地址: viat/rendering_image_forAT.py ---
import warnings
warnings.filterwarnings('ignore', '.*FullyFusedMLP.*')

import torch
import time
import os
import numpy as np
from models.networks import NGP
from models.rendering import render
from metrics import psnr

from tqdm import tqdm
from datasets import dataset_dict
from datasets.ray_utils import get_rays
from utils import load_ckpt
from train import depth2img
import imageio
from datasets.opts import get_opts
import joblib


# dataset_name = 'nerf'
# scene = 'hotdog'
# dataset = dataset_dict[dataset_name](
#     f'/data/home/run/scv7303/rsw_/NeRFAttack/ngp_pl/dataset_source/{scene}',
#     split='test', downsample=1.0
# )

# exp_name = 'ngp_hotdog_nerf'
# model = NGP(scale=0.5).cuda()
# load_ckpt(model, f'ckpts/{dataset_name}/{exp_name}/epoch=19_slim.ckpt')

# psnrs = []; ts=0; imgs = []; depths = []
# os.makedirs(f'results/{dataset_name}/{scene}_traj', exist_ok=True)


# for img_idx in tqdm(range(len(dataset))):
#     t = time.time()
#     rays_o, rays_d = get_rays(dataset.directions.cuda(), dataset[img_idx]['pose'].cuda())
#     results = render(model, rays_o, rays_d,
#                      **{'test_time': True,
#                         'T_threshold': 1e-2
#                         })
#     torch.cuda.synchronize()
#     ts += time.time()-t

#     pred = results['rgb'].reshape(dataset.img_wh[1], dataset.img_wh[0], 3).cpu().numpy()
#     pred = (pred*255).astype(np.uint8)
#     #depth = results['depth'].reshape(dataset.img_wh[1], dataset.img_wh[0]).cpu().numpy()
#     #depth_ = depth2img(depth)
#     imgs += [pred]
#     #depths += [depth_]
#     imageio.imwrite(f'results/{dataset_name}/{scene}_traj/{img_idx:03d}.png', pred)
#     #imageio.imwrite(f'results/{dataset_name}/{scene}_traj/{img_idx:03d}_d.png', depth_)

#     # if dataset.split != 'test_traj':
#     #     rgb_gt = dataset[img_idx]['rgb'].cuda()
#     #     psnrs += [psnr(results['rgb'], rgb_gt).item()]
# # if psnrs: print(f'mean PSNR: {np.mean(psnrs):.2f}, min: {np.min(psnrs):.2f}, max: {np.max(psnrs):.2f}')
# # print(f'mean time: {np.mean(ts):.4f} s, FPS: {1/np.mean(ts):.2f}')
# # print(f'mean samples per ray: {results["total_samples"]/len(rays_d):.2f}')

# if len(imgs)>30:
#     imageio.mimsave(f'results/{dataset_name}/{scene}_traj/rgb.mp4', imgs, fps=30)
#     # imageio.mimsave(f'results/{dataset_name}/{scene}_traj/depth.mp4', depths, fps=30)

# print('cost_time:', ts)
import time


@torch.no_grad()
def render_image(all_args, ckpt_path, is_over=False, is_viewfool=False):
    args = get_opts()

    dataset = dataset_dict[args.dataset_name](
        root_dir=args.root_dir,
        split='test', downsample=0.5, all_args=all_args, is_over=is_over, is_viewfool=is_viewfool
    )

    model = NGP(scale=0.5).cuda()
    load_ckpt(model, ckpt_path)

    imgs = []

    for img_idx in range(len(dataset)):
        rays_o, rays_d = get_rays(dataset.directions.cuda(), dataset[img_idx]['pose'].cuda())
        results = render(model, rays_o, rays_d,
                        **{'test_time': True,
                            'T_threshold': 1e-2
                            })
        torch.cuda.synchronize()
        #TS += time.time()-t
        pred = results['rgb'].reshape(dataset.img_wh[1], dataset.img_wh[0], 3).cpu().numpy()
        pred = (pred*255).astype(np.uint8)
        imgs += [pred]
    
    return imgs



--- 文件地址: viat/run_Attack_1.sh ---
#!/bin/bash
#SBATCH --gpus=1

# 激活conda环境
# 注意: 如果您的conda环境不是全局的，可能需要先 source ~/.bashrc
# module load anaconda/2020.11 # 如果需要的话
source activate viat

# 切换到项目主目录，这是一个好习惯，可以避免很多相对路径问题
cd /hy-tmp/VIAT/

echo "当前工作目录: $(pwd)"
echo "开始运行攻击脚本..."

# 使用绝对路径运行Python脚本
python viat/Attack_exp_fast_K.py \
    \
    # ------------------- 数据集和NeRF模型相关路径 -------------------
    # 1. NeRF数据集的根目录 (用于加载相机参数，以airliner_01为例)
    --root_dir '/hy-tmp/VIAT/datasets/GMFool_dataset/airliner_01' \
    \
    # 2. 任意一个NeRF模型的检查点路径 (用于初始化)
    --ckpt_path '/hy-tmp/VIAT/run_train_nerf/ckpts/nerf/train/00/00.ckpt' \
    \
    # 3. [最关键!] 所有NeRF检查点的根目录 (指向train/test的父目录)
    --ckpt_attack_path '/hy-tmp/VIAT/run_train_nerf/ckpts/nerf' \
    \
    # ------------------- 脚本运行参数 -------------------
    --dataset_name nerf_for_attack \
    --scene_name 'results_resnet_GMM_hotdog' \
    --N_importance 64 \
    --optim_method NES \
    --search_num 6 \
    --popsize 101 \
    --iteration 50 \
    --iteration_warmstart 10 \
    --mu_lamba 0.05 \
    --sigma_lamba 0.05 \
    --omiga_lamba 0.05 \
    --num_sample 100 \
    --train_mood 'AT' \
    --batch-size 512 \
    --test-batch-size 512 \
    --lr 0.001 \
    --epochs 90 \
    --no_background \
    --share_dist \
    \
    # ------------------- 攻击目标和实验命名 -------------------
    # 4. 确认要攻击的目标模型名称
    --treat_model 'resnet50' \
    \
    # 5. 实验名称，用于保存结果
    --AT_exp_name 'k5_attack_experiment' \
    --num_k 5

echo "脚本运行结束。"
--- 文件地址: viat/run_benchmark.sh ---
#!/bin/bash
#SBATCH --gpus=1
module load anaconda/2020.11
source activate fastNeRF

python benchmark.py --root_dir '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --train_mood 'AT' --batch-size 512 --test-batch-size 128 --AT_exp_name 'test_k=1' --lr 0.001 --epochs 1 --num_k 1 --no_background --fast_AVDT --share_dist --AT_type 'AVDT' --share_dist_rate 0 --ckpt_attack_path './run_train_NeRF/ckpts/nerf/dataset_all'
--- 文件地址: viat/run_minibatch_train.sh ---
#!/bin/bash

export PYTHONPATH="${PWD}"

python viat/train_trades_imagenet_viewpoint_new.py \
    --root_dir 'datasets/GMFool_dataset/airliner_01' \
    --ckpt_path 'run_train_nerf/ckpts/nerf/train/00/00.ckpt' \
    --ckpt_attack_path 'run_train_nerf/ckpts/nerf' \
    --epochs 2 \
    --batch-size 32 \
    --test-batch-size 32 \
    --iteration 10 \
    --iteration_warmstart 5 \
    --popsize 21 \
    # --save_freq 1 \  <-- 删掉这一行
    --treat_model 'resnet50' \
    --AT_exp_name 'minibatch_test_run' \
    --dataset_name nerf_for_attack \
    --train_mood 'AT' \
    --AT_type 'AVDT' \
    --num_k 5 \
    --share_dist \
    --share_dist_rate 0.5 \
    --no_background
--- 文件地址: viat/run_train_AT.sh ---
#!/bin/bash
#SBATCH --gpus=1
module load anaconda/2020.11
source activate fastNeRF

# python train_trades_imagenet_viewpoint_new.py --root_dir '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --num_k 1 --train_mood 'AT' --batch-size 512 --test-batch-size 512 --lr 0.001 --epochs 90 --AT_exp_name 'test' --no_background --fast_AVDT --share_dist --AT_type 'AVDT' --share_dist_rate 0.5 --ckpt_attack_path './ckpts/nerf'

#-------------------------------

# 1
python train_trades_imagenet_viewpoint_new.py --root_dir '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --train_mood 'AT' --batch-size 512 --test-batch-size 512 --AT_exp_name 'test_k=1' --lr 0.001 --epochs 1 --num_k 1 --no_background --fast_AVDT --share_dist --AT_type 'AVDT' --share_dist_rate 0 --ckpt_attack_path './run_train_NeRF/ckpts/nerf/dataset_all'

# 2
#python train_trades_imagenet_viewpoint_new.py --root_dir '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --train_mood 'AT' --batch-size 512 --test-batch-size 512 --AT_exp_name 'test_k=5' --lr 0.001 --epochs 90 --num_k 5 --no_background --fast_AVDT --share_dist --AT_type 'AVDT' --share_dist_rate 0 --ckpt_attack_path './run_train_NeRF/ckpts/nerf/dataset_all'

# 3
#python train_trades_imagenet_viewpoint_new.py --root_dir '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --train_mood 'AT' --batch-size 512 --test-batch-size 512 --AT_exp_name 'test_k=10' --lr 0.001 --epochs 90 --num_k 10 --no_background --fast_AVDT --share_dist --AT_type 'AVDT' --share_dist_rate 0 --ckpt_attack_path './run_train_NeRF/ckpts/nerf/dataset_all'

# 4
#python train_trades_imagenet_viewpoint_new.py --root_dir '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --train_mood 'AT' --batch-size 512 --test-batch-size 512 --AT_exp_name 'test_k=15' --lr 0.001 --epochs 90 --num_k 15 --no_background --fast_AVDT --share_dist --AT_type 'AVDT' --share_dist_rate 0 --ckpt_attack_path './run_train_NeRF/ckpts/nerf/dataset_all'

# 5
#python train_trades_imagenet_viewpoint_new.py --root_dir '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --train_mood 'AT' --batch-size 512 --test-batch-size 512 --AT_exp_name 'test_k=20' --lr 0.001 --epochs 90 --num_k 20 --no_background --fast_AVDT --share_dist --AT_type 'AVDT' --share_dist_rate 0 --ckpt_attack_path './run_train_NeRF/ckpts/nerf/dataset_all'

# 6
#python train_trades_imagenet_viewpoint_new.py --root_dir '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --train_mood 'AT' --batch-size 512 --test-batch-size 512 --AT_exp_name 'test_k=25' --lr 0.001 --epochs 90 --num_k 25 --no_background --fast_AVDT --share_dist --AT_type 'AVDT' --share_dist_rate 0 --ckpt_attack_path './run_train_NeRF/ckpts/nerf/dataset_all'

#----------------------------------------------------------------
# --no_background  --share_dist   './run_train_NeRF/ckpts/nerf/dataset_all'

# 第一次实验全部是 lr=0.001  376570 376370   
# 第二次开始设置 lr=0.01  377804
# lr=0.1 377805
--- 文件地址: viat/run_train_AT_final_res_viatgf_R.sh ---
#!/bin/bash
#SBATCH --gpus=1
#module load anaconda/2020.11
#source activate fastNeRF

# 1
python viat/train_trades_imagenet_viewpoint_new.py --root_dir '/hy-tmp/VIAT/datasets/GMFool_dataset/airliner_01' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --train_mood 'AT' --batch-size 512 --test-batch-size 512 --AT_exp_name 'converage_resnet' --lr 0.001 --epochs 120 --num_k 15 --no_background --fast_AVDT --share_dist --AT_type 'AVDT' --share_dist_rate 0.5 --ckpt_attack_path './run_train_NeRF/ckpts/nerf/dataset_all' --treat_model 'resnet50'

--- 文件地址: viat/run_train_AT_final_res_viatgf_woR.sh ---
#!/bin/bash
#SBATCH --gpus=1
module load anaconda/2020.11
source activate fastNeRF


# 1
python train_trades_imagenet_viewpoint_new.py --root_dir '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --train_mood 'AT' --batch-size 512 --test-batch-size 512 --AT_exp_name 'final_res_viatgf_woR' --lr 0.001 --epochs 90 --num_k 15 --no_background --fast_AVDT --share_dist --AT_type 'AVDT' --share_dist_rate 0.0 --ckpt_attack_path './run_train_NeRF/ckpts/nerf/dataset_all' --treat_model 'resnet50'

--- 文件地址: viat/run_train_AT_final_res_viatvf_R.sh ---
#!/bin/bash
#SBATCH --gpus=1
module load anaconda/2020.11
source activate fastNeRF


# 1
python train_trades_imagenet_viewpoint_new.py --root_dir '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --train_mood 'AT' --batch-size 512 --test-batch-size 512 --AT_exp_name 'final_res_viatvf_R' --lr 0.001 --epochs 90 --num_k 15 --no_background --fast_AVDT --share_dist --AT_type 'AVDT' --share_dist_rate 0.5 --ckpt_attack_path './run_train_NeRF/ckpts/nerf/dataset_all' --treat_model 'resnet50'

--- 文件地址: viat/run_train_AT_final_res_viatvf_woR.sh ---
#!/bin/bash
#SBATCH --gpus=1
module load anaconda/2020.11
source activate fastNeRF


# 1
python train_trades_imagenet_viewpoint_new.py --root_dir '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --train_mood 'AT' --batch-size 512 --test-batch-size 512 --AT_exp_name 'final_res_viatvf_woR' --lr 0.001 --epochs 90 --num_k 1 --no_background --fast_AVDT --share_dist --AT_type 'AVDT' --share_dist_rate 0.0 --ckpt_attack_path './run_train_NeRF/ckpts/nerf/dataset_all' --treat_model 'resnet50'

--- 文件地址: viat/run_train_Attack_exp_2.sh ---
#!/bin/bash
#SBATCH --gpus=1
module load anaconda/2020.11
source activate fastNeRF

python Attack_exp.py --root_dir '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog' --dataset_name nerf_for_attack --scene_name 'resnet_GMM/hotdog' --N_importance 64 --ckpt_path '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/ckpts/nerf/ngp_hotdog_nerf/epoch=19_slim.ckpt' --optim_method NES --search_num 6 --popsize 101 --iteration 50 --iteration_warmstart 10 --mu_lamba 0.05 --sigma_lamba 0.05 --omiga_lamba 0.05 --num_sample 100 --num_k 5 --train_mood 'AT' --batch-size 512 --test-batch-size 512 --lr 0.001 --epochs 90 --AT_exp_name 'attack_incv3' --treat_model 'inc-v3' --no_background --share_dist --ckpt_attack_path './run_train_NeRF/ckpts/nerf/dataset_all'


--- 文件地址: viat/test_render.py ---
from rendering_image import render_image
import numpy as np

random = np.zeros([100, 6])
gamma = 0.0
th = np.linspace(-180, 180, 100)
phi = 0.0
r = 4.0
a = 0.0
b = 0.0

random[:, 0] = gamma
random[:, 1] = th
random[:, 2] = phi
random[:, 3] = r
random[:, 4] = a
random[:, 5] = b

render_image(random, is_over=True)
--- 文件地址: viat/trades.py ---
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import torch.optim as optim


def squared_l2_norm(x):
    flattened = x.view(x.unsqueeze(0).shape[0], -1)
    return (flattened ** 2).sum(1)


def l2_norm(x):
    return squared_l2_norm(x).sqrt()


def trades_loss(model,
                x_natural,
                y,
                optimizer,
                step_size=0.003,
                epsilon=0.031,
                perturb_steps=10,
                beta=1.0,
                distance='l_inf'):
    # define KL-loss
    criterion_kl = nn.KLDivLoss(size_average=False)
    model.eval()
    batch_size = len(x_natural)
    # generate adversarial example
    x_adv = x_natural.detach() + 0.001 * torch.randn(x_natural.shape).cuda().detach()
    if distance == 'l_inf':
        for _ in range(perturb_steps):
            x_adv.requires_grad_()
            with torch.enable_grad():
                loss_kl = criterion_kl(F.log_softmax(model(x_adv), dim=1),
                                       F.softmax(model(x_natural), dim=1))
            grad = torch.autograd.grad(loss_kl, [x_adv])[0]
            x_adv = x_adv.detach() + step_size * torch.sign(grad.detach())
            x_adv = torch.min(torch.max(x_adv, x_natural - epsilon), x_natural + epsilon)
            x_adv = torch.clamp(x_adv, 0.0, 1.0)
    elif distance == 'l_2':
        delta = 0.001 * torch.randn(x_natural.shape).cuda().detach()
        delta = Variable(delta.data, requires_grad=True)

        # Setup optimizers
        optimizer_delta = optim.SGD([delta], lr=epsilon / perturb_steps * 2)

        for _ in range(perturb_steps):
            adv = x_natural + delta

            # optimize
            optimizer_delta.zero_grad()
            with torch.enable_grad():
                loss = (-1) * criterion_kl(F.log_softmax(model(adv), dim=1),
                                           F.softmax(model(x_natural), dim=1))
            loss.backward()
            # renorming gradient
            grad_norms = delta.grad.view(batch_size, -1).norm(p=2, dim=1)
            delta.grad.div_(grad_norms.view(-1, 1, 1, 1))
            # avoid nan or inf if gradient is 0
            if (grad_norms == 0).any():
                delta.grad[grad_norms == 0] = torch.randn_like(delta.grad[grad_norms == 0])
            optimizer_delta.step()

            # projection
            delta.data.add_(x_natural)
            delta.data.clamp_(0, 1).sub_(x_natural)
            delta.data.renorm_(p=2, dim=0, maxnorm=epsilon)
        x_adv = Variable(x_natural + delta, requires_grad=False)
    else:
        x_adv = torch.clamp(x_adv, 0.0, 1.0)
    model.train()

    x_adv = Variable(torch.clamp(x_adv, 0.0, 1.0), requires_grad=False)
    # zero gradient
    optimizer.zero_grad()
    # calculate robust loss
    logits = model(x_natural)
    loss_natural = F.cross_entropy(logits, y)
    loss_robust = (1.0 / batch_size) * criterion_kl(F.log_softmax(model(x_adv), dim=1),
                                                    F.softmax(model(x_natural), dim=1))
    loss = loss_natural + beta * loss_robust
    return loss

--- 文件地址: viat/train.py ---
import torch
from torch import nn
from opt import get_opts
import os
import glob
import imageio
import numpy as np
import cv2
from einops import rearrange

# data
from torch.utils.data import DataLoader
from datasets import dataset_dict
from datasets.ray_utils import axisangle_to_R, get_rays

# models
from kornia.utils.grid import create_meshgrid3d
from models.networks import NGP
from models.rendering import render, MAX_SAMPLES

# optimizer, losses
from apex.optimizers import FusedAdam
from torch.optim.lr_scheduler import CosineAnnealingLR
from losses import NeRFLoss

# metrics
from torchmetrics import (
    PeakSignalNoiseRatio, 
    StructuralSimilarityIndexMeasure
)
from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity

# pytorch-lightning
from pytorch_lightning.plugins import DDPPlugin
from pytorch_lightning import LightningModule, Trainer
from pytorch_lightning.callbacks import TQDMProgressBar, ModelCheckpoint
from pytorch_lightning.loggers import TensorBoardLogger
from pytorch_lightning.utilities.distributed import all_gather_ddp_if_available

from utils import slim_ckpt, load_ckpt

import warnings; warnings.filterwarnings("ignore")


def depth2img(depth):
    depth = (depth-depth.min())/(depth.max()-depth.min())
    depth_img = cv2.applyColorMap((depth*255).astype(np.uint8),
                                  cv2.COLORMAP_TURBO)

    return depth_img


class NeRFSystem(LightningModule):
    def __init__(self, hparams):
        super().__init__()
        self.save_hyperparameters(hparams)

        self.warmup_steps = 256
        self.update_interval = 16

        self.loss = NeRFLoss(lambda_distortion=self.hparams.distortion_loss_w)
        self.train_psnr = PeakSignalNoiseRatio(data_range=1)
        self.val_psnr = PeakSignalNoiseRatio(data_range=1)
        self.val_ssim = StructuralSimilarityIndexMeasure(data_range=1)
        if self.hparams.eval_lpips:
            self.val_lpips = LearnedPerceptualImagePatchSimilarity('vgg')
            for p in self.val_lpips.net.parameters():
                p.requires_grad = False

        rgb_act = 'None' if self.hparams.use_exposure else 'Sigmoid'
        self.model = NGP(scale=self.hparams.scale, rgb_act=rgb_act)
        G = self.model.grid_size
        self.model.register_buffer('density_grid',
            torch.zeros(self.model.cascades, G**3))
        self.model.register_buffer('grid_coords',
            create_meshgrid3d(G, G, G, False, dtype=torch.int32).reshape(-1, 3))

    def forward(self, batch, split):
        if split=='train':
            poses = self.poses[batch['img_idxs']]
            directions = self.directions[batch['pix_idxs']]
        else:
            poses = batch['pose']
            directions = self.directions

        if self.hparams.optimize_ext:
            dR = axisangle_to_R(self.dR[batch['img_idxs']])
            poses[..., :3] = dR @ poses[..., :3]
            poses[..., 3] += self.dT[batch['img_idxs']]

        rays_o, rays_d = get_rays(directions, poses)

        kwargs = {'test_time': split!='train',
                  'random_bg': self.hparams.random_bg}
        if self.hparams.scale > 0.5:
            kwargs['exp_step_factor'] = 1/256
        if self.hparams.use_exposure:
            kwargs['exposure'] = batch['exposure']

        return render(self.model, rays_o, rays_d, **kwargs)

    def setup(self, stage):
        dataset = dataset_dict[self.hparams.dataset_name]
        kwargs = {'root_dir': self.hparams.root_dir,
                  'downsample': self.hparams.downsample}
        self.train_dataset = dataset(split=self.hparams.split, **kwargs)
        self.train_dataset.batch_size = self.hparams.batch_size
        self.train_dataset.ray_sampling_strategy = self.hparams.ray_sampling_strategy

        self.test_dataset = dataset(split='test', **kwargs)

    def configure_optimizers(self):
        # define additional parameters
        self.register_buffer('directions', self.train_dataset.directions.to(self.device))
        self.register_buffer('poses', self.train_dataset.poses.to(self.device))

        if self.hparams.optimize_ext:
            N = len(self.train_dataset.poses)
            self.register_parameter('dR',
                nn.Parameter(torch.zeros(N, 3, device=self.device)))
            self.register_parameter('dT',
                nn.Parameter(torch.zeros(N, 3, device=self.device)))

        load_ckpt(self.model, self.hparams.weight_path)

        net_params = []
        for n, p in self.named_parameters():
            if n not in ['dR', 'dT']: net_params += [p]

        opts = []
        self.net_opt = FusedAdam(net_params, self.hparams.lr, eps=1e-15)
        opts += [self.net_opt]
        if self.hparams.optimize_ext:
            opts += [FusedAdam([self.dR, self.dT], 1e-6)] # learning rate is hard-coded
        net_sch = CosineAnnealingLR(self.net_opt,
                                    self.hparams.num_epochs,
                                    self.hparams.lr/30)

        return opts, [net_sch]

    def train_dataloader(self):
        return DataLoader(self.train_dataset,
                          num_workers=16,
                          persistent_workers=True,
                          batch_size=None,
                          pin_memory=True)

    def val_dataloader(self):
        return DataLoader(self.test_dataset,
                          num_workers=8,
                          batch_size=None,
                          pin_memory=True)

    def on_train_start(self):
        self.model.mark_invisible_cells(self.train_dataset.K.to(self.device),
                                        self.poses,
                                        self.train_dataset.img_wh)

    def training_step(self, batch, batch_nb, *args):
        if self.global_step%self.update_interval == 0:
            self.model.update_density_grid(0.01*MAX_SAMPLES/3**0.5,
                                           warmup=self.global_step<self.warmup_steps,
                                           erode=self.hparams.dataset_name=='colmap')

        results = self(batch, split='train')
        loss_d = self.loss(results, batch)
        if self.hparams.use_exposure:
            zero_radiance = torch.zeros(1, 3, device=self.device)
            unit_exposure_rgb = self.model.log_radiance_to_rgb(zero_radiance,
                                    **{'exposure': torch.ones(1, 1, device=self.device)})
            loss_d['unit_exposure'] = \
                0.5*(unit_exposure_rgb-self.train_dataset.unit_exposure_rgb)**2
        loss = sum(lo.mean() for lo in loss_d.values())

        with torch.no_grad():
            self.train_psnr(results['rgb'], batch['rgb'])
        self.log('lr', self.net_opt.param_groups[0]['lr'])
        self.log('train/loss', loss)
        # ray marching samples per ray (occupied space on the ray)
        self.log('train/rm_s', results['rm_samples']/len(batch['rgb']), True)
        # volume rendering samples per ray (stops marching when transmittance drops below 1e-4)
        self.log('train/vr_s', results['vr_samples']/len(batch['rgb']), True)
        self.log('train/psnr', self.train_psnr, True)

        return loss

    def on_validation_start(self):
        torch.cuda.empty_cache()
        if not self.hparams.no_save_test:
            self.val_dir = f'results/{self.hparams.dataset_name}/{self.hparams.exp_name}'
            os.makedirs(self.val_dir, exist_ok=True)

    def validation_step(self, batch, batch_nb):
        rgb_gt = batch['rgb']
        results = self(batch, split='test')

        logs = {}
        # compute each metric per image
        self.val_psnr(results['rgb'], rgb_gt)
        logs['psnr'] = self.val_psnr.compute()
        self.val_psnr.reset()

        w, h = self.train_dataset.img_wh
        rgb_pred = rearrange(results['rgb'], '(h w) c -> 1 c h w', h=h)
        rgb_gt = rearrange(rgb_gt, '(h w) c -> 1 c h w', h=h)
        self.val_ssim(rgb_pred, rgb_gt)
        logs['ssim'] = self.val_ssim.compute()
        self.val_ssim.reset()
        if self.hparams.eval_lpips:
            self.val_lpips(torch.clip(rgb_pred*2-1, -1, 1),
                           torch.clip(rgb_gt*2-1, -1, 1))
            logs['lpips'] = self.val_lpips.compute()
            self.val_lpips.reset()

        if not self.hparams.no_save_test: # save test image to disk
            idx = batch['img_idxs']
            rgb_pred = rearrange(results['rgb'].cpu().numpy(), '(h w) c -> h w c', h=h)
            rgb_pred = (rgb_pred*255).astype(np.uint8)
            depth = depth2img(rearrange(results['depth'].cpu().numpy(), '(h w) -> h w', h=h))
            imageio.imsave(os.path.join(self.val_dir, f'{idx:03d}.png'), rgb_pred)
            imageio.imsave(os.path.join(self.val_dir, f'{idx:03d}_d.png'), depth)

        return logs

    def validation_epoch_end(self, outputs):
        psnrs = torch.stack([x['psnr'] for x in outputs])
        mean_psnr = all_gather_ddp_if_available(psnrs).mean()
        self.log('test/psnr', mean_psnr, True)

        ssims = torch.stack([x['ssim'] for x in outputs])
        mean_ssim = all_gather_ddp_if_available(ssims).mean()
        self.log('test/ssim', mean_ssim)

        if self.hparams.eval_lpips:
            lpipss = torch.stack([x['lpips'] for x in outputs])
            mean_lpips = all_gather_ddp_if_available(lpipss).mean()
            self.log('test/lpips_vgg', mean_lpips)

    def get_progress_bar_dict(self):
        # don't show the version number
        items = super().get_progress_bar_dict()
        items.pop("v_num", None)
        return items


if __name__ == '__main__':
    hparams = get_opts()
    if hparams.val_only and (not hparams.ckpt_path):
        raise ValueError('You need to provide a @ckpt_path for validation!')
    system = NeRFSystem(hparams)

    ckpt_cb = ModelCheckpoint(dirpath=f'ckpts/{hparams.dataset_name}/{hparams.exp_name}',
                              filename='{epoch:d}',
                              save_weights_only=True,
                              every_n_epochs=hparams.num_epochs,
                              save_on_train_epoch_end=True,
                              save_top_k=-1)
    callbacks = [ckpt_cb, TQDMProgressBar(refresh_rate=1)]

    logger = TensorBoardLogger(save_dir=f"logs/{hparams.dataset_name}",
                               name=hparams.exp_name,
                               default_hp_metric=False)

    trainer = Trainer(max_epochs=hparams.num_epochs,
                      check_val_every_n_epoch=hparams.num_epochs,
                      callbacks=callbacks,
                      logger=logger,
                      enable_model_summary=False,
                      accelerator='gpu',
                      devices=hparams.num_gpus,
                      strategy=DDPPlugin(find_unused_parameters=False)
                               if hparams.num_gpus>1 else None,
                      num_sanity_val_steps=-1 if hparams.val_only else 0,
                      precision=16)

    trainer.fit(system, ckpt_path=hparams.ckpt_path)
    
    

     # save slimmed ckpt for the last epoch
    ckpt_ = \
        slim_ckpt(f'ckpts/{hparams.dataset_name}/{hparams.exp_name}/epoch={hparams.num_epochs-1}.ckpt',
                      save_poses=hparams.optimize_ext)

    os.remove(f'ckpts/{hparams.dataset_name}/{hparams.exp_name}/epoch={hparams.num_epochs-1}.ckpt')

    exist = os.listdir(f'ckpts/{hparams.dataset_name}/{hparams.exp_name}/')
    if len(exist)==0:
        file_idx = 0
    else:
        file_idx = len(exist)
    file_idx = str('%02d' % file_idx)
    
    torch.save(ckpt_, f'ckpts/{hparams.dataset_name}/{hparams.exp_name}/{file_idx}.ckpt')
        

    if (not hparams.no_save_test) and \
       hparams.dataset_name=='nsvf' and \
       'Synthetic' in hparams.root_dir: # save 
        import time
        t1 = time.time()
        imgs = sorted(glob.glob(os.path.join(system.val_dir, '*.png')))
        t2 = time.time()

        imageio.mimsave(os.path.join(system.val_dir, 'rgb.mp4'),
                        [imageio.imread(img) for img in imgs[::2]],
                        fps=30, macro_block_size=1)
        imageio.mimsave(os.path.join(system.val_dir, 'depth.mp4'),
                        [imageio.imread(img) for img in imgs[1::2]],
                        fps=30, macro_block_size=1)

        print('time:', t2-t1)
--- 文件地址: viat/train_imagenet.py ---
from __future__ import print_function
import os
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torch.optim as optim
from torchvision import datasets, transforms

from trades import trades_loss

from PIL import Image  
import numpy as np
from models.networks import NGP
from models.rendering import render
from metrics import psnr

from tqdm import tqdm
from datasets import dataset_dict
from datasets.ray_utils import get_rays
from utils import load_ckpt
from train import depth2img
import imageio
import joblib
import timm


from datasets.opts import get_opts

# 用于寻找攻击的 dist_pool 需要遍历当前所有存在的物体 保存dist_pool.npy（为了warm-star操作）
from NES_GMM_forAT import NES_GMM_search
from NES_viewfool_forAT import NES_viewfool_search


args = get_opts()

@torch.no_grad()
def render_image(all_args, labels, objects, is_over=False, split='train'):
    """
    调用渲染函数 从viewpoints渲染一批图像
    Args:
        all_args: viewpoints array(batchsize, 6)
        labels: 每列viewpoint属于的类别号 array(batchszie, 1)
        batch_size: 每列viewpoint属于的类别中的物体序号 array(batchszie, 1)

    Returns: a batch of adversarial viewpoint rendering images

    ./ckpt/nerf/ 存放着所有物体的nerf权重
    -----------
    /913/00.pt
    /913/01.pt
    ... ... ...
    /913/09.pt
    -------------
    """

    dataset = dataset_dict['nerf_for_attack'](
        root_dir='/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog',
        split='AT', downsample=0.5, all_args=all_args, is_over=is_over
    )
    model = NGP(scale=0.5).cuda()
    
    # save_path = f'results/{args.dataset_name}/{args.scene_name}'
    # os.makedirs(save_path, exist_ok=True)
    imgs = np.zeros((len(dataset), 400, 400, 3))
    
    for img_idx in range(len(dataset)):
        
        ckpt_path = f'{args.ckpt_attack_path}/{split}/' + str('%02d' % int(labels[img_idx])) + '/' + str('%02d' % objects[img_idx]) + '.ckpt'
        load_ckpt(model, ckpt_path)

        rays_o, rays_d = get_rays(dataset.directions.cuda(), dataset[img_idx]['pose'].cuda())
        results = render(model, rays_o, rays_d,
                        **{'test_time': True,
                            'T_threshold': 1e-2
                            })
        torch.cuda.synchronize()
        #TS += time.time()-t
        pred = results['rgb'].reshape(dataset.img_wh[1], dataset.img_wh[0], 3).cpu().numpy()
        pred = (pred*255).astype(np.uint8)

        imgs[img_idx, :, :, :] = pred
        # if is_over:
        #     imageio.imwrite(os.path.join(save_path, f'{img_idx:03d}.png'), pred)

    return imgs


def AddBackground(render_imgs, clean_images, batch_size, split, flag='AT'):
    
    render_transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize(args.crop_size),
            transforms.ToTensor(),
        ])

    render_imgs_ = torch.zeros([len(render_imgs), 3, args.crop_size, args.crop_size])
    for i in range(len(render_imgs)):
        a = np.uint8(render_imgs[i,:,:,:])
        render_imgs_[i,:,:,:] = render_transform(a)
        #--------------------------------------------------------------------#
        # save = render_imgs_[i,:,:,:].numpy()
        # save = np.transpose(save, (1,2,0))
        # save = (save*255).astype(np.uint8)
        # # print(save)
        # # print(save.shape)
        # imageio.imwrite(os.path.join('./results', f'{i:03d}.png'), save)
        #--------------------------------------------------------------------#
        
    if split == 'train' and not args.no_background and flag == 'AT':
        for i in range(batch_size):
            background = torch.squeeze(clean_images[np.random.randint(low=0, high=batch_size, size=1),:,:,:])
            render = render_imgs_[i, :, :, :]
            # print('background',background.size())
            # print('render', render_imgs_[i, :, :, :].size())
            
            for h in range(args.crop_size):
                for w in range(args.crop_size):
                    if render[0, h, w]>0.95:
                        render_imgs_[i, :, h, w] = background[:, h, w]
        #--------------------------------------------------------------------#
    # save = render_imgs_[i,:,:,:].numpy()
    # save = np.transpose(save, (1,2,0))
    # save = (save*255).astype(np.uint8)
    # # print(save)
    # # print(save.shape)
    # imageio.imwrite(os.path.join('./results', f'{i:03d}.png'), save)
        #--------------------------------------------------------------------#
                    
    # Normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    # for i in range(len(render_imgs)):
    #     render_imgs_[i,:,:,:] = Normalize(render_imgs_[i,:,:,:])

    return render_imgs_


def GMSampler(dist_pool_mu, dist_pool_sigma, batch_size, clean_imgs=None, split='train', flag='AT'):
    args = get_opts()
    """
    从对应类别的混合高斯分布池中采样视角参数，并生成对应的渲染对抗样本
    Args:
        label: a batch of true label
        dist_pool: The uploaded GM distribution pool
        batch_size: num of adversarial viewpoint renderings

    Returns: a batch of adversarial viewpoint rendering images

    """
    """
    dist_pool以四维数组形式存储 m为标签（数字表示） 后三维为对应的 n*k*6矩阵(n为每个物体设置采集的分布数,k为一个分布的分量数)
    
    dist_pool_mu: array(m,n,k,6)
    dist_pool_sigma: array(m,n,k,6)
    dist_pool_omiga: array(m,n,k,6) // omiga = 1.0/K
    """
    M = dist_pool_mu.shape[0]
    # N = dist_pool_mu.shape[1]
    k = dist_pool_mu.shape[2]

    if split == 'train':
        ckpt_path = f'{args.ckpt_attack_path}/train/'
    else:
        ckpt_path = f'{args.ckpt_attack_path}/test/'

    label_list = os.listdir(ckpt_path)
    label_list.sort()

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])

    a = [30, 180, 70, 1.0, 0.5, 0.5]
    b = [0, 0, 0, 4.0, 0, 0]
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)
        # if args.share_dist:
        #     mu = dist_pool_mu[label_idx[i], 0, :, :].squeeze()
        #     sigma = dist_pool_sigma[label_idx[i], 0, :, :].squeeze()
        # else:
        if args.share_dist:  # 分布共享策略，将以0.5的概率抽到物体本身分布，其余0.5概率随机选择剩下的分布共享 
            num_self = np.random.random(size=1)
            if num_self < 1-args.share_dist_rate:
                n_choice = n_idx
            else:
                n_choice = np.random.randint(low=0, high=N, size=1)
        else:
            n_choice = n_idx

        mu = dist_pool_mu[label_idx[i], n_choice, :, :].squeeze()
        sigma = dist_pool_sigma[label_idx[i], n_choice, :, :].squeeze()

        F = np.random.choice(a=np.arange(k), size=6, replace=True, p=np.ones(k)/k)
        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            L = int(F[j])
            if args.num_k == 1:
                sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[j], scale=sigma[j], size=1))+b[j]
            else:
                sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[L, j], scale=sigma[L, j], size=1))+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs, split=split) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split, flag=flag)

    return  render_imgs, labels



def ViewFoolSampler(dist_pool_mu, dist_pool_sigma, batch_size, clean_imgs=None, split='train', flag='AT'):
    args = get_opts()
    """
    执行ViewFool攻击后，从单高斯分布中采样，并生成对应的渲染对抗样本
    Args:
        label: a batch of true label
        dist_pool: The uploaded GM distribution pool
        batch_size: num of adversarial viewpoint renderings

    Returns: a batch of adversarial viewpoint rendering images

    """
    """
    viewfool 的dist_pool以三维数组形式存储 m为标签（数字表示） 后二维为对应的 n*6矩阵(n为每个物体设置采集的分布数,k为一个分布的分量数)
    
    dist_pool_mu: array(m,n,6)
    dist_pool_sigma: array(m,n,6)
    """
    M = dist_pool_mu.shape[0]
    # N = dist_pool_mu.shape[1]

    if split == 'train':
        ckpt_path = f'{args.ckpt_attack_path}/train/'
    else:
        ckpt_path = f'{args.ckpt_attack_path}/test/'

    label_list = os.listdir(ckpt_path)
    label_list.sort()

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])

    a = [30, 180, 70, 1.0, 0.5, 0.5]
    b = [0, 0, 0, 4.0, 0, 0]
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)
        mu = dist_pool_mu[label_idx[i], n_idx, :].squeeze()
        sigma = dist_pool_sigma[label_idx[i], n_idx, :].squeeze()
        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[j], scale=sigma[j], size=1))+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs, split=split) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split, flag=flag)

    return  render_imgs, labels


def RandomSampler(batch_size, clean_imgs=None, split='test', mood='eval'):
    args = get_opts()
    ckpt_path = f'{args.ckpt_attack_path}/test/'
    label_list = os.listdir(ckpt_path)
    label_list.sort()
    M = len(label_list)

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])
    with open('/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/natural_viewrange.txt') as f:
        viewrange = [line.strip() for line in f.readlines()]
    
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)

        if mood == 'eval': # side
            if str(viewrange[int(label_list[label_idx[i]])]) == '0':
                a = [0, 360, 0, 2.0, 1.0, 1.0]
                b = [0, -180, 70, 3.0, -0.5, -0.5]
            if str(viewrange[int(label_list[label_idx[i]])]) == '1':
                a = [0, 360, -10, 2.0, 1.0, 1.0]
                b = [0, -180, 55, 3.0, -0.5, -0.5]
            if str(viewrange[int(label_list[label_idx[i]])]) == '2':
                a = [0, 360, -20, 2.0, 1.0, 1.0]
                b = [0, -180, 10, 3.0, -0.5, -0.5]
        
        else:
            if args.AT_type == 'random': # full
                a = [60, 360, 140, 2.0, 1.0, 1.0]
                b = [-30, -180, -70, 3.0, -0.5, -0.5]
            elif args.AT_type == 'natural': # side
                if str(viewrange[int(label_list[label_idx[i]])]) == '0':
                    a = [0, 360, 0, 2.0, 1.0, 1.0]
                    b = [0, -180, 70, 3.0, -0.5, -0.5]
                if str(viewrange[int(label_list[label_idx[i]])]) == '1':
                    a = [0, 360, -10, 2.0, 1.0, 1.0]
                    b = [0, -180, 55, 3.0, -0.5, -0.5]
                if str(viewrange[int(label_list[label_idx[i]])]) == '2':
                    a = [0, 360, -20, 2.0, 1.0, 1.0]
                    b = [0, -180, 10, 3.0, -0.5, -0.5]
                
        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            sample[j] = a[j]*np.random.random(1)+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split)

    return  render_imgs, labels



# ------------------------------------------------------------------------------------------------------------- #


# settings
model_dir = args.model_dir
if not os.path.exists(model_dir):
    os.makedirs(model_dir)
use_cuda = not args.no_cuda and torch.cuda.is_available()
torch.manual_seed(args.seed)
device = torch.device("cuda" if use_cuda else "cpu")
# gpus = [0, 1, 2, 3, 4, 5]
gpus = [0, 1, 2, 3]

kwargs = {'num_workers': 10*len(gpus), 'pin_memory': True} if use_cuda else {}

# setup data loader

traindir = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/imagenet/train'
valdir = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/imagenet/val'

train_dataset = datasets.ImageFolder(
        traindir,
        transforms.Compose([
            transforms.RandomResizedCrop(args.crop_size),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],       
                                      std=[0.229, 0.224, 0.225])
        ]))

train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=args.batch_size, shuffle=True, sampler=None, **kwargs)

test_loader = torch.utils.data.DataLoader(
        datasets.ImageFolder(valdir, transforms.Compose([
            transforms.Resize(args.img_size),
            transforms.CenterCrop(args.crop_size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],       
                                      std=[0.229, 0.224, 0.225])
        ])),
        batch_size=args.batch_size, shuffle=False, **kwargs)



def train(args, model, device, train_loader, optimizer, scheduler, epoch, dist_pool_mu, dist_pool_sigma):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        
        if args.train_mood == 'AT':
            if args.AT_type == 'AVDT':
                render_imgs, render_label = GMSampler(dist_pool_mu, dist_pool_sigma, batch_size=16, clean_imgs=data,split='train')

            else:
                render_imgs, render_label = RandomSampler(batch_size=16, mood='training')

            data = torch.cat([data, render_imgs], dim=0)
            target = torch.cat([target, render_label], dim=0)
            # 打乱数据
            data = data.numpy()
            target = target.numpy()
            index = np.arange(len(target))
            np.random.shuffle(index)
            data = data[index]
            target = target[index]

            data = torch.from_numpy(data)
            target = torch.from_numpy(target)

        data, target = data.to(device), target.to(device)

        optimizer.zero_grad()
        # calculate robust loss
        if args.treat_model == 'inc-v3':
            logits = model(data).logits
        else:
            logits = model(data)
        loss = F.cross_entropy(logits, target)

        loss.backward()
        optimizer.step()
        # if args.treat_model == 'vit-b' or args.treat_model == 'swin-b' or args.treat_model == 'deit-b':
        #     scheduler.step()

        # print progress
        if batch_idx % args.log_interval == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                       100. * batch_idx / len(train_loader), loss.item()))

def eval_train(model, device, train_loader):
    model.eval()
    train_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in train_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= len(train_loader.dataset)
    print('Clean sample in Training set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, len(train_loader.dataset),
        100. * correct / len(train_loader.dataset)))
    training_accuracy = correct / len(train_loader.dataset)
    return train_loss, training_accuracy


def eval_test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    test_loss /= len(test_loader.dataset)
    print('Clean sample in Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))
    test_accuracy = correct / len(test_loader.dataset)
    return test_loss, test_accuracy


def eval_robust_last(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0

    NES_GMM_search(model, dist_pool_mu=None, dist_pool_sigma=None, mood='init')
    # load dist_pool
    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')
        
    for i in range(10):
        data, target = GMSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='test')
        data, target = data.to(device), target.to(device)
        data_num += len(data)

        output = model(data)
        train_loss += F.cross_entropy(output, target, size_average=False).item()
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('render train set robust_accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='AT'):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0
    with torch.no_grad():
        for i in range(10):
            data, target = GMSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='train', flag=flag)
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('GMFool trainset accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_robust_test(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0

    NES_GMM_search(model, dist_pool_mu=None, dist_pool_sigma=None, mood='eval_test')
    # load dist_pool
    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}_eval_test.npy')
    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}_eval_test.npy')

    with torch.no_grad():
        for i in range(5):
            data, target = GMSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='test')
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('GMFool testset accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_viewfool_test(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0

    NES_viewfool_search(model, mood='test')
    # load dist_pool
    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}_viewfool_test.npy')
    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}_viewfool_test.npy')

    with torch.no_grad():
        for i in range(5):
            data, target = ViewFoolSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='test')
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('ViewFool testset accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_random(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0
    with torch.no_grad():
        for i in range(10):
            data, target = RandomSampler(args.batch_size, mood='eval')
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('Random render accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy



def adjust_learning_rate(optimizer, epoch):
    """decrease the learning rate"""
    args = get_opts()
    if args.train_mood == 'AT':
        lr = args.lr
        # if epoch <= 9:
        #     lr = args.lr + 0.001
        if epoch >= 55:
            lr = args.lr * 0.1
        if epoch >= 70:
            lr = args.lr * 0.01
        if epoch >= 80:
            lr = args.lr * 0.001
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr
    else:
        lr = args.lr
        if epoch >= 75:
            lr = args.lr * 0.1
        if epoch >= 90:
            lr = args.lr * 0.01
        if epoch >= 100:
            lr = args.lr * 0.001
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr

#----------------------------------------------------------------------------------------------------------#

def main():
    # init model, ResNet18() can be also used here for training
    if args.treat_model == 'resnet50':
        model = torchvision.models.resnet50(pretrained=True)
        # checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-resnet50-final_res_viatvf_R-epoch60.pt'
        # checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-resnet50-test_random-epoch20.pt'
        #----------------------------------------------
        num_ftr = model.fc.in_features
        model.fc = nn.Linear(num_ftr,100)
        #----------------------------------------------

    if args.treat_model == 'inc-v3':
        model = torchvision.models.inception_v3(pretrained=False)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-inc-v3-inc-v3_pre_train-epoch120.pt'
        #----------------------------------------------
        num_ftr = model.fc.in_features
        model.fc = nn.Linear(num_ftr,100)
        #----------------------------------------------
    
    if args.treat_model == 'vit-b':
        model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=100)
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-vit-b-final_vit_viatvf_R-epoch60.pt'
        # checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-vit-b-final_vit_random-epoch20.pt'


    if args.train_mood == 'AT':
        model.load_state_dict(torch.load(checkpoint))
        
    model = model.to(device)
    model = torch.nn.DataParallel(model, device_ids=gpus, output_device=gpus[0])
    
    #----------------------------------------------------------------------------------------
    # if args.treat_model == 'vit-b' or args.treat_model == 'swin-b' or args.treat_model == 'deit-b':
    #     optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    #     scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=1e-9)
    # else:
    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)
    scheduler = None
    #----------------------------------------------------------------------------------------
    

    if args.AT_type == 'AVDT':
        for epoch in range(1, args.epochs + 1):
            # adjust learning rate for SGD
            # if not args.treat_model == 'vit-b' or args.treat_model == 'swin-b' or args.treat_model == 'deit-b':
            adjust_learning_rate(optimizer, epoch)
            
            if args.train_mood == 'AT':
                # random attack
                print('================================================================')
                eval_random(model, device)
                print('================================================================')
                
                # warm_start if epoch>1
                if epoch == 1:
                    # attack to generate dist_pool first
                    
                    # NES_GMM_search(model, dist_pool_mu=None, dist_pool_sigma=None, mood='init')
                    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
                    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')
                    
                    print('================================================================')
                    eval_robust_test(model, device) # GMVFool
                    # eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='before_AT')
                    eval_viewfool_test(model, device) # ViewFool
                    print('================================================================')
                else:
                    # load dist_pool first
                    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
                    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')

                    NES_GMM_search(model, dist_pool_mu=dist_pool_mu, dist_pool_sigma=dist_pool_sigma, mood='warm_start')

                    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
                    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')
            else:
                dist_pool_mu = None
                dist_pool_sigma = None


            # adversarial training
            train(args, model, device, train_loader, optimizer, scheduler, epoch, dist_pool_mu, dist_pool_sigma)

            # evaluation on natural examples
            print('================================================================')
            eval_train(model, device, train_loader)
            eval_test(model, device, test_loader)
            if args.train_mood == 'AT':
                # eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='before_AT')
                if epoch % 30 == 0:
                    eval_robust_test(model, device) # GMVFool
                    eval_viewfool_test(model, device)
            print('================================================================')

            # save checkpoint
            if epoch % args.save_freq == 0:
                torch.save(model.module.state_dict(), os.path.join(model_dir, 'model-{}-{}-epoch{}.pt'.format(args.treat_model, args.AT_exp_name, epoch)))
                # torch.save(optimizer.state_dict(), os.path.join(model_dir, 'opt-res50-checkpoint_epoch{}.tar'.format(epoch)))
        
        # GMFool ATTACK
        # eval_robust_last(model, device)
    
    if args.AT_type == 'natural' or args.AT_type == 'random':   
        for epoch in range(1, args.epochs + 1):
            # adjust learning rate for SGD
            # if not args.treat_model == 'vit-b' or args.treat_model == 'swin-b' or args.treat_model == 'deit-b':
            adjust_learning_rate(optimizer, epoch)
           
            dist_pool_mu = None
            dist_pool_sigma = None

            print('================================================================')
            eval_random(model, device)
            print('================================================================')

            if epoch == 0:
                # random attack
                print('================================================================')
                eval_robust_test(model, device) # GMVFool
                # eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='before_AT')
                eval_viewfool_test(model, device) # ViewFool
                print('================================================================')
                
            # adversarial training
            train(args, model, device, train_loader, optimizer, scheduler, epoch, dist_pool_mu, dist_pool_sigma)
            # evaluation on natural examples
            print('================================================================')
            eval_train(model, device, train_loader)
            eval_test(model, device, test_loader)
            if args.train_mood == 'AT':
                # eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='before_AT')
                if epoch % 30 == 0:
                    eval_robust_test(model, device) # GMVFool
                    eval_viewfool_test(model, device)
            print('================================================================')

            # save checkpoint
            if epoch % args.save_freq == 0:
                torch.save(model.module.state_dict(), os.path.join(model_dir, 'model-{}-{}-epoch{}.pt'.format(args.treat_model, args.AT_exp_name, epoch)))
                # torch.save(optimizer.state_dict(), os.path.join(model_dir, 'opt-res50-checkpoint_epoch{}.tar'.format(epoch)))
        
        # GMFool ATTACK
        # eval_robust_last(model, device)



if __name__ == '__main__':
    main()

--- 文件地址: viat/train_trades_imagenet_Natural_viewpoint.py ---
from __future__ import print_function
import os
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torch.optim as optim
from torchvision import datasets, transforms

from trades import trades_loss

from PIL import Image  
import numpy as np
from models.networks import NGP
from models.rendering import render
from metrics import psnr

from tqdm import tqdm
from datasets import dataset_dict
from datasets.ray_utils import get_rays
from utils import load_ckpt
from train import depth2img
import imageio
import joblib

from datasets.opts import get_opts

# 用于寻找攻击的 dist_pool 需要遍历当前所有存在的物体 保存dist_pool.npy（为了warm-star操作）
from NES_GMM_forAT import NES_GMM_search
from NES_viewfool_forAT import NES_viewfool_search


args = get_opts()

@torch.no_grad()
def render_image(all_args, labels, objects, is_over=False, split='train'):
    """
    调用渲染函数 从viewpoints渲染一批图像
    Args:
        all_args: viewpoints array(batchsize, 6)
        labels: 每列viewpoint属于的类别号 array(batchszie, 1)
        batch_size: 每列viewpoint属于的类别中的物体序号 array(batchszie, 1)

    Returns: a batch of adversarial viewpoint rendering images

    ./ckpt/nerf/ 存放着所有物体的nerf权重
    -----------
    /913/00.pt
    /913/01.pt
    ... ... ...
    /913/09.pt
    -------------
    """

    dataset = dataset_dict['nerf_for_attack'](
        root_dir='/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog',
        split='AT', downsample=0.5, all_args=all_args, is_over=is_over
    )
    model = NGP(scale=0.5).cuda()
    
    # save_path = f'results/{args.dataset_name}/{args.scene_name}'
    # os.makedirs(save_path, exist_ok=True)
    imgs = np.zeros((len(dataset), 400, 400, 3))
    
    for img_idx in range(len(dataset)):
        
        ckpt_path = f'./ckpts/nerf/{split}/' + str('%02d' % int(labels[img_idx])) + '/' + str('%02d' % objects[img_idx]) + '.ckpt'
        load_ckpt(model, ckpt_path)

        rays_o, rays_d = get_rays(dataset.directions.cuda(), dataset[img_idx]['pose'].cuda())
        results = render(model, rays_o, rays_d,
                        **{'test_time': True,
                            'T_threshold': 1e-2
                            })
        torch.cuda.synchronize()
        #TS += time.time()-t
        pred = results['rgb'].reshape(dataset.img_wh[1], dataset.img_wh[0], 3).cpu().numpy()
        pred = (pred*255).astype(np.uint8)

        imgs[img_idx, :, :, :] = pred
        # if is_over:
        #     imageio.imwrite(os.path.join(save_path, f'{img_idx:03d}.png'), pred)

    return imgs


def AddBackground(render_imgs, clean_images, batch_size, split, flag='AT'):
    
    render_transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize(args.crop_size),
            transforms.ToTensor(),
        ])

    render_imgs_ = torch.zeros([len(render_imgs), 3, args.crop_size, args.crop_size])
    for i in range(len(render_imgs)):
        a = np.uint8(render_imgs[i,:,:,:])
        render_imgs_[i,:,:,:] = render_transform(a)
        #--------------------------------------------------------------------#
        # save = render_imgs_[i,:,:,:].numpy()
        # save = np.transpose(save, (1,2,0))
        # save = (save*255).astype(np.uint8)
        # # print(save)
        # # print(save.shape)
        # imageio.imwrite(os.path.join('./results', f'{i:03d}.png'), save)
        #--------------------------------------------------------------------#
        
    if split == 'train' and not args.no_background and flag == 'AT':
        for i in range(batch_size):
            background = torch.squeeze(clean_images[np.random.randint(low=0, high=batch_size, size=1),:,:,:])
            render = render_imgs_[i, :, :, :]
            # print('background',background.size())
            # print('render', render_imgs_[i, :, :, :].size())
            
            for h in range(args.crop_size):
                for w in range(args.crop_size):
                    if render[0, h, w]>0.95:
                        render_imgs_[i, :, h, w] = background[:, h, w]
        #--------------------------------------------------------------------#
    save = render_imgs_[i,:,:,:].numpy()
    save = np.transpose(save, (1,2,0))
    save = (save*255).astype(np.uint8)
    # print(save)
    # print(save.shape)
    imageio.imwrite(os.path.join('./results', f'{i:03d}.png'), save)
        #--------------------------------------------------------------------#
                    
    # Normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    # for i in range(len(render_imgs)):
    #     render_imgs_[i,:,:,:] = Normalize(render_imgs_[i,:,:,:])

    return render_imgs_


def GMSampler(dist_pool_mu, dist_pool_sigma, batch_size, clean_imgs=None, split='train', flag='AT'):
    args = get_opts()
    """
    从对应类别的混合高斯分布池中采样视角参数，并生成对应的渲染对抗样本
    Args:
        label: a batch of true label
        dist_pool: The uploaded GM distribution pool
        batch_size: num of adversarial viewpoint renderings

    Returns: a batch of adversarial viewpoint rendering images

    """
    """
    dist_pool以四维数组形式存储 m为标签（数字表示） 后三维为对应的 n*k*6矩阵(n为每个物体设置采集的分布数,k为一个分布的分量数)
    
    dist_pool_mu: array(m,n,k,6)
    dist_pool_sigma: array(m,n,k,6)
    dist_pool_omiga: array(m,n,k,6) // omiga = 1.0/K
    """
    M = dist_pool_mu.shape[0]
    # N = dist_pool_mu.shape[1]
    k = dist_pool_mu.shape[2]

    if split == 'train':
        ckpt_path = './ckpts/nerf/train/'
    else:
        ckpt_path = './ckpts/nerf/test/'

    label_list = os.listdir(ckpt_path)
    label_list.sort()

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])

    a = [30, 180, 70, 1.0, 0.5, 0.5]
    b = [0, 0, 0, 4.0, 0, 0]
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)
        if args.share_dist:
            mu = dist_pool_mu[label_idx[i], 0, :, :].squeeze()
            sigma = dist_pool_sigma[label_idx[i], 0, :, :].squeeze()
        else:
            mu = dist_pool_mu[label_idx[i], n_idx, :, :].squeeze()
            sigma = dist_pool_sigma[label_idx[i], n_idx, :, :].squeeze()

        F = np.random.choice(a=np.arange(k), size=6, replace=True, p=np.ones(k)/k)
        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            L = int(F[j])
            sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[L, j], scale=sigma[L, j], size=1))+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs, split=split) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split, flag=flag)

    return  render_imgs, labels



def ViewFoolSampler(dist_pool_mu, dist_pool_sigma, batch_size, clean_imgs=None, split='train', flag='AT'):
    """
    执行ViewFool攻击后，从单高斯分布中采样，并生成对应的渲染对抗样本
    Args:
        label: a batch of true label
        dist_pool: The uploaded GM distribution pool
        batch_size: num of adversarial viewpoint renderings

    Returns: a batch of adversarial viewpoint rendering images

    """
    """
    viewfool 的dist_pool以三维数组形式存储 m为标签（数字表示） 后二维为对应的 n*6矩阵(n为每个物体设置采集的分布数,k为一个分布的分量数)
    
    dist_pool_mu: array(m,n,6)
    dist_pool_sigma: array(m,n,6)
    """
    M = dist_pool_mu.shape[0]
    # N = dist_pool_mu.shape[1]

    if split == 'train':
        ckpt_path = './ckpts/nerf/train/'
    else:
        ckpt_path = './ckpts/nerf/test/'

    label_list = os.listdir(ckpt_path)
    label_list.sort()

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])

    a = [30, 180, 70, 1.0, 0.5, 0.5]
    b = [0, 0, 0, 4.0, 0, 0]
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)
        mu = dist_pool_mu[label_idx[i], n_idx, :].squeeze()
        sigma = dist_pool_sigma[label_idx[i], n_idx, :].squeeze()
        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[j], scale=sigma[j], size=1))+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs, split=split) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split, flag=flag)

    return  render_imgs, labels


def RandomSampler(batch_size, clean_imgs=None, split='test'):

    ckpt_path = './ckpts/nerf/test/'
    label_list = os.listdir(ckpt_path)
    label_list.sort()
    M = len(label_list)

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])
    random_type = 'side'

    if random_type=='side':
        a = [0, 360, -10, 2.0, 1.0, 1.0]
        b = [0, -180, 70, 3.0, -0.5, -0.5]
    elif random_type=='up':
        a = [0, 360, -30, 2.0, 1.0, 1.0]
        b = [0, -180, 15, 3.0, -0.5, -0.5]
    elif random_type=='full':
        a = [60, 360, 140, 2.0, 1.0, 1.0]
        b = [-30, -180, -70, 3.0, -0.5, -0.5]

    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)

        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            sample[j] = a[j]*np.random.random(1)+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split)

    return  render_imgs, labels



# ------------------------------------------------------------------------------------------------------------- #


# settings
model_dir = args.model_dir
if not os.path.exists(model_dir):
    os.makedirs(model_dir)
use_cuda = not args.no_cuda and torch.cuda.is_available()
torch.manual_seed(args.seed)
device = torch.device("cuda" if use_cuda else "cpu")
gpus = [0, 1, 2, 3, 4, 5, 6, 7]
# gpus = [0, 1, 2, 3]

kwargs = {'num_workers': 10*len(gpus), 'pin_memory': True} if use_cuda else {}

# setup data loader

traindir = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/imagenet/train'
valdir = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/imagenet/val'

train_dataset = datasets.ImageFolder(
        traindir,
        transforms.Compose([
            transforms.RandomResizedCrop(args.crop_size),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],       
                                      std=[0.229, 0.224, 0.225])
        ]))

train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=args.batch_size, shuffle=True, sampler=None, **kwargs)

test_loader = torch.utils.data.DataLoader(
        datasets.ImageFolder(valdir, transforms.Compose([
            transforms.Resize(args.img_size),
            transforms.CenterCrop(args.crop_size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],       
                                      std=[0.229, 0.224, 0.225])
        ])),
        batch_size=args.batch_size, shuffle=False, **kwargs)



def train(args, model, device, train_loader, optimizer, epoch, dist_pool_mu, dist_pool_sigma):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        
        if args.train_mood == 'AT':
            render_imgs, render_label = RandomSampler(batch_size=16)
            # print('img label:' , target)
            # print('render label:' , render_label)
            # print('img data:' , data.shape)
            # print('render data:' , render_imgs.shape)

            data = torch.cat([data, render_imgs], dim=0)
            target = torch.cat([target, render_label], dim=0)
            # 打乱数据
            data = data.numpy()
            target = target.numpy()
            index = np.arange(len(target))
            np.random.shuffle(index)
            data = data[index]
            target = target[index]

            data = torch.from_numpy(data)
            target = torch.from_numpy(target)

        data, target = data.to(device), target.to(device)

        optimizer.zero_grad()
        # calculate robust loss
        logits = model(data)
        loss = F.cross_entropy(logits, target)

        loss.backward()
        optimizer.step()

        # print progress
        if batch_idx % args.log_interval == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                       100. * batch_idx / len(train_loader), loss.item()))

def eval_train(model, device, train_loader):
    model.eval()
    train_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in train_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= len(train_loader.dataset)
    print('Clean sample in Training set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, len(train_loader.dataset),
        100. * correct / len(train_loader.dataset)))
    training_accuracy = correct / len(train_loader.dataset)
    return train_loss, training_accuracy


def eval_test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    test_loss /= len(test_loader.dataset)
    print('Clean sample in Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))
    test_accuracy = correct / len(test_loader.dataset)
    return test_loss, test_accuracy


def eval_robust_last(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0

    NES_GMM_search(model, mood='init')
    # load dist_pool
    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')
        
    for i in range(10):
        data, target = GMSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='test')
        data, target = data.to(device), target.to(device)
        data_num += len(data)

        output = model(data)
        train_loss += F.cross_entropy(output, target, size_average=False).item()
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('render train set robust_accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='AT'):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0
    with torch.no_grad():
        for i in range(10):
            data, target = GMSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='train', flag=flag)
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('GMFool trainset accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_robust_test(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0

    NES_GMM_search(model, mood='eval_test')
    # load dist_pool
    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}_eval_test.npy')
    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}_eval_test.npy')

    with torch.no_grad():
        for i in range(5):
            data, target = GMSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='test')
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('GMFool testset accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_viewfool_test(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0

    NES_viewfool_search(model, mood='test')
    # load dist_pool
    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}_viewfool_test.npy')
    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}_viewfool_test.npy')

    with torch.no_grad():
        for i in range(5):
            data, target = ViewFoolSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='test')
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('ViewFool testset accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_random(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0
    with torch.no_grad():
        for i in range(10):
            data, target = RandomSampler(args.batch_size)
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('Random render accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy



def adjust_learning_rate(optimizer, epoch):
    """decrease the learning rate"""
    lr = args.lr
    # if epoch <= 9:
    #     lr = args.lr + 0.001
    if epoch >= 35:
        lr = args.lr * 0.1
    if epoch >= 65:
        lr = args.lr * 0.01
    if epoch >= 100:
        lr = args.lr * 0.001
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr

#----------------------------------------------------------------------------------------------------------#

def main():
    # init model, ResNet18() can be also used here for training
    model = torchvision.models.resnet50(pretrained=False)
    # checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/NeRF/ckpts/resnet50-0676ba61.pth'
    checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-res50AT-test5_natural-epoch40.pt'
    num_ftr = model.fc.in_features
    model.fc = nn.Linear(num_ftr,100)

    model.load_state_dict(torch.load(checkpoint))
    model = model.to(device)
    model = torch.nn.DataParallel(model, device_ids=gpus, output_device=gpus[0])

    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)

    for epoch in range(41, args.epochs + 41):
        # adjust learning rate for SGD
        adjust_learning_rate(optimizer, epoch)
        
        if args.train_mood == 'AT':
            # random attack
            
             
            # warm_start if epoch>1
            if epoch == 0:
                # attack to generate dist_pool first
                print('================================================================')
                eval_random(model, device)
                print('================================================================')
                
                print('================================================================')
                eval_viewfool_test(model, device)
                print('================================================================')

            else:
                # adversarial training
                train(args, model, device, train_loader, optimizer, epoch, dist_pool_mu=None, dist_pool_sigma=None)

                # evaluation on natural examples
                print('================================================================')
                eval_train(model, device, train_loader)
                eval_test(model, device, test_loader)
                if args.train_mood == 'AT':
                # eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='before_AT')
                    if epoch % 5 == 0:
                        eval_viewfool_test(model, device)
                print('================================================================')
                
        else:
            dist_pool_mu = None
            dist_pool_sigma = None

        # save checkpoint
        if epoch % args.save_freq == 0:
            torch.save(model.module.state_dict(), os.path.join(model_dir, 'model-res50AT-{}-epoch{}.pt'.format(args.AT_exp_name, epoch)))
            # torch.save(optimizer.state_dict(), os.path.join(model_dir, 'opt-res50-checkpoint_epoch{}.tar'.format(epoch)))
    
    # GMFool ATTACK
    # eval_robust_last(model, device)

if __name__ == '__main__':
    main()

--- 文件地址: viat/train_trades_imagenet_viewpoint.py ---
from __future__ import print_function
import os
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torch.optim as optim
from torchvision import datasets, transforms

from trades import trades_loss

from PIL import Image  
import numpy as np
from models.networks import NGP
from models.rendering import render
from metrics import psnr

from tqdm import tqdm
from datasets import dataset_dict
from datasets.ray_utils import get_rays
from utils import load_ckpt
from train import depth2img
import imageio
import joblib
import timm


from datasets.opts import get_opts

# 用于寻找攻击的 dist_pool 需要遍历当前所有存在的物体 保存dist_pool.npy（为了warm-star操作）
from NES_GMM_forAT import NES_GMM_search
from NES_viewfool_forAT import NES_viewfool_search


args = get_opts()

@torch.no_grad()
def render_image(all_args, labels, objects, is_over=False, split='train'):
    """
    调用渲染函数 从viewpoints渲染一批图像
    Args:
        all_args: viewpoints array(batchsize, 6)
        labels: 每列viewpoint属于的类别号 array(batchszie, 1)
        batch_size: 每列viewpoint属于的类别中的物体序号 array(batchszie, 1)

    Returns: a batch of adversarial viewpoint rendering images

    ./ckpt/nerf/ 存放着所有物体的nerf权重
    -----------
    /913/00.pt
    /913/01.pt
    ... ... ...
    /913/09.pt
    -------------
    """

    dataset = dataset_dict['nerf_for_attack'](
        root_dir='/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog',
        split='AT', downsample=0.5, all_args=all_args, is_over=is_over
    )
    model = NGP(scale=0.5).cuda()
    
    # save_path = f'results/{args.dataset_name}/{args.scene_name}'
    # os.makedirs(save_path, exist_ok=True)
    imgs = np.zeros((len(dataset), 400, 400, 3))
    
    for img_idx in range(len(dataset)):
        
        ckpt_path = f'{args.ckpt_attack_path}/{split}/' + str('%02d' % int(labels[img_idx])) + '/' + str('%02d' % objects[img_idx]) + '.ckpt'
        load_ckpt(model, ckpt_path)

        rays_o, rays_d = get_rays(dataset.directions.cuda(), dataset[img_idx]['pose'].cuda())
        results = render(model, rays_o, rays_d,
                        **{'test_time': True,
                            'T_threshold': 1e-2
                            })
        torch.cuda.synchronize()
        #TS += time.time()-t
        pred = results['rgb'].reshape(dataset.img_wh[1], dataset.img_wh[0], 3).cpu().numpy()
        pred = (pred*255).astype(np.uint8)

        imgs[img_idx, :, :, :] = pred
        # if is_over:
        #     imageio.imwrite(os.path.join(save_path, f'{img_idx:03d}.png'), pred)

    return imgs


def AddBackground(render_imgs, clean_images, batch_size, split, flag='AT'):
    
    render_transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize(args.crop_size),
            transforms.ToTensor(),
        ])

    render_imgs_ = torch.zeros([len(render_imgs), 3, args.crop_size, args.crop_size])
    for i in range(len(render_imgs)):
        a = np.uint8(render_imgs[i,:,:,:])
        render_imgs_[i,:,:,:] = render_transform(a)
        #--------------------------------------------------------------------#
        # save = render_imgs_[i,:,:,:].numpy()
        # save = np.transpose(save, (1,2,0))
        # save = (save*255).astype(np.uint8)
        # # print(save)
        # # print(save.shape)
        # imageio.imwrite(os.path.join('./results', f'{i:03d}.png'), save)
        #--------------------------------------------------------------------#
        
    if split == 'train' and not args.no_background and flag == 'AT':
        for i in range(batch_size):
            background = torch.squeeze(clean_images[np.random.randint(low=0, high=batch_size, size=1),:,:,:])
            render = render_imgs_[i, :, :, :]
            # print('background',background.size())
            # print('render', render_imgs_[i, :, :, :].size())
            
            for h in range(args.crop_size):
                for w in range(args.crop_size):
                    if render[0, h, w]>0.95:
                        render_imgs_[i, :, h, w] = background[:, h, w]
        #--------------------------------------------------------------------#
    # save = render_imgs_[i,:,:,:].numpy()
    # save = np.transpose(save, (1,2,0))
    # save = (save*255).astype(np.uint8)
    # # print(save)
    # # print(save.shape)
    # imageio.imwrite(os.path.join('./results', f'{i:03d}.png'), save)
        #--------------------------------------------------------------------#
                    
    # Normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    # for i in range(len(render_imgs)):
    #     render_imgs_[i,:,:,:] = Normalize(render_imgs_[i,:,:,:])

    return render_imgs_


def GMSampler(dist_pool_mu, dist_pool_sigma, batch_size, clean_imgs=None, split='train', flag='AT'):
    args = get_opts()
    """
    从对应类别的混合高斯分布池中采样视角参数，并生成对应的渲染对抗样本
    Args:
        label: a batch of true label
        dist_pool: The uploaded GM distribution pool
        batch_size: num of adversarial viewpoint renderings

    Returns: a batch of adversarial viewpoint rendering images

    """
    """
    dist_pool以四维数组形式存储 m为标签（数字表示） 后三维为对应的 n*k*6矩阵(n为每个物体设置采集的分布数,k为一个分布的分量数)
    
    dist_pool_mu: array(m,n,k,6)
    dist_pool_sigma: array(m,n,k,6)
    dist_pool_omiga: array(m,n,k,6) // omiga = 1.0/K
    """
    M = dist_pool_mu.shape[0]
    # N = dist_pool_mu.shape[1]
    k = dist_pool_mu.shape[2]

    if split == 'train':
        ckpt_path = f'{args.ckpt_attack_path}/train/'
    else:
        ckpt_path = f'{args.ckpt_attack_path}/test/'

    label_list = os.listdir(ckpt_path)
    label_list.sort()

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])

    a = [30, 180, 70, 1.0, 0.5, 0.5]
    b = [0, 0, 0, 4.0, 0, 0]
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)
        # if args.share_dist:
        #     mu = dist_pool_mu[label_idx[i], 0, :, :].squeeze()
        #     sigma = dist_pool_sigma[label_idx[i], 0, :, :].squeeze()
        # else:
        if args.share_dist:  # 分布共享策略，将以0.5的概率抽到物体本身分布，其余0.5概率随机选择剩下的分布共享 
            num_self = np.random.random(size=1)
            if num_self < 1-args.share_dist_rate:
                n_choice = n_idx
            else:
                n_choice = np.random.randint(low=0, high=N, size=1)
        else:
            n_choice = n_idx

        mu = dist_pool_mu[label_idx[i], n_choice, :, :].squeeze()
        sigma = dist_pool_sigma[label_idx[i], n_choice, :, :].squeeze()

        F = np.random.choice(a=np.arange(k), size=6, replace=True, p=np.ones(k)/k)
        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            L = int(F[j])
            sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[L, j], scale=sigma[L, j], size=1))+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs, split=split) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split, flag=flag)

    return  render_imgs, labels



def ViewFoolSampler(dist_pool_mu, dist_pool_sigma, batch_size, clean_imgs=None, split='train', flag='AT'):
    args = get_opts()
    """
    执行ViewFool攻击后，从单高斯分布中采样，并生成对应的渲染对抗样本
    Args:
        label: a batch of true label
        dist_pool: The uploaded GM distribution pool
        batch_size: num of adversarial viewpoint renderings

    Returns: a batch of adversarial viewpoint rendering images

    """
    """
    viewfool 的dist_pool以三维数组形式存储 m为标签（数字表示） 后二维为对应的 n*6矩阵(n为每个物体设置采集的分布数,k为一个分布的分量数)
    
    dist_pool_mu: array(m,n,6)
    dist_pool_sigma: array(m,n,6)
    """
    M = dist_pool_mu.shape[0]
    # N = dist_pool_mu.shape[1]

    if split == 'train':
        ckpt_path = f'{args.ckpt_attack_path}/train/'
    else:
        ckpt_path = f'{args.ckpt_attack_path}/test/'

    label_list = os.listdir(ckpt_path)
    label_list.sort()

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])

    a = [30, 180, 70, 1.0, 0.5, 0.5]
    b = [0, 0, 0, 4.0, 0, 0]
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)
        mu = dist_pool_mu[label_idx[i], n_idx, :].squeeze()
        sigma = dist_pool_sigma[label_idx[i], n_idx, :].squeeze()
        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[j], scale=sigma[j], size=1))+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs, split=split) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split, flag=flag)

    return  render_imgs, labels


def RandomSampler(batch_size, clean_imgs=None, split='test'):
    args = get_opts()
    ckpt_path = f'{args.ckpt_attack_path}/test/'
    label_list = os.listdir(ckpt_path)
    label_list.sort()
    M = len(label_list)

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])
    random_type = 'side'

    if random_type=='side':
        a = [0, 360, -10, 2.0, 1.0, 1.0]
        b = [0, -180, 70, 3.0, -0.5, -0.5]
    elif random_type=='up':
        a = [0, 360, -30, 2.0, 1.0, 1.0]
        b = [0, -180, 15, 3.0, -0.5, -0.5]
    elif random_type=='full':
        a = [60, 360, 140, 2.0, 1.0, 1.0]
        b = [-30, -180, -70, 3.0, -0.5, -0.5]

    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)

        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            sample[j] = a[j]*np.random.random(1)+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split)

    return  render_imgs, labels



# ------------------------------------------------------------------------------------------------------------- #


# settings
model_dir = args.model_dir
if not os.path.exists(model_dir):
    os.makedirs(model_dir)
use_cuda = not args.no_cuda and torch.cuda.is_available()
torch.manual_seed(args.seed)
device = torch.device("cuda" if use_cuda else "cpu")
gpus = [0, 1, 2, 3]
# gpus = [0, 1, 2, 3]

kwargs = {'num_workers': 10*len(gpus), 'pin_memory': True} if use_cuda else {}

# setup data loader

traindir = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/imagenet/train'
valdir = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/imagenet/val'

train_dataset = datasets.ImageFolder(
        traindir,
        transforms.Compose([
            transforms.RandomResizedCrop(args.crop_size),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],       
                                      std=[0.229, 0.224, 0.225])
        ]))

train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=args.batch_size, shuffle=True, sampler=None, **kwargs)

test_loader = torch.utils.data.DataLoader(
        datasets.ImageFolder(valdir, transforms.Compose([
            transforms.Resize(args.img_size),
            transforms.CenterCrop(args.crop_size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],       
                                      std=[0.229, 0.224, 0.225])
        ])),
        batch_size=args.batch_size, shuffle=False, **kwargs)



def train(args, model, device, train_loader, optimizer, scheduler, epoch, dist_pool_mu, dist_pool_sigma):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        
        if args.train_mood == 'AT':
            render_imgs, render_label = GMSampler(dist_pool_mu, dist_pool_sigma, batch_size=16, clean_imgs=data,split='train')
            # print('img label:' , target)
            # print('render label:' , render_label)
            # print('img data:' , data.shape)
            # print('render data:' , render_imgs.shape)

            data = torch.cat([data, render_imgs], dim=0)
            target = torch.cat([target, render_label], dim=0)
            # 打乱数据
            data = data.numpy()
            target = target.numpy()
            index = np.arange(len(target))
            np.random.shuffle(index)
            data = data[index]
            target = target[index]

            data = torch.from_numpy(data)
            target = torch.from_numpy(target)

        data, target = data.to(device), target.to(device)

        optimizer.zero_grad()
        # calculate robust loss
        if args.treat_model == 'inc-v3':
            logits = model(data).logits
        else:
            logits = model(data)
        loss = F.cross_entropy(logits, target)

        loss.backward()
        optimizer.step()
        if args.treat_model == 'vit-b' or args.treat_model == 'swin-b' or args.treat_model == 'deit-b':
            scheduler.step()

        # print progress
        if batch_idx % args.log_interval == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                       100. * batch_idx / len(train_loader), loss.item()))

def eval_train(model, device, train_loader):
    model.eval()
    train_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in train_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= len(train_loader.dataset)
    print('Clean sample in Training set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, len(train_loader.dataset),
        100. * correct / len(train_loader.dataset)))
    training_accuracy = correct / len(train_loader.dataset)
    return train_loss, training_accuracy


def eval_test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    test_loss /= len(test_loader.dataset)
    print('Clean sample in Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))
    test_accuracy = correct / len(test_loader.dataset)
    return test_loss, test_accuracy


def eval_robust_last(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0

    NES_GMM_search(model, dist_pool_mu=None, dist_pool_sigma=None, mood='init')
    # load dist_pool
    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')
        
    for i in range(10):
        data, target = GMSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='test')
        data, target = data.to(device), target.to(device)
        data_num += len(data)

        output = model(data)
        train_loss += F.cross_entropy(output, target, size_average=False).item()
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('render train set robust_accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='AT'):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0
    with torch.no_grad():
        for i in range(10):
            data, target = GMSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='train', flag=flag)
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('GMFool trainset accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_robust_test(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0

    NES_GMM_search(model, dist_pool_mu=None, dist_pool_sigma=None, mood='eval_test')
    # load dist_pool
    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}_eval_test.npy')
    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}_eval_test.npy')

    with torch.no_grad():
        for i in range(5):
            data, target = GMSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='test')
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('GMFool testset accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_viewfool_test(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0

    NES_viewfool_search(model, mood='test')
    # load dist_pool
    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}_viewfool_test.npy')
    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}_viewfool_test.npy')

    with torch.no_grad():
        for i in range(5):
            data, target = ViewFoolSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='test')
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('ViewFool testset accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_random(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0
    with torch.no_grad():
        for i in range(10):
            data, target = RandomSampler(args.batch_size)
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('Random render accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy



def adjust_learning_rate(optimizer, epoch):
    """decrease the learning rate"""
    args = get_opts()
    if args.train_mood == 'AT':
        lr = args.lr
        # if epoch <= 9:
        #     lr = args.lr + 0.001
        if epoch >= 55:
            lr = args.lr * 0.1
        if epoch >= 70:
            lr = args.lr * 0.01
        if epoch >= 80:
            lr = args.lr * 0.001
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr
    else:
        lr = args.lr
        if epoch >= 75:
            lr = args.lr * 0.1
        if epoch >= 90:
            lr = args.lr * 0.01
        if epoch >= 100:
            lr = args.lr * 0.001
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr

#----------------------------------------------------------------------------------------------------------#

def main():
    # init model, ResNet18() can be also used here for training
    if args.treat_model == 'resnet50':
        model = torchvision.models.resnet50(pretrained=False)
        # checkpoint = '/data/home/scv7306/run/rsw_/NeRFAttack/NeRF/ckpts/resnet50-0676ba61.pth'
        checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-res50-epoch120.pt'
        #----------------------------------------------
        num_ftr = model.fc.in_features
        model.fc = nn.Linear(num_ftr,100)
        #----------------------------------------------

    if args.treat_model == 'inc-v3':
        model = torchvision.models.inception_v3(pretrained=False)
        checkpoint = '/data/home/scv7306/run/rsw_/NeRFAttack/NeRF/ckpts/inception_v3_google-0cc3c7bd.pth'
        # checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-res50-epoch120.pt'
        #----------------------------------------------
        num_ftr = model.fc.in_features
        model.fc = nn.Linear(num_ftr,100)
        #----------------------------------------------
    
    if args.treat_model == 'dense':
        model = torchvision.models.densenet121(pretrained=False)
        checkpoint = '/data/home/scv7306/run/rsw_/NeRFAttack/NeRF/ckpts/inception_v3_google-0cc3c7bd.pth'
        # checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-res50-epoch120.pt'
        #----------------------------------------------
        num_ftr = model.classifier.in_features
        model.classifier = nn.Linear(num_ftr, 100)
        #----------------------------------------------

    if args.treat_model == 'inc-res':
        model = timm.create_model('inception_resnet_v2', pretrained=False, num_classes=100)
    if args.treat_model == 'en':
        model = timm.create_model('efficientnet_b0', pretrained=False, num_classes=100)

    if args.treat_model == 'vit-b':
        model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=100)
    if args.treat_model == 'deit-b':
        model = timm.create_model('deit_base_patch16_224', pretrained=True, num_classes=100)
    if args.treat_model == 'swin-b':
        model = timm.create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=100)


    if args.train_mood == 'AT':
        model.load_state_dict(torch.load(checkpoint))
        
    model = model.to(device)
    model = torch.nn.DataParallel(model, device_ids=gpus, output_device=gpus[0])
    
    #----------------------------------------------------------------------------------------
    if args.treat_model == 'vit-b' or args.treat_model == 'swin-b' or args.treat_model == 'deit-b':
        optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=1e-9)
    else:
        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)
        scheduler = None
    #----------------------------------------------------------------------------------------
    


    for epoch in range(1, args.epochs + 1):
        # adjust learning rate for SGD
        if not args.treat_model == 'vit-b' or args.treat_model == 'swin-b' or args.treat_model == 'deit-b':
            adjust_learning_rate(optimizer, epoch)
        
        if args.train_mood == 'AT':
            # random attack
            print('================================================================')
            eval_random(model, device)
            print('================================================================')
            
            # warm_start if epoch>1
            if epoch == 1:
                # attack to generate dist_pool first
                
                NES_GMM_search(model, dist_pool_mu=None, dist_pool_sigma=None, mood='init')
                dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
                dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')
                
                print('================================================================')
                eval_robust_test(model, device) # GMVFool
                # eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='before_AT')
                eval_viewfool_test(model, device) # ViewFool
                print('================================================================')
            else:
                # load dist_pool first
                dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
                dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')

                NES_GMM_search(model, dist_pool_mu=dist_pool_mu, dist_pool_sigma=dist_pool_sigma, mood='warm_start')

                dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
                dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')
        else:
            dist_pool_mu = None
            dist_pool_sigma = None


        # adversarial training
        train(args, model, device, train_loader, optimizer, scheduler, epoch, dist_pool_mu, dist_pool_sigma)

        # evaluation on natural examples
        print('================================================================')
        eval_train(model, device, train_loader)
        eval_test(model, device, test_loader)
        if args.train_mood == 'AT':
            # eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='before_AT')
            if epoch % 10 == 0:
               eval_robust_test(model, device) # GMVFool
               eval_viewfool_test(model, device)
        print('================================================================')

        # save checkpoint
        if epoch % args.save_freq == 0:
            torch.save(model.module.state_dict(), os.path.join(model_dir, 'model-{}-{}-epoch{}.pt'.format(args.treat_model, args.AT_exp_name, epoch)))
            # torch.save(optimizer.state_dict(), os.path.join(model_dir, 'opt-res50-checkpoint_epoch{}.tar'.format(epoch)))
    
    # GMFool ATTACK
    # eval_robust_last(model, device)

if __name__ == '__main__':
    main()

--- 文件地址: viat/train_trades_imagenet_viewpoint_new.py ---
from __future__ import print_function

import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import os
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torch.optim as optim
from torchvision import datasets, transforms

from trades import trades_loss

from PIL import Image  
import numpy as np
from models.networks import NGP
from models.rendering import render
from metrics import psnr

from tqdm import tqdm
from datasets import dataset_dict
# --- BEGIN: PATH CORRECTION BLOCK ---
import sys
import os

# 强制将项目根目录（即当前脚本所在目录的上一级）插入到sys.path的最前面
# 这确保了无论如何，根目录都是模块搜索的最高优先级
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if sys.path[0] != project_root:
    sys.path.insert(0, project_root)
    print(f"--- PATH CORRECTION: Moved project root to the front of sys.path ---")
    print(f"[*] New sys.path[0]: {sys.path[0]}")

# --- END: PATH CORRECTION BLOCK ---
from datasets.ray_utils import get_rays
from utils import load_ckpt
from train import depth2img
import imageio
import joblib
import timm


from datasets.opts import get_opts

# 用于寻找攻击的 dist_pool 需要遍历当前所有存在的物体 保存dist_pool.npy（为了warm-star操作）
from NES_GMM_forAT import NES_GMM_search
from NES_viewfool_forAT import NES_viewfool_search


args = get_opts()

@torch.no_grad()
def render_image(all_args, labels, objects, is_over=False, split='train'):
    """
    调用渲染函数 从viewpoints渲染一批图像
    Args:
        all_args: viewpoints array(batchsize, 6)
        labels: 每列viewpoint属于的类别号 array(batchszie, 1)
        batch_size: 每列viewpoint属于的类别中的物体序号 array(batchszie, 1)

    Returns: a batch of adversarial viewpoint rendering images

    ./ckpt/nerf/ 存放着所有物体的nerf权重
    -----------
    /913/00.pt
    /913/01.pt
    ... ... ...
    /913/09.pt
    -------------
    """

    dataset = dataset_dict['nerf_for_attack'](
        root_dir='/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/dataset_source/viewfool/hotdog',
        split='AT', downsample=0.5, all_args=all_args, is_over=is_over
    )
    model = NGP(scale=0.5).cuda()
    
    # save_path = f'results/{args.dataset_name}/{args.scene_name}'
    # os.makedirs(save_path, exist_ok=True)
    imgs = np.zeros((len(dataset), 400, 400, 3))
    
    for img_idx in range(len(dataset)):
        
        ckpt_path = f'{args.ckpt_attack_path}/{split}/' + str('%02d' % int(labels[img_idx])) + '/' + str('%02d' % objects[img_idx]) + '.ckpt'
        load_ckpt(model, ckpt_path)

        rays_o, rays_d = get_rays(dataset.directions.cuda(), dataset[img_idx]['pose'].cuda())
        results = render(model, rays_o, rays_d,
                        **{'test_time': True,
                            'T_threshold': 1e-2
                            })
        torch.cuda.synchronize()
        #TS += time.time()-t
        pred = results['rgb'].reshape(dataset.img_wh[1], dataset.img_wh[0], 3).cpu().numpy()
        pred = (pred*255).astype(np.uint8)

        imgs[img_idx, :, :, :] = pred
        # if is_over:
        #     imageio.imwrite(os.path.join(save_path, f'{img_idx:03d}.png'), pred)

    return imgs


def AddBackground(render_imgs, clean_images, batch_size, split, flag='AT'):
    
    render_transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize(args.crop_size),
            transforms.ToTensor(),
        ])

    render_imgs_ = torch.zeros([len(render_imgs), 3, args.crop_size, args.crop_size])
    for i in range(len(render_imgs)):
        a = np.uint8(render_imgs[i,:,:,:])
        render_imgs_[i,:,:,:] = render_transform(a)
        #--------------------------------------------------------------------#
        # save = render_imgs_[i,:,:,:].numpy()
        # save = np.transpose(save, (1,2,0))
        # save = (save*255).astype(np.uint8)
        # # print(save)
        # # print(save.shape)
        # imageio.imwrite(os.path.join('./results', f'{i:03d}.png'), save)
        #--------------------------------------------------------------------#
        
    if split == 'train' and not args.no_background and flag == 'AT':
        for i in range(batch_size):
            background = torch.squeeze(clean_images[np.random.randint(low=0, high=batch_size, size=1),:,:,:])
            render = render_imgs_[i, :, :, :]
            # print('background',background.size())
            # print('render', render_imgs_[i, :, :, :].size())
            
            for h in range(args.crop_size):
                for w in range(args.crop_size):
                    if render[0, h, w]>0.95:
                        render_imgs_[i, :, h, w] = background[:, h, w]
        #--------------------------------------------------------------------#
    # save = render_imgs_[i,:,:,:].numpy()
    # save = np.transpose(save, (1,2,0))
    # save = (save*255).astype(np.uint8)
    # # print(save)
    # # print(save.shape)
    # imageio.imwrite(os.path.join('./results', f'{i:03d}.png'), save)
        #--------------------------------------------------------------------#
                    
    # Normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    # for i in range(len(render_imgs)):
    #     render_imgs_[i,:,:,:] = Normalize(render_imgs_[i,:,:,:])

    return render_imgs_


def GMSampler(dist_pool_mu, dist_pool_sigma, batch_size, clean_imgs=None, split='train', flag='AT'):
    args = get_opts()
    """
    从对应类别的混合高斯分布池中采样视角参数，并生成对应的渲染对抗样本
    Args:
        label: a batch of true label
        dist_pool: The uploaded GM distribution pool
        batch_size: num of adversarial viewpoint renderings

    Returns: a batch of adversarial viewpoint rendering images

    """
    """
    dist_pool以四维数组形式存储 m为标签（数字表示） 后三维为对应的 n*k*6矩阵(n为每个物体设置采集的分布数,k为一个分布的分量数)
    
    dist_pool_mu: array(m,n,k,6)
    dist_pool_sigma: array(m,n,k,6)
    dist_pool_omiga: array(m,n,k,6) // omiga = 1.0/K
    """
    M = dist_pool_mu.shape[0]
    # N = dist_pool_mu.shape[1]
    k = dist_pool_mu.shape[2]

    if split == 'train':
        ckpt_path = f'{args.ckpt_attack_path}/train/'
    else:
        ckpt_path = f'{args.ckpt_attack_path}/test/'

    label_list = os.listdir(ckpt_path)
    label_list.sort()

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])

    a = [30, 180, 70, 1.0, 0.5, 0.5]
    b = [0, 0, 0, 4.0, 0, 0]
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)
        # if args.share_dist:
        #     mu = dist_pool_mu[label_idx[i], 0, :, :].squeeze()
        #     sigma = dist_pool_sigma[label_idx[i], 0, :, :].squeeze()
        # else:
        if args.share_dist:  # 分布共享策略，将以0.5的概率抽到物体本身分布，其余0.5概率随机选择剩下的分布共享 
            num_self = np.random.random(size=1)
            if num_self < 1-args.share_dist_rate:
                n_choice = n_idx
            else:
                n_choice = np.random.randint(low=0, high=N, size=1)
        else:
            n_choice = n_idx

        mu = dist_pool_mu[label_idx[i], n_choice, :, :].squeeze()
        sigma = dist_pool_sigma[label_idx[i], n_choice, :, :].squeeze()

        F = np.random.choice(a=np.arange(k), size=6, replace=True, p=np.ones(k)/k)
        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            L = int(F[j])
            if args.num_k == 1:
                sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[j], scale=sigma[j], size=1))+b[j]
            else:
                sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[L, j], scale=sigma[L, j], size=1))+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs, split=split) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split, flag=flag)

    return  render_imgs, labels



def ViewFoolSampler(dist_pool_mu, dist_pool_sigma, batch_size, clean_imgs=None, split='train', flag='AT'):
    args = get_opts()
    """
    执行ViewFool攻击后，从单高斯分布中采样，并生成对应的渲染对抗样本
    Args:
        label: a batch of true label
        dist_pool: The uploaded GM distribution pool
        batch_size: num of adversarial viewpoint renderings

    Returns: a batch of adversarial viewpoint rendering images

    """
    """
    viewfool 的dist_pool以三维数组形式存储 m为标签（数字表示） 后二维为对应的 n*6矩阵(n为每个物体设置采集的分布数,k为一个分布的分量数)
    
    dist_pool_mu: array(m,n,6)
    dist_pool_sigma: array(m,n,6)
    """
    M = dist_pool_mu.shape[0]
    # N = dist_pool_mu.shape[1]

    if split == 'train':
        ckpt_path = f'{args.ckpt_attack_path}/train/'
    else:
        ckpt_path = f'{args.ckpt_attack_path}/test/'

    label_list = os.listdir(ckpt_path)
    label_list.sort()

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])

    a = [30, 180, 70, 1.0, 0.5, 0.5]
    b = [0, 0, 0, 4.0, 0, 0]
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)
        mu = dist_pool_mu[label_idx[i], n_idx, :].squeeze()
        sigma = dist_pool_sigma[label_idx[i], n_idx, :].squeeze()
        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            sample[j] = a[j]*np.tanh(np.random.normal(loc=mu[j], scale=sigma[j], size=1))+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs, split=split) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split, flag=flag)

    return  render_imgs, labels


def RandomSampler(batch_size, clean_imgs=None, split='test', mood='eval'):
    args = get_opts()
    ckpt_path = f'{args.ckpt_attack_path}/test/'
    label_list = os.listdir(ckpt_path)
    label_list.sort()
    M = len(label_list)

    label_idx = np.random.randint(low=0, high=M, size=batch_size)  # 生成随机的label
    # n_idx = np.random.randint(low=0, high=N, size=batch_size)

    sample_all = np.zeros([batch_size, 6])
    with open('/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/natural_viewrange.txt') as f:
        viewrange = [line.strip() for line in f.readlines()]
    
    n_idxs = []
    for i in range(batch_size):
        
        N = len(os.listdir(ckpt_path+label_list[label_idx[i]]+'/'))
        n_idx = np.random.randint(low=0, high=N, size=1)
        n_idxs.append(n_idx)
        # print(n_idx)

        if mood == 'eval': # side
            if str(viewrange[int(label_list[label_idx[i]])]) == '0':
                a = [0, 360, 0, 2.0, 1.0, 1.0]
                b = [0, -180, 70, 3.0, -0.5, -0.5]
            if str(viewrange[int(label_list[label_idx[i]])]) == '1':
                a = [0, 360, -10, 2.0, 1.0, 1.0]
                b = [0, -180, 55, 3.0, -0.5, -0.5]
            if str(viewrange[int(label_list[label_idx[i]])]) == '2':
                a = [0, 360, -20, 2.0, 1.0, 1.0]
                b = [0, -180, 10, 3.0, -0.5, -0.5]
        
        else:
            if args.AT_type == 'random': # full
                a = [60, 360, 140, 2.0, 1.0, 1.0]
                b = [-30, -180, -70, 3.0, -0.5, -0.5]
            elif args.AT_type == 'natural': # side
                if str(viewrange[int(label_list[label_idx[i]])]) == '0':
                    a = [0, 360, 0, 2.0, 1.0, 1.0]
                    b = [0, -180, 70, 3.0, -0.5, -0.5]
                if str(viewrange[int(label_list[label_idx[i]])]) == '1':
                    a = [0, 360, -10, 2.0, 1.0, 1.0]
                    b = [0, -180, 55, 3.0, -0.5, -0.5]
                if str(viewrange[int(label_list[label_idx[i]])]) == '2':
                    a = [0, 360, -20, 2.0, 1.0, 1.0]
                    b = [0, -180, 10, 3.0, -0.5, -0.5]
                
        sample = np.zeros(6)
        # print(mu)
        # print(sigma)
        for j in range(6):
            sample[j] = a[j]*np.random.random(1)+b[j]   # 得到一个viewpoint的一组参数

        sample_all[i, :] = sample # 加进总的viewpoints中


    labels = np.zeros(batch_size)
    for i in range(batch_size):
        labels[i] = int(label_list[label_idx[i]])
    labels = labels.astype(int)
    labels = torch.from_numpy(labels)
    render_imgs = render_image(sample_all, labels, n_idxs) # 遍历渲染第M个类的第N个物体
    render_imgs = AddBackground(render_imgs, clean_imgs, batch_size, split=split)

    return  render_imgs, labels



# ------------------------------------------------------------------------------------------------------------- #


# settings
model_dir = args.model_dir
if not os.path.exists(model_dir):
    os.makedirs(model_dir)
use_cuda = not args.no_cuda and torch.cuda.is_available()
torch.manual_seed(args.seed)
device = torch.device("cuda" if use_cuda else "cpu")
gpus = [0] 
# gpus = [0, 1, 2, 3]

kwargs = {'num_workers': 10*len(gpus), 'pin_memory': True} if use_cuda else {}

# setup data loader

traindir = '/hy-tmp/VIAT/datasets/ImageNet-V+/train' # 您的训练集路径
valdir = '/hy-tmp/VIAT/datasets/ImageNet-V+/val'     # 您的验证集路径

train_dataset = datasets.ImageFolder(
        traindir,
        transforms.Compose([
            transforms.RandomResizedCrop(args.crop_size),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],       
                                      std=[0.229, 0.224, 0.225])
        ]))

train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=args.batch_size, shuffle=True, sampler=None, **kwargs)

test_loader = torch.utils.data.DataLoader(
        datasets.ImageFolder(valdir, transforms.Compose([
            transforms.Resize(args.img_size),
            transforms.CenterCrop(args.crop_size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],       
                                      std=[0.229, 0.224, 0.225])
        ])),
        batch_size=args.batch_size, shuffle=False, **kwargs)



def train(args, model, device, train_loader, optimizer, scheduler, epoch, dist_pool_mu, dist_pool_sigma):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        
        if args.train_mood == 'AT':
            if args.AT_type == 'AVDT':
                render_imgs, render_label = GMSampler(dist_pool_mu, dist_pool_sigma, batch_size=16, clean_imgs=data,split='train')

            else:
                render_imgs, render_label = RandomSampler(batch_size=16, mood='training')

            data = torch.cat([data, render_imgs], dim=0)
            target = torch.cat([target, render_label], dim=0)
            # 打乱数据
            data = data.numpy()
            target = target.numpy()
            index = np.arange(len(target))
            np.random.shuffle(index)
            data = data[index]
            target = target[index]

            data = torch.from_numpy(data)
            target = torch.from_numpy(target)

        data, target = data.to(device), target.to(device)

        optimizer.zero_grad()
        # calculate robust loss
        if args.treat_model == 'inc-v3':
            logits = model(data).logits
        else:
            logits = model(data)
        loss = F.cross_entropy(logits, target)

        loss.backward()
        optimizer.step()
        # if args.treat_model == 'vit-b' or args.treat_model == 'swin-b' or args.treat_model == 'deit-b':
        #     scheduler.step()

        # print progress
        if batch_idx % args.log_interval == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                       100. * batch_idx / len(train_loader), loss.item()))

def eval_train(model, device, train_loader):
    model.eval()
    train_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in train_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= len(train_loader.dataset)
    print('Clean sample in Training set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, len(train_loader.dataset),
        100. * correct / len(train_loader.dataset)))
    training_accuracy = correct / len(train_loader.dataset)
    return train_loss, training_accuracy


def eval_test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    test_loss /= len(test_loader.dataset)
    print('Clean sample in Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))
    test_accuracy = correct / len(test_loader.dataset)
    return test_loss, test_accuracy


def eval_robust_last(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0

    NES_GMM_search(model, dist_pool_mu=None, dist_pool_sigma=None, mood='init')
    # load dist_pool
    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')
        
    for i in range(10):
        data, target = GMSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='test')
        data, target = data.to(device), target.to(device)
        data_num += len(data)

        output = model(data)
        train_loss += F.cross_entropy(output, target, size_average=False).item()
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('render train set robust_accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='AT'):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0
    with torch.no_grad():
        for i in range(10):
            data, target = GMSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='train', flag=flag)
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('GMFool trainset accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_robust_test(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0

    NES_GMM_search(model, dist_pool_mu=None, dist_pool_sigma=None, mood='eval_test')
    # load dist_pool
    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}_eval_test.npy')
    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}_eval_test.npy')

    with torch.no_grad():
        for i in range(5):
            data, target = GMSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='test')
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('GMFool testset accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_viewfool_test(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0

    NES_viewfool_search(model, mood='test')
    # load dist_pool
    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}_viewfool_test.npy')
    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}_viewfool_test.npy')

    with torch.no_grad():
        for i in range(5):
            data, target = ViewFoolSampler(dist_pool_mu, dist_pool_sigma, args.batch_size, split='test')
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('ViewFool testset accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy


def eval_random(model, device):
    model.eval()
    train_loss = 0
    correct = 0
    data_num = 0
    with torch.no_grad():
        for i in range(10):
            data, target = RandomSampler(args.batch_size, mood='eval')
            data, target = data.to(device), target.to(device)
            data_num += len(data)

            output = model(data)
            train_loss += F.cross_entropy(output, target, size_average=False).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= data_num

    print('Random render accuracy: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
        train_loss, correct, data_num,
        100. * correct / data_num))
    training_accuracy = correct / data_num

    return train_loss, training_accuracy



def adjust_learning_rate(optimizer, epoch):
    """decrease the learning rate"""
    args = get_opts()
    if args.train_mood == 'AT':
        lr = args.lr
        # if epoch <= 9:
        #     lr = args.lr + 0.001
        if epoch >= 55:
            lr = args.lr * 0.1
        if epoch >= 70:
            lr = args.lr * 0.01
        if epoch >= 80:
            lr = args.lr * 0.001
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr
    else:
        lr = args.lr
        if epoch >= 75:
            lr = args.lr * 0.1
        if epoch >= 90:
            lr = args.lr * 0.01
        if epoch >= 100:
            lr = args.lr * 0.001
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr

#----------------------------------------------------------------------------------------------------------#

def main():
    # init model, ResNet18() can be also used here for training
    # if args.treat_model == 'resnet50':
    #     # model = torchvision.models.resnet50(pretrained=False)
    #     # # checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-resnet50-final_res_viatvf_R-epoch60.pt'
    #     # checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-res50-epoch120.pt'
    #     # #----------------------------------------------
    #     # num_ftr = model.fc.in_features
    #     # model.fc = nn.Linear(num_ftr,100)
    #     # #----------------------------------------------
    if args.treat_model == 'resnet50':
        print("Loading ImageNet pre-trained ResNet-50 model...")
        # 1. 加载预训练模型，pretrained=True 会自动下载权重
        model = torchvision.models.resnet50(pretrained=True) 

        # 2. 获取最后一层全连接层的输入特征数
        num_ftr = model.fc.in_features
        
        # 3. [关键!] 替换最后一层，以适应你的5分类任务
        #    将原来的1000类输出改为5类输出
        NUM_CLASSES = 5 # 你的类别数量
        model.fc = nn.Linear(num_ftr, NUM_CLASSES)
        print(f"Model's final layer replaced for {NUM_CLASSES} classes.")

    elif args.treat_model == 'inc-v3':
        # 如果你要测试其他模型，也可以在这里添加类似逻辑
        # ...
        pass # 暂时忽略其他模型

    # if args.treat_model == 'inc-v3':
    #     model = torchvision.models.inception_v3(pretrained=False)
    #     checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-inc-v3-inc-v3_pre_train-epoch120.pt'
    #     #----------------------------------------------
    #     num_ftr = model.fc.in_features
    #     model.fc = nn.Linear(num_ftr,100)
    #     #----------------------------------------------
    
    # if args.treat_model == 'vit-b':
    #     model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=100)
    #     checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-vit-b-final_vit_viatvf_R-epoch60.pt'
    #     # checkpoint = '/data/home/scv7303/run/rsw_/NeRFAttack/ngp_pl/model-imagenet-100-ckpts/model-vit-b-final_vit_random-epoch20.pt'


    # if args.train_mood == 'AT':
    #     model.load_state_dict(torch.load(checkpoint))
        
    model = model.to(device)
    model = torch.nn.DataParallel(model, device_ids=gpus, output_device=gpus[0])
    
    #----------------------------------------------------------------------------------------
    # if args.treat_model == 'vit-b' or args.treat_model == 'swin-b' or args.treat_model == 'deit-b':
    #     optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    #     scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=1e-9)
    # else:
    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)
    scheduler = None
    #----------------------------------------------------------------------------------------
    

    if args.AT_type == 'AVDT':
        for epoch in range(1, args.epochs + 1):
            # adjust learning rate for SGD
            # if not args.treat_model == 'vit-b' or args.treat_model == 'swin-b' or args.treat_model == 'deit-b':
            adjust_learning_rate(optimizer, epoch)
            
            if args.train_mood == 'AT':
                # random attack
                print('================================================================')
                eval_random(model, device)
                print('================================================================')
                
                # warm_start if epoch>1
                if epoch == 1:
                    # attack to generate dist_pool first
                    
                    NES_GMM_search(model, dist_pool_mu=None, dist_pool_sigma=None, mood='init')
                    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
                    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')
                    
                    print('================================================================')
                    eval_robust_test(model, device) # GMVFool
                    # eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='before_AT')
                    eval_viewfool_test(model, device) # ViewFool
                    print('================================================================')
                else:
                    # load dist_pool first
                    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
                    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')

                    NES_GMM_search(model, dist_pool_mu=dist_pool_mu, dist_pool_sigma=dist_pool_sigma, mood='warm_start')

                    dist_pool_mu = np.load(f'./dist_pool/dist_pool_mu_{args.AT_exp_name}.npy')
                    dist_pool_sigma = np.load(f'./dist_pool/dist_pool_sigma_{args.AT_exp_name}.npy')
            else:
                dist_pool_mu = None
                dist_pool_sigma = None


            # adversarial training
            train(args, model, device, train_loader, optimizer, scheduler, epoch, dist_pool_mu, dist_pool_sigma)

            # evaluation on natural examples
            print('================================================================')
            eval_train(model, device, train_loader)
            eval_test(model, device, test_loader)
            if args.train_mood == 'AT':
                # eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='before_AT')
                if epoch % 10 == 0:
                    eval_robust_test(model, device) # GMVFool
                    eval_viewfool_test(model, device)
            print('================================================================')

            # save checkpoint
            if epoch % args.save_freq == 0:
                torch.save(model.module.state_dict(), os.path.join(model_dir, 'iccv-model-{}-{}-epoch{}.pt'.format(args.treat_model, args.AT_exp_name, epoch)))
                # torch.save(optimizer.state_dict(), os.path.join(model_dir, 'opt-res50-checkpoint_epoch{}.tar'.format(epoch)))
        
        # GMFool ATTACK
        # eval_robust_last(model, device)
    
    if args.AT_type == 'natural' or args.AT_type == 'random':   
        for epoch in range(1, args.epochs + 1):
            # adjust learning rate for SGD
            # if not args.treat_model == 'vit-b' or args.treat_model == 'swin-b' or args.treat_model == 'deit-b':
            adjust_learning_rate(optimizer, epoch)
           
            dist_pool_mu = None
            dist_pool_sigma = None

            print('================================================================')
            eval_random(model, device)
            print('================================================================')

            if epoch == 0:
                # random attack
                print('================================================================')
                eval_robust_test(model, device) # GMVFool
                # eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='before_AT')
                eval_viewfool_test(model, device) # ViewFool
                print('================================================================')
                
            # adversarial training
            train(args, model, device, train_loader, optimizer, scheduler, epoch, dist_pool_mu, dist_pool_sigma)
            # evaluation on natural examples
            print('================================================================')
            eval_train(model, device, train_loader)
            eval_test(model, device, test_loader)
            if args.train_mood == 'AT':
                # eval_robust_train(model, device, dist_pool_mu, dist_pool_sigma, flag='before_AT')
                if epoch % 10 == 0:
                    eval_robust_test(model, device) # GMVFool
                    eval_viewfool_test(model, device)
            print('================================================================')

            # save checkpoint
            if epoch % args.save_freq == 0:
                torch.save(model.module.state_dict(), os.path.join(model_dir, 'model-{}-{}-epoch{}.pt'.format(args.treat_model, args.AT_exp_name, epoch)))
                # torch.save(optimizer.state_dict(), os.path.join(model_dir, 'opt-res50-checkpoint_epoch{}.tar'.format(epoch)))
        
        # GMFool ATTACK
        # eval_robust_last(model, device)



if __name__ == '__main__':
    main()

--- 文件地址: viat/utils.py ---
import torch


def extract_model_state_dict(ckpt_path, model_name='model', prefixes_to_ignore=[]):
    checkpoint = torch.load(ckpt_path, map_location='cpu')
    checkpoint_ = {}
    if 'state_dict' in checkpoint: # if it's a pytorch-lightning checkpoint
        checkpoint = checkpoint['state_dict']
    for k, v in checkpoint.items():
        if not k.startswith(model_name):
            continue
        k = k[len(model_name)+1:]
        for prefix in prefixes_to_ignore:
            if k.startswith(prefix):
                break
        else:
            checkpoint_[k] = v
    return checkpoint_


def load_ckpt(model, ckpt_path, model_name='model', prefixes_to_ignore=[]):
    if not ckpt_path: return
    model_dict = model.state_dict()
    checkpoint_ = extract_model_state_dict(ckpt_path, model_name, prefixes_to_ignore)
    model_dict.update(checkpoint_)
    model.load_state_dict(model_dict)


def slim_ckpt(ckpt_path, save_poses=False):
    ckpt = torch.load(ckpt_path, map_location='cpu')
    # pop unused parameters
    keys_to_pop = ['directions', 'model.density_grid', 'model.grid_coords']
    if not save_poses: keys_to_pop += ['poses']
    for k in ckpt['state_dict']:
        if k.startswith('val_lpips'):
            keys_to_pop += [k]
    for k in keys_to_pop:
        ckpt['state_dict'].pop(k, None)
    return ckpt['state_dict']

